{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 01: Multi-class Classification \n",
    "In this Assignment, you will train a deep model on the CIFAR10 from the scratch using PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import os.path as osp\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "SEED = 1 \n",
    "NUM_CLASS = 10\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 30\n",
    "EVAL_INTERVAL=1\n",
    "SAVE_DIR = './log'\n",
    "\n",
    "# Optimizer\n",
    "LEARNING_RATE = 1e-1\n",
    "MOMENTUM = 0.9\n",
    "STEP=5\n",
    "GAMMA=0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cifar10 transform\n",
    "transform_cifar10_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_cifar10_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='../data', train=True,\n",
    "                                        download=True, transform=transform_cifar10_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='../data', train=False,\n",
    "                                       download=True, transform=transform_cifar10_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 4, 3)  \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3)  \n",
    "        self.fc1 = nn.Linear(8 * 6 * 6, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 8 * 6 * 6)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: per batch training/testing\n",
    "---\n",
    "\n",
    "Please denfine two function named ``train_batch`` and ``test_batch``. These functions are essential for training and evaluating machine learning models using batched data from dataloaders.\n",
    "\n",
    "**To do**: \n",
    "1. Define the loss function i.e [nn.CrossEntropyLoss()](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html).\n",
    "2. Take the image as the input and generate the output using the pre-defined SimpleNet.\n",
    "3. Calculate the loss between the output and the corresponding label using the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Write your answer here ##################\n",
    "# Define the loss function\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.L1Loss()\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAE\n",
    "def to_one_hot(target, num_classes):\n",
    "    \"\"\"\n",
    "    Convert target to one-hot encoding.\n",
    "\n",
    "    Args:\n",
    "        target (torch.Tensor): Target tensor of shape (batch_size,).\n",
    "        num_classes (int): Number of classes.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: One-hot encoded target of shape (batch_size, num_classes).\n",
    "    \"\"\"\n",
    "    one_hot_target = torch.zeros(target.size(0), num_classes).to(target.device)\n",
    "    one_hot_target.scatter_(1, target.unsqueeze(1), 1.)\n",
    "    return one_hot_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one training batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to train.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated by the defined loss function loss_fn().\n",
    "    \"\"\"\n",
    "    \n",
    "    ##################### Write your answer here ################## \n",
    "    output = model(image)\n",
    "    one_hot_target = to_one_hot(target, NUM_CLASS)\n",
    "    loss = criterion(output, one_hot_target)\n",
    "    \n",
    "    #output = model(image)\n",
    "    \n",
    "    #loss_fn =nn.CrossEntropyLoss()\n",
    "    #loss_fn =ce_loss(output, target)\n",
    "    #loss_fn = nn.L1Loss()\n",
    "    #loss_fn =focal_loss_gamma_0_5(output, target)\n",
    "    #loss_fn =focal_loss_gamma_2(output, target)\n",
    "    #loss = loss_fn(output , target)\n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one testing batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to evaluate.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated for the batch.\n",
    "    \"\"\"\n",
    "\n",
    "    ##################### Write your answer here ##################\n",
    "    #output = model(image)\n",
    "    output = model(image)\n",
    "    one_hot_target = to_one_hot(target, NUM_CLASS)\n",
    "    loss = criterion(output, one_hot_target)\n",
    "    #loss_fn = nn.CrossEntropyLoss()\n",
    "    #loss_fn =ce_loss(output, target)\n",
    "    #loss_fn = nn.L1Loss()\n",
    "    #loss_fn =focal_loss_gamma_0_5(output, target)\n",
    "    #loss_fn =focal_loss_gamma_2(output, target)\n",
    "    #loss = loss_fn(output, target)  \n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(learning_rate, momentum, gamma, step, EVAL_INTERVAL):\n",
    "    # Define your model, optimizer, and other necessary components\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    NUM_CLASS = 10\n",
    "    BATCH_SIZE = 64\n",
    "    NUM_EPOCHS = 30\n",
    "    SAVE_DIR = './log'\n",
    "    transform_cifar10_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    transform_cifar10_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    train_set = torchvision.datasets.CIFAR10(root='../data', train=True,\n",
    "                                             download=True, transform=transform_cifar10_train)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                                                   shuffle=True, num_workers=2)\n",
    "\n",
    "    test_set = torchvision.datasets.CIFAR10(root='../data', train=False,\n",
    "                                            download=True, transform=transform_cifar10_test)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                                  shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "    model = models.resnet18(weights=None)\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, NUM_CLASS)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step, gamma=gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = []\n",
    "training_acc = []\n",
    "testing_loss = []\n",
    "testing_acc = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    ##########################\n",
    "    ### Training\n",
    "    ##########################\n",
    "\n",
    "    running_cls_loss = 0.0\n",
    "    running_cls_corrects = 0\n",
    "\n",
    "    for batch_idx, (image, target) in enumerate(train_dataloader):\n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "       # model = model.to(device)\n",
    "\n",
    "        # train model\n",
    "        outputs, loss = train_batch(model, image, target)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        \n",
    "        loss_data = loss.data.item()\n",
    "        if np.isnan(loss_data):\n",
    "            raise ValueError('loss is nan while training')\n",
    "        running_cls_loss += loss.item()\n",
    "        running_cls_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    epoch_loss = running_cls_loss / len(train_set)\n",
    "    epoch_acc = running_cls_corrects.double() / len(train_set)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{NUM_EPOCHS} Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "    training_loss.append(epoch_loss)\n",
    "    training_acc.append(epoch_acc.cpu().detach().numpy())\n",
    "\n",
    "    # change learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "    ##########################\n",
    "    ### Testing\n",
    "    ##########################\n",
    "    # # eval model during training or in the last epoch\n",
    "    if (epoch + 1) % EVAL_INTERVAL == 0 or (epoch +1) == NUM_EPOCHS:\n",
    "        print('Begin test......')\n",
    "        model.eval()\n",
    "    \n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "\n",
    "        for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # test model\n",
    "            outputs, loss = test_batch(model, image, target)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            val_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        val_loss = val_loss / len(test_set)\n",
    "        val_acc = val_corrects.double() / len(test_set)\n",
    "        print(f'Test Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "        testing_loss.append(val_loss)\n",
    "        testing_acc.append(val_acc.cpu().detach().numpy())\n",
    "\n",
    "        # save the model in last epoch\n",
    "        if (epoch +1) == NUM_EPOCHS:\n",
    "            \n",
    "            state = {\n",
    "            'state_dict': model.state_dict(),\n",
    "            'acc': epoch_acc,\n",
    "            'epoch': (epoch+1),\n",
    "            }\n",
    "\n",
    "            # check the dir\n",
    "            if not os.path.exists(SAVE_DIR):\n",
    "                os.makedirs(SAVE_DIR)\n",
    "\n",
    "            # save the state\n",
    "            torch.save(state, osp.join(SAVE_DIR, 'checkpoint_%s.pth' % (str(epoch+1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data = {\n",
    "        'Epoch': list(range(1, NUM_EPOCHS + 1)),\n",
    "        'Train Loss': training_loss,\n",
    "        'Train Accuracy': training_acc,\n",
    "        'Test Loss': testing_loss,\n",
    "        'Test Accuracy': testing_acc,\n",
    "}\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(process_data['Epoch'], process_data['Train Loss'], label='Train Loss', marker='o')\n",
    "plt.plot(process_data['Epoch'], process_data['Test Loss'], label='Test Loss', marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Testing Loss')\n",
    "plt.grid(True)\n",
    "plt.savefig('loss_plot.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(process_data['Epoch'], process_data['Train Accuracy'], label='Train Accuracy', marker='o')\n",
    "plt.plot(process_data['Epoch'], process_data['Test Accuracy'], label='Test Accuracy', marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Testing Accuracy')\n",
    "plt.grid(True)\n",
    "plt.savefig('accuracy_plot.png')\n",
    "plt.show()\n",
    "def train_and_evaluate(learning_rate, momentum, gamma, step, EVAL_INTERVAL):\n",
    "    # 在这里定义 train_and_evaluate 函数，包含你的训练和评估逻辑\n",
    "    # 返回训练好的模型\n",
    "    model = models.resnet18(weights=None)\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, NUM_CLASS)\n",
    "    return model\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    learning_rate = 0.1\n",
    "    momentum = 0.5\n",
    "    step = 5\n",
    "    gamma = 0.9\n",
    "    EVAL_INTERVAL = 1\n",
    "    results = []\n",
    "\n",
    "    SEED = 1\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "    result = train_and_evaluate(learning_rate, momentum, gamma, step, EVAL_INTERVAL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Instance inference\n",
    "---\n",
    "The task is to visualizes an image along with model prediction and class probabilities.\n",
    "\n",
    "**To do**: \n",
    "1. Calculate the prediction and the probabilities for each class.\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(model, image, target):\n",
    "    # Perform one training batch iteration.\n",
    "    output = model(image)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    loss = loss_fn(output, target)\n",
    "    return output, loss\n",
    "\n",
    "\n",
    "def test_batch(model, image, target):\n",
    "    # Perform one testing batch iteration.\n",
    "    output = model(image)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    loss = loss_fn(output, target)\n",
    "    return output, loss\n",
    "\n",
    "\n",
    "def train_and_evaluate(learning_rate, momentum, gamma, step, EVAL_INTERVAL):\n",
    "    # Define your model, optimizer, and other necessary components\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    NUM_CLASS = 10\n",
    "    BATCH_SIZE = 64\n",
    "    NUM_EPOCHS = 30\n",
    "    SAVE_DIR = './log'\n",
    "    transform_cifar10_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    transform_cifar10_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    train_set = torchvision.datasets.CIFAR10(root='../data', train=True,\n",
    "                                             download=True, transform=transform_cifar10_train)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                                                   shuffle=True, num_workers=2)\n",
    "\n",
    "    test_set = torchvision.datasets.CIFAR10(root='../data', train=False,\n",
    "                                            download=True, transform=transform_cifar10_test)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                                  shuffle=False, num_workers=2)\n",
    "    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "    model = models.resnet18(weights='imagenet')\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, NUM_CLASS)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step, gamma=gamma)\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        torch.cuda.empty_cache()\n",
    "        running_cls_loss = 0.0\n",
    "        running_cls_corrects = 0\n",
    "\n",
    "        for batch_idx, (image, target) in enumerate(train_dataloader):\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            outputs, loss = train_batch(model, image, target)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            loss_data = loss.data.item()\n",
    "            if np.isnan(loss_data):\n",
    "                raise ValueError('loss is nan while training')\n",
    "            running_cls_loss += loss.item()\n",
    "            running_cls_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        epoch_loss = running_cls_loss / len(train_set)\n",
    "        epoch_acc = running_cls_corrects.double() / len(train_set)\n",
    "        print(f'Epoch: {epoch + 1}/{NUM_EPOCHS} Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        if (epoch + 1) % EVAL_INTERVAL == 0 or (epoch + 1) == NUM_EPOCHS:\n",
    "            print('Begin test...')\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_corrects = 0\n",
    "\n",
    "            for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "                image = image.to(device)\n",
    "                target = target.to(device)\n",
    "\n",
    "                outputs, loss = test_batch(model, image, target)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                val_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "            val_loss = val_loss / len(test_set)\n",
    "            val_acc = val_corrects.double() / len(test_set)\n",
    "            print(f'Test Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "\n",
    "            if (epoch + 1) == NUM_EPOCHS:\n",
    "\n",
    "                state = {\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'acc': epoch_acc,\n",
    "                    'epoch': (epoch + 1),\n",
    "                }\n",
    "\n",
    "                if not os.path.exists(SAVE_DIR):\n",
    "                    os.makedirs(SAVE_DIR)\n",
    "\n",
    "                torch.save(state, osp.join(SAVE_DIR, 'checkpoint_%s.pth' % (str(epoch + 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, classes = next(iter(test_dataloader))\n",
    "inputs = inputs.to(device)\n",
    "input = inputs[0]\n",
    "input = input.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Write your answer here ##################\n",
    "# input: image, model\n",
    "# outputs: predict_label, probabilities\n",
    "# predict_label is the index (or label) of the class with the highest probability from the probabilities.\n",
    "###############################################################\n",
    "with torch.no_grad():\n",
    "        model.eval()\n",
    "        output = model(input.unsqueeze(0))\n",
    "        probabilities = torch.softmax(output, dim=1)\n",
    "        predict_label = torch.argmax(probabilities, dim=1).item()\n",
    "#probabilities = torch.softmax(output, dim=1)\n",
    "#predict_label = torch.argmax(probabilities, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print probabilities for each class:\n",
      "airplane: 0.0036\n",
      "automobile: 0.0053\n",
      "bird: 0.0715\n",
      "cat: 0.3815\n",
      "deer: 0.0413\n",
      "dog: 0.1183\n",
      "frog: 0.3264\n",
      "horse: 0.0252\n",
      "ship: 0.0219\n",
      "truck: 0.0050\n"
     ]
    }
   ],
   "source": [
    "predicted_class = class_names[predict_label]\n",
    "predicted_probability = probabilities[0, predict_label].item()\n",
    "image = input.cpu().numpy().transpose((1, 2, 0))\n",
    "image = (image * np.array([0.2023, 0.1994, 0.2010])) + np.array([0.4914, 0.4822, 0.4465])\n",
    "image = np.clip(image, 0, 1)\n",
    "image = Image.fromarray((image * 255).astype(np.uint8))\n",
    "plt.imshow(image)\n",
    "plt.text(17, 30, f'Predicted Class: {predicted_class}\\nProbability: {predicted_probability:.2f}', \n",
    "            color='white', backgroundcolor='black', fontsize=8)\n",
    "plt.show()\n",
    "\n",
    "# Print probabilities for each class\n",
    "print('Print probabilities for each class:')\n",
    "for i in range(len(class_names)):\n",
    "    print(f'{class_names[i]}: {probabilities[0,i].item():.4f}')\n",
    "def train_and_evaluate(learning_rate, momentum, gamma, step, EVAL_INTERVAL):\n",
    "    # 在这里定义 train_and_evaluate 函数，包含你的训练和评估逻辑\n",
    "    # 返回训练好的模型\n",
    "    model = models.resnet18(pretrained=False)\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, NUM_CLASS)\n",
    "    \n",
    "    return model\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    learning_rate = 0.1\n",
    "    momentum = 0.5\n",
    "    step = 5\n",
    "    gamma = 0.9\n",
    "    EVAL_INTERVAL = 30\n",
    "    results = []\n",
    "\n",
    "    SEED = 1\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "    result = train_and_evaluate(learning_rate, momentum, gamma, step, EVAL_INTERVAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
