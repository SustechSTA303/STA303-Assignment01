{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 01: Multi-class Classification \n",
    "In this Assignment, you will train a deep model on the CIFAR10 from the scratch using PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "SEED = 1 \n",
    "NUM_CLASS = 10\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 30\n",
    "EVAL_INTERVAL=1\n",
    "SAVE_DIR = './log'\n",
    "\n",
    "# Optimizer\n",
    "LEARNING_RATE = 1e-1\n",
    "MOMENTUM = 0.9\n",
    "STEP=5\n",
    "GAMMA=0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# cifar10 transform\n",
    "transform_cifar10_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_cifar10_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='../data', train=True,\n",
    "                                        download=True, transform=transform_cifar10_train)\n",
    "#train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,shuffle=True, num_workers=2)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='../data', train=False,\n",
    "                                       download=True, transform=transform_cifar10_test)\n",
    "#test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,shuffle=False, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class ConvNet(nn.Module):\n",
    "    #def __init__(self):\n",
    "        #super(ConvNet, self).__init__()\n",
    "        #self.conv1 = nn.Conv2d(3, 4, 3)  \n",
    "        #self.pool = nn.MaxPool2d(2, 2)\n",
    "        #self.conv2 = nn.Conv2d(4, 8, 3)  \n",
    "        #self.fc1 = nn.Linear(8 * 6 * 6, 32)\n",
    "        #self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    #def forward(self, x):\n",
    "        #x = self.pool(torch.relu(self.conv1(x)))\n",
    "        #x = self.pool(torch.relu(self.conv2(x)))\n",
    "        #x = x.view(-1, 8 * 6 * 6)\n",
    "        #x = torch.relu(self.fc1(x))\n",
    "        #x = self.fc2(x)\n",
    "        #return x\n",
    "        \n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "    #def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        #self.fc1 = nn.Linear(4096, num_classes)\n",
    "        #self.fc1 = nn.Linear(in_features=6488, out_features=512)\n",
    "        #self.fc1 = nn.Linear(8 * 6 * 6, 32)\n",
    "        self.fc1 = nn.Linear(4096, 10)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.drop1 = nn.Dropout(p=0.5)\n",
    "        #self.fc2 = nn.Linear(in_features=512, out_features=num_classes)\n",
    "        #self.fc2 = nn.Linear(32, 10)\n",
    "        self.fc2 = nn.Linear(10, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1, 64*8*8)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.drop1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = ConvNet()\n",
    "model = MyModel(num_classes=10)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: per batch training/testing\n",
    "---\n",
    "\n",
    "Please denfine two function named ``train_batch`` and ``test_batch``. These functions are essential for training and evaluating machine learning models using batched data from dataloaders.\n",
    "\n",
    "**To do**: \n",
    "1. Define the loss function i.e [nn.CrossEntropyLoss()](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html).\n",
    "2. Take the image as the input and generate the output using the pre-defined SimpleNet.\n",
    "3. Calculate the loss between the output and the corresponding label using the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Write your answer here ##################\n",
    "# Define the loss function\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
    "        return torch.mean(focal_loss)\n",
    "\n",
    "loss_functions = {\n",
    "    'MAE': nn.L1Loss(),\n",
    "    'CE': nn.CrossEntropyLoss(),\n",
    "    'Focal (gamma=0.5)': FocalLoss(gamma=0.5),\n",
    "    'Focal (gamma=2)': FocalLoss(gamma=2)\n",
    "}\n",
    "\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_loader):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        # Convert labels to one-hot encoding\n",
    "        labels_onehot = F.one_hot(labels, num_classes=NUM_CLASS).float()\n",
    "        loss = criterion(outputs, labels_onehot)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(model, criterion, test_loader):\n",
    "    # TODO: Implement the evaluation loop\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels = data\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Function: MAE, Epoch: 1, Train Loss: 0.13510192747768537\n",
      "Loss Function: MAE, Epoch: 2, Train Loss: 0.10011785128689787\n",
      "Loss Function: MAE, Epoch: 3, Train Loss: 0.10011628742718026\n",
      "Loss Function: MAE, Epoch: 4, Train Loss: 0.10010859231128717\n",
      "Loss Function: MAE, Epoch: 5, Train Loss: 0.10011277237282995\n",
      "Loss Function: MAE, Epoch: 6, Train Loss: 0.10010829091529407\n",
      "Loss Function: MAE, Epoch: 7, Train Loss: 0.10011417942736155\n",
      "Loss Function: MAE, Epoch: 8, Train Loss: 0.10010709522096702\n",
      "Loss Function: MAE, Epoch: 9, Train Loss: 0.10010621763403764\n",
      "Loss Function: MAE, Epoch: 10, Train Loss: 0.10010692006562982\n",
      "Loss Function: MAE, Test Accuracy: 10.0\n",
      "Loss Function: CE, Epoch: 1, Train Loss: 2.1763560021929726\n",
      "Loss Function: CE, Epoch: 2, Train Loss: 2.0523084191715015\n",
      "Loss Function: CE, Epoch: 3, Train Loss: 1.9731995656972041\n",
      "Loss Function: CE, Epoch: 4, Train Loss: 1.937276638377353\n",
      "Loss Function: CE, Epoch: 5, Train Loss: 1.9109439935220782\n",
      "Loss Function: CE, Epoch: 6, Train Loss: 1.8999674054972655\n",
      "Loss Function: CE, Epoch: 7, Train Loss: 1.8823570695984395\n",
      "Loss Function: CE, Epoch: 8, Train Loss: 1.8766234930214065\n",
      "Loss Function: CE, Epoch: 9, Train Loss: 1.8660322671656109\n",
      "Loss Function: CE, Epoch: 10, Train Loss: 1.8611362056659007\n",
      "Loss Function: CE, Test Accuracy: 43.45\n",
      "Loss Function: Focal (gamma=0.5), Epoch: 1, Train Loss: 1.950223670896057\n",
      "Loss Function: Focal (gamma=0.5), Epoch: 2, Train Loss: 1.7229221156795922\n",
      "Loss Function: Focal (gamma=0.5), Epoch: 3, Train Loss: 1.6385173745777295\n",
      "Loss Function: Focal (gamma=0.5), Epoch: 4, Train Loss: 1.5835970006025661\n",
      "Loss Function: Focal (gamma=0.5), Epoch: 5, Train Loss: 1.5579353848381725\n",
      "Loss Function: Focal (gamma=0.5), Epoch: 6, Train Loss: 1.5407098793922482\n",
      "Loss Function: Focal (gamma=0.5), Epoch: 7, Train Loss: 1.516816036780472\n",
      "Loss Function: Focal (gamma=0.5), Epoch: 8, Train Loss: 1.4995330187975597\n",
      "Loss Function: Focal (gamma=0.5), Epoch: 9, Train Loss: 1.4841164560878979\n",
      "Loss Function: Focal (gamma=0.5), Epoch: 10, Train Loss: 1.476701764804323\n",
      "Loss Function: Focal (gamma=0.5), Test Accuracy: 52.88\n",
      "Loss Function: Focal (gamma=2), Epoch: 1, Train Loss: 1.7823109492621458\n",
      "Loss Function: Focal (gamma=2), Epoch: 2, Train Loss: 1.657116194210394\n",
      "Loss Function: Focal (gamma=2), Epoch: 3, Train Loss: 1.6088312547225172\n",
      "Loss Function: Focal (gamma=2), Epoch: 4, Train Loss: 1.592690136121667\n",
      "Loss Function: Focal (gamma=2), Epoch: 5, Train Loss: 1.581371868967705\n",
      "Loss Function: Focal (gamma=2), Epoch: 6, Train Loss: 1.5356973366969078\n",
      "Loss Function: Focal (gamma=2), Epoch: 7, Train Loss: 1.435343150287638\n",
      "Loss Function: Focal (gamma=2), Epoch: 8, Train Loss: 1.413593474251535\n",
      "Loss Function: Focal (gamma=2), Epoch: 9, Train Loss: 1.4013512924199214\n",
      "Loss Function: Focal (gamma=2), Epoch: 10, Train Loss: 1.3908118515673196\n",
      "Loss Function: Focal (gamma=2), Test Accuracy: 40.69\n"
     ]
    }
   ],
   "source": [
    "for loss_name, loss_function in loss_functions.items():\n",
    "    # Instantiate the model\n",
    "    # Define the number of classes for the problem\n",
    "    num_classes = 10 # change this to the appropriate value for your problem\n",
    "    model = MyModel(num_classes)\n",
    "    #model = MyModel()\n",
    "\n",
    "    # Set up the optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the model\n",
    "    num_epochs = 10 # adjust as needed\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train(model, loss_function, optimizer, train_loader)\n",
    "        print(f\"Loss Function: {loss_name}, Epoch: {epoch+1}, Train Loss: {train_loss}\")\n",
    "\n",
    "    # Evaluate the model\n",
    "    test_accuracy = evaluate(model, loss_function, test_loader)\n",
    "\n",
    "    print(f\"Loss Function: {loss_name}, Test Accuracy: {test_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
