{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 01: Multi-class Classification \n",
    "In this Assignment, you will train a deep model on the CIFAR10 from the scratch using PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "SEED = 1 \n",
    "NUM_CLASS = 10\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 100\n",
    "EVAL_INTERVAL=1\n",
    "SAVE_DIR = './log'\n",
    "\n",
    "# Optimizer\n",
    "LEARNING_RATE = 1e-3\n",
    "MOMENTUM = 0.9\n",
    "STEP=5\n",
    "GAMMA=0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# cifar10 transform\n",
    "transform_cifar10_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_cifar10_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='../data', train=True,\n",
    "                                        download=True, transform=transform_cifar10_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='../data', train=False,\n",
    "                                       download=True, transform=transform_cifar10_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 4, 3)  \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3)  \n",
    "        self.fc1 = nn.Linear(8 * 6 * 6, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 8 * 6 * 6)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=288, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvNet()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: per batch training/testing\n",
    "---\n",
    "\n",
    "Please denfine two function named ``train_batch`` and ``test_batch``. These functions are essential for training and evaluating machine learning models using batched data from dataloaders.\n",
    "\n",
    "**To do**: \n",
    "1. Define the loss function i.e [nn.CrossEntropyLoss()](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html).\n",
    "2. Take the image as the input and generate the output using the pre-defined SimpleNet.\n",
    "3. Calculate the loss between the output and the corresponding label using the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def one_hot_encoding(target, num_classes):\n",
    "    return F.one_hot(target, num_classes=num_classes).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Focal Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=1.0):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        \"\"\"\n",
    "        y_pred: raw scores (logits) for each class. [batch_size, num_classes]\n",
    "        y_true: ground truth labels. [batch_size]\n",
    "        \"\"\"\n",
    "        # Convert y_true labels into one-hot encoding\n",
    "        y_true_onehot = torch.zeros(y_pred.size(), device=y_pred.device).scatter_(1, y_true.unsqueeze(1).long(), 1)\n",
    "        \n",
    "        # Calculate softmax over y_pred for calculating probabilities\n",
    "        probs = F.softmax(y_pred, dim=1)\n",
    "        \n",
    "        # Calculate focal loss\n",
    "        focal_loss = -self.alpha * (y_true_onehot * torch.log(probs) * (1 - probs) ** self.gamma).sum(dim=1).mean()\n",
    "        \n",
    "        return focal_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Write your answer here ##################\n",
    "# Define the loss function\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = FocalLoss()\n",
    "#criterion = nn.L1Loss()\n",
    "lossfunction = 'epo100FC201'\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def train_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one training batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to train.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated by the defined loss function loss_fn().\n",
    "    \"\"\"\n",
    "    \n",
    "    ##################### Write your answer here ##################\n",
    "    output = model(image)\n",
    "    loss = criterion(output, target)\n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def test_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one testing batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to evaluate.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated for the batch.\n",
    "    \"\"\"\n",
    "\n",
    "    ##################### Write your answer here ##################\n",
    "    output = model(image)\n",
    "    loss = criterion(output, target)\n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100 Train Loss: 0.0139 Acc: 0.1611\n",
      "Begin test......\n",
      "Test Loss: 0.0130 Acc: 0.2127\n",
      "Epoch: 2/100 Train Loss: 0.0124 Acc: 0.2502\n",
      "Begin test......\n",
      "Test Loss: 0.0117 Acc: 0.2910\n",
      "Epoch: 3/100 Train Loss: 0.0116 Acc: 0.2886\n",
      "Begin test......\n",
      "Test Loss: 0.0109 Acc: 0.3346\n",
      "Epoch: 4/100 Train Loss: 0.0109 Acc: 0.3208\n",
      "Begin test......\n",
      "Test Loss: 0.0103 Acc: 0.3598\n",
      "Epoch: 5/100 Train Loss: 0.0104 Acc: 0.3433\n",
      "Begin test......\n",
      "Test Loss: 0.0097 Acc: 0.3797\n",
      "Epoch: 6/100 Train Loss: 0.0100 Acc: 0.3548\n",
      "Begin test......\n",
      "Test Loss: 0.0095 Acc: 0.3913\n",
      "Epoch: 7/100 Train Loss: 0.0098 Acc: 0.3618\n",
      "Begin test......\n",
      "Test Loss: 0.0094 Acc: 0.3999\n",
      "Epoch: 8/100 Train Loss: 0.0097 Acc: 0.3702\n",
      "Begin test......\n",
      "Test Loss: 0.0091 Acc: 0.4034\n",
      "Epoch: 9/100 Train Loss: 0.0095 Acc: 0.3771\n",
      "Begin test......\n",
      "Test Loss: 0.0089 Acc: 0.4213\n",
      "Epoch: 10/100 Train Loss: 0.0093 Acc: 0.3816\n",
      "Begin test......\n",
      "Test Loss: 0.0087 Acc: 0.4247\n",
      "Epoch: 11/100 Train Loss: 0.0092 Acc: 0.3887\n",
      "Begin test......\n",
      "Test Loss: 0.0086 Acc: 0.4278\n",
      "Epoch: 12/100 Train Loss: 0.0091 Acc: 0.3916\n",
      "Begin test......\n",
      "Test Loss: 0.0086 Acc: 0.4331\n",
      "Epoch: 13/100 Train Loss: 0.0091 Acc: 0.3979\n",
      "Begin test......\n",
      "Test Loss: 0.0085 Acc: 0.4366\n",
      "Epoch: 14/100 Train Loss: 0.0090 Acc: 0.3987\n",
      "Begin test......\n",
      "Test Loss: 0.0084 Acc: 0.4430\n",
      "Epoch: 15/100 Train Loss: 0.0090 Acc: 0.4029\n",
      "Begin test......\n",
      "Test Loss: 0.0083 Acc: 0.4456\n",
      "Epoch: 16/100 Train Loss: 0.0089 Acc: 0.4063\n",
      "Begin test......\n",
      "Test Loss: 0.0083 Acc: 0.4432\n",
      "Epoch: 17/100 Train Loss: 0.0088 Acc: 0.4071\n",
      "Begin test......\n",
      "Test Loss: 0.0083 Acc: 0.4491\n",
      "Epoch: 18/100 Train Loss: 0.0088 Acc: 0.4093\n",
      "Begin test......\n",
      "Test Loss: 0.0083 Acc: 0.4470\n",
      "Epoch: 19/100 Train Loss: 0.0088 Acc: 0.4111\n",
      "Begin test......\n",
      "Test Loss: 0.0082 Acc: 0.4510\n",
      "Epoch: 20/100 Train Loss: 0.0088 Acc: 0.4110\n",
      "Begin test......\n",
      "Test Loss: 0.0082 Acc: 0.4529\n",
      "Epoch: 21/100 Train Loss: 0.0087 Acc: 0.4136\n",
      "Begin test......\n",
      "Test Loss: 0.0082 Acc: 0.4524\n",
      "Epoch: 22/100 Train Loss: 0.0087 Acc: 0.4130\n",
      "Begin test......\n",
      "Test Loss: 0.0081 Acc: 0.4541\n",
      "Epoch: 23/100 Train Loss: 0.0087 Acc: 0.4161\n",
      "Begin test......\n",
      "Test Loss: 0.0081 Acc: 0.4562\n",
      "Epoch: 24/100 Train Loss: 0.0087 Acc: 0.4160\n",
      "Begin test......\n",
      "Test Loss: 0.0081 Acc: 0.4567\n",
      "Epoch: 25/100 Train Loss: 0.0087 Acc: 0.4158\n",
      "Begin test......\n",
      "Test Loss: 0.0081 Acc: 0.4570\n",
      "Epoch: 26/100 Train Loss: 0.0087 Acc: 0.4179\n",
      "Begin test......\n",
      "Test Loss: 0.0081 Acc: 0.4568\n",
      "Epoch: 27/100 Train Loss: 0.0087 Acc: 0.4168\n",
      "Begin test......\n",
      "Test Loss: 0.0081 Acc: 0.4542\n",
      "Epoch: 28/100 Train Loss: 0.0087 Acc: 0.4176\n",
      "Begin test......\n",
      "Test Loss: 0.0081 Acc: 0.4582\n",
      "Epoch: 29/100 Train Loss: 0.0087 Acc: 0.4156\n",
      "Begin test......\n",
      "Test Loss: 0.0081 Acc: 0.4573\n",
      "Epoch: 30/100 Train Loss: 0.0086 Acc: 0.4172\n",
      "Begin test......\n",
      "Test Loss: 0.0081 Acc: 0.4587\n",
      "Epoch: 31/100 Train Loss: 0.0087 Acc: 0.4169\n",
      "Begin test......\n",
      "Test Loss: 0.0081 Acc: 0.4598\n",
      "Epoch: 32/100 Train Loss: 0.0086 Acc: 0.4182\n",
      "Begin test......\n",
      "Test Loss: 0.0081 Acc: 0.4597\n",
      "Epoch: 33/100 Train Loss: 0.0086 Acc: 0.4192\n",
      "Begin test......\n",
      "Test Loss: 0.0081 Acc: 0.4608\n",
      "Epoch: 34/100 Train Loss: 0.0086 Acc: 0.4202\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4597\n",
      "Epoch: 35/100 Train Loss: 0.0086 Acc: 0.4193\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4606\n",
      "Epoch: 36/100 Train Loss: 0.0086 Acc: 0.4195\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4603\n",
      "Epoch: 37/100 Train Loss: 0.0086 Acc: 0.4198\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4602\n",
      "Epoch: 38/100 Train Loss: 0.0086 Acc: 0.4188\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4608\n",
      "Epoch: 39/100 Train Loss: 0.0086 Acc: 0.4181\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4603\n",
      "Epoch: 40/100 Train Loss: 0.0086 Acc: 0.4233\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4612\n",
      "Epoch: 41/100 Train Loss: 0.0086 Acc: 0.4216\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4606\n",
      "Epoch: 42/100 Train Loss: 0.0087 Acc: 0.4163\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4603\n",
      "Epoch: 43/100 Train Loss: 0.0087 Acc: 0.4209\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4600\n",
      "Epoch: 44/100 Train Loss: 0.0086 Acc: 0.4194\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4602\n",
      "Epoch: 45/100 Train Loss: 0.0086 Acc: 0.4203\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4604\n",
      "Epoch: 46/100 Train Loss: 0.0086 Acc: 0.4196\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4604\n",
      "Epoch: 47/100 Train Loss: 0.0086 Acc: 0.4228\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4599\n",
      "Epoch: 48/100 Train Loss: 0.0086 Acc: 0.4199\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4600\n",
      "Epoch: 49/100 Train Loss: 0.0086 Acc: 0.4218\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4607\n",
      "Epoch: 50/100 Train Loss: 0.0086 Acc: 0.4216\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4607\n",
      "Epoch: 51/100 Train Loss: 0.0086 Acc: 0.4204\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4603\n",
      "Epoch: 52/100 Train Loss: 0.0086 Acc: 0.4185\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4603\n",
      "Epoch: 53/100 Train Loss: 0.0086 Acc: 0.4210\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4604\n",
      "Epoch: 54/100 Train Loss: 0.0086 Acc: 0.4210\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4603\n",
      "Epoch: 55/100 Train Loss: 0.0086 Acc: 0.4227\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4600\n",
      "Epoch: 56/100 Train Loss: 0.0086 Acc: 0.4206\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4599\n",
      "Epoch: 57/100 Train Loss: 0.0086 Acc: 0.4194\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4604\n",
      "Epoch: 58/100 Train Loss: 0.0086 Acc: 0.4203\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4607\n",
      "Epoch: 59/100 Train Loss: 0.0086 Acc: 0.4218\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4608\n",
      "Epoch: 60/100 Train Loss: 0.0086 Acc: 0.4173\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4608\n",
      "Epoch: 61/100 Train Loss: 0.0086 Acc: 0.4195\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4607\n",
      "Epoch: 62/100 Train Loss: 0.0086 Acc: 0.4206\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4608\n",
      "Epoch: 63/100 Train Loss: 0.0086 Acc: 0.4203\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4606\n",
      "Epoch: 64/100 Train Loss: 0.0086 Acc: 0.4215\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4604\n",
      "Epoch: 65/100 Train Loss: 0.0086 Acc: 0.4217\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4606\n",
      "Epoch: 66/100 Train Loss: 0.0086 Acc: 0.4188\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4606\n",
      "Epoch: 67/100 Train Loss: 0.0086 Acc: 0.4198\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4606\n",
      "Epoch: 68/100 Train Loss: 0.0086 Acc: 0.4191\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4606\n",
      "Epoch: 69/100 Train Loss: 0.0086 Acc: 0.4212\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4604\n",
      "Epoch: 70/100 Train Loss: 0.0086 Acc: 0.4181\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4604\n",
      "Epoch: 71/100 Train Loss: 0.0086 Acc: 0.4226\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4604\n",
      "Epoch: 72/100 Train Loss: 0.0086 Acc: 0.4200\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4606\n",
      "Epoch: 73/100 Train Loss: 0.0086 Acc: 0.4225\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4604\n",
      "Epoch: 74/100 Train Loss: 0.0086 Acc: 0.4197\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4607\n",
      "Epoch: 75/100 Train Loss: 0.0086 Acc: 0.4178\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4607\n",
      "Epoch: 76/100 Train Loss: 0.0086 Acc: 0.4213\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4607\n",
      "Epoch: 77/100 Train Loss: 0.0086 Acc: 0.4215\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4607\n",
      "Epoch: 78/100 Train Loss: 0.0086 Acc: 0.4198\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4607\n",
      "Epoch: 79/100 Train Loss: 0.0086 Acc: 0.4212\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4607\n",
      "Epoch: 80/100 Train Loss: 0.0086 Acc: 0.4223\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4607\n",
      "Epoch: 81/100 Train Loss: 0.0086 Acc: 0.4207\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4607\n",
      "Epoch: 82/100 Train Loss: 0.0086 Acc: 0.4185\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4606\n",
      "Epoch: 83/100 Train Loss: 0.0086 Acc: 0.4213\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4607\n",
      "Epoch: 84/100 Train Loss: 0.0086 Acc: 0.4192\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4607\n",
      "Epoch: 85/100 Train Loss: 0.0086 Acc: 0.4204\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4606\n",
      "Epoch: 86/100 Train Loss: 0.0086 Acc: 0.4187\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4606\n",
      "Epoch: 87/100 Train Loss: 0.0086 Acc: 0.4181\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4606\n",
      "Epoch: 88/100 Train Loss: 0.0086 Acc: 0.4199\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4606\n",
      "Epoch: 89/100 Train Loss: 0.0086 Acc: 0.4217\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4607\n",
      "Epoch: 90/100 Train Loss: 0.0086 Acc: 0.4201\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4607\n",
      "Epoch: 91/100 Train Loss: 0.0086 Acc: 0.4187\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4606\n",
      "Epoch: 92/100 Train Loss: 0.0086 Acc: 0.4215\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4607\n",
      "Epoch: 93/100 Train Loss: 0.0086 Acc: 0.4196\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4606\n",
      "Epoch: 94/100 Train Loss: 0.0086 Acc: 0.4203\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4607\n",
      "Epoch: 95/100 Train Loss: 0.0086 Acc: 0.4223\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4606\n",
      "Epoch: 96/100 Train Loss: 0.0086 Acc: 0.4220\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4606\n",
      "Epoch: 97/100 Train Loss: 0.0086 Acc: 0.4196\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4606\n",
      "Epoch: 98/100 Train Loss: 0.0086 Acc: 0.4180\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4606\n",
      "Epoch: 99/100 Train Loss: 0.0086 Acc: 0.4246\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4606\n",
      "Epoch: 100/100 Train Loss: 0.0086 Acc: 0.4214\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.4606\n"
     ]
    }
   ],
   "source": [
    "training_loss = []\n",
    "training_acc = []\n",
    "testing_loss = []\n",
    "testing_acc = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    ##########################\n",
    "    ### Training\n",
    "    ##########################\n",
    "\n",
    "    running_cls_loss = 0.0\n",
    "    running_cls_corrects = 0\n",
    "\n",
    "######################################################################################\n",
    "    for batch_idx, (image, target) in enumerate(train_dataloader):   #CE-loss/FCLoss\n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # train model\n",
    "        outputs, loss = train_batch(model, image, target)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        \n",
    "        loss_data = loss.data.item()\n",
    "        if np.isnan(loss_data):\n",
    "            raise ValueError('loss is nan while training')\n",
    "        running_cls_loss += loss.item()\n",
    "        running_cls_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()                                         #CE-Loss/FCLoss\n",
    "########################################################################################\n",
    "#     for batch_idx, (image, target) in enumerate(train_dataloader):   #L1-loss\n",
    "\n",
    "#         image = image.to(device)\n",
    "#         target = target.to(device)\n",
    "#         #######################\n",
    "#         # 为使用L1loss function：\n",
    "#         target_one_hot = one_hot_encoding(target, 10)  # 转换成 one-hot 编码\n",
    "\n",
    "\n",
    "#         # train model\n",
    "#         outputs, loss = train_batch(model, image, target_one_hot)  # 使用 one-hot 编码后的目标\n",
    "#         _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        \n",
    "#         loss_data = loss.data.item()\n",
    "#         if np.isnan(loss_data):\n",
    "#             raise ValueError('loss is nan while training')\n",
    "#         running_cls_loss += loss.item()\n",
    "#         running_cls_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()                                       #L1-Loss\n",
    "########################################################################################\n",
    "\n",
    "    epoch_loss = running_cls_loss / len(train_set)\n",
    "    epoch_acc = running_cls_corrects.double() / len(train_set)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{NUM_EPOCHS} Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "    training_loss.append(epoch_loss)\n",
    "    training_acc.append(epoch_acc.cpu().detach().numpy())\n",
    "\n",
    "    # change learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "    ##########################\n",
    "    ### Testing\n",
    "    ##########################\n",
    "    # # eval model during training or in the last epoch\n",
    "    if (epoch + 1) % EVAL_INTERVAL == 0 or (epoch +1) == NUM_EPOCHS:\n",
    "        print('Begin test......')\n",
    "        model.eval()\n",
    "    \n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "################################################################################\n",
    "        for batch_idx, (image, target) in enumerate(test_dataloader):  #CE-Loss/FCLoss\n",
    "\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # test model\n",
    "            outputs, loss = test_batch(model, image, target)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            val_corrects += torch.sum(preds == target.data)           #CE-Loss/FCLoss\n",
    "#################################################################################\n",
    "#         for batch_idx, (image, target) in enumerate(test_dataloader):  #L1-Loss\n",
    "#             image = image.to(device)\n",
    "#             target = target.to(device)\n",
    "\n",
    "#             # test model\n",
    "#             ##################\n",
    "#             target_one_hot = one_hot_encoding(target, 10)  # 转换成 one-hot 编码\n",
    "#             outputs, loss = test_batch(model, image, target_one_hot)  # 使用 one-hot 编码后的目标\n",
    "#             #######################\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "#             val_loss += loss.item()\n",
    "#             val_corrects += torch.sum(preds == target.data)  #L1-Loss\n",
    "####################################################################################            \n",
    "\n",
    "        val_loss = val_loss / len(test_set)\n",
    "        val_acc = val_corrects.double() / len(test_set)\n",
    "        print(f'Test Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "        testing_loss.append(val_loss)\n",
    "        testing_acc.append(val_acc.cpu().detach().numpy())\n",
    "\n",
    "        # save the model in last epoch\n",
    "        if (epoch +1) == NUM_EPOCHS:\n",
    "            \n",
    "            state = {\n",
    "            'state_dict': model.state_dict(),\n",
    "            'acc': epoch_acc,\n",
    "            'epoch': (epoch+1),\n",
    "            }\n",
    "\n",
    "            # check the dir\n",
    "            if not os.path.exists(SAVE_DIR):\n",
    "                os.makedirs(SAVE_DIR)\n",
    "\n",
    "            # save the state\n",
    "            torch.save(state, osp.join(SAVE_DIR, 'checkpoint_%s.pth' % (str(epoch+1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file1 = './dataForEpo/{0}_trainloss.txt'.format(lossfunction)\n",
    "file2 = './dataForEpo/{0}_trainacc.txt'.format(lossfunction)\n",
    "file3 = './dataForEpo/{0}_testloss.txt'.format(lossfunction)\n",
    "file4 = './dataForEpo/{0}_testacc.txt'.format(lossfunction)\n",
    "\n",
    "with open(file1, 'w', encoding='utf-8') as f:\n",
    "    for i in training_loss:\n",
    "        f.write(str(i)+'\\n')\n",
    "with open(file2, 'w', encoding='utf-8') as f:\n",
    "    for i in training_acc:\n",
    "        f.write(str(i)+'\\n')\n",
    "with open(file3, 'w', encoding='utf-8') as f:\n",
    "    for i in testing_loss:\n",
    "        f.write(str(i)+'\\n')\n",
    "with open(file4, 'w', encoding='utf-8') as f:\n",
    "    for i in testing_acc:\n",
    "        f.write(str(i)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Instance inference\n",
    "---\n",
    "The task is to visualizes an image along with model prediction and class probabilities.\n",
    "\n",
    "**To do**: \n",
    "1. Calculate the prediction and the probabilities for each class.\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, classes = next(iter(test_dataloader))\n",
    "input = inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1539, -2.0562,  1.2645,  2.2131,  0.2431,  2.2197,  1.4304, -0.6267,\n",
      "        -0.9770, -2.0736], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(5, device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################### Write your answer here ##################\n",
    "# input: image, model\n",
    "# outputs: predict_label, probabilities\n",
    "# predict_label is the index (or label) of the class with the highest probability from the probabilities.\n",
    "###############################################################\n",
    "\n",
    "input = input.to(device)\n",
    "probabilities = model(input)[0]\n",
    "predict_label = torch.argmax(probabilities)\n",
    "print(probabilities)\n",
    "predict_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print probabilities for each class:\n",
      "airplane: -1.1539\n",
      "automobile: -2.0562\n",
      "bird: 1.2645\n",
      "cat: 2.2131\n",
      "deer: 0.2431\n",
      "dog: 2.2197\n",
      "frog: 1.4304\n",
      "horse: -0.6267\n",
      "ship: -0.9770\n",
      "truck: -2.0736\n"
     ]
    }
   ],
   "source": [
    "predicted_class = class_names[predict_label.item()]\n",
    "predicted_probability = probabilities[predict_label].item()\n",
    "\n",
    "image = input.cpu().numpy().transpose((1, 2, 0))\n",
    "plt.imshow(image)\n",
    "plt.text(17, 30, f'Predicted Class: {predicted_class}\\nProbability: {predicted_probability:.2f}', \n",
    "            color='white', backgroundcolor='black', fontsize=8)\n",
    "plt.show()\n",
    "\n",
    "# Print probabilities for each class\n",
    "print('Print probabilities for each class:')\n",
    "for i in range(len(class_names)):\n",
    "    print(f'{class_names[i]}: {probabilities[i].item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
