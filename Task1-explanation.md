# **Task1：**
## **MAE(L1) loss：**
我们观察到当我们使用MAE(L1) loss作为损失函数时，模型在测试集上的表现始终一致且较差，准确度仅为0.105，说明MAE(L1) loss在此问题上的表现较差。接下来，我们分析其原因。根据MAE(L1) loss的公式：$loss(x, y) = \frac {1}{n} \sum_{i=1}^{n} (y_i - f(x_i))^2$，我们可知：1.由于它包含了绝对值运算，所以L1 loss是一个非光滑的函数，因此，在损失函数的优化过程中，可能导致了一些数值的不稳定，使模型难以收敛。2.由于我们是多分类问题，所以这里的$y_i$和$f(x_i)$都是0-9的整数，可能会出现一些较大的异常值，在多分类问题中，异常值可能会对模型的训练产生较大的影响。3.根据MAE(L1) loss和多分类问题的性质，L1 loss没有考虑类别之间的相对关系，它只关心模型的输出与真实值之间的绝对差异，而在多分类问题中，通常需要考虑类别之间的相对重要性。
## **CE loss**
我们观察到随着训练次数的增加，当我们使用CE loss作为损失函数时，模型的准确度逐渐上升，且较快。接下来，我们分析其原因：根据CE loss的公式：$L = \frac {1}{N} \sum_{i} L_i = - \frac {1}{N} \sum_{i} \sum_{c=1}{M} y_{ic} log(p_{ic})$，其中M为类别的数量，$y_{ic}$代表如果样本的真实类别等于c取1，否则取0，$p_{ic}$代表样本i属于类别c的预测概率，我们可知：1.CE loss是基于概率的损失函数，它衡量了模型输出的预测概率与实际类别的概率之间的差异。这使得它能够直接反映模型对各个类别的置信度。2.CE loss是一个连续、光滑的函数，相比于L1 loss，它在优化过程中避免了数值上的不稳定性。3.CE loss计算公式是可导的，所以避免了梯度消失的问题。
## **Focal loss**
### **假设每个类别的权重一致**
首先，我们先假设在这个多分类任务中，每个类别的权重是一致的。
我们发现，当我们使用focal loss作为损失函数时，无论$\gamma$的选取，随着训练次数的增加，模型的准确度都逐渐上升。但当$\gamma = 2$时最终的准确度不如$\gamma = 0.5$的时候，接下来，我们分析其原因：根据focal loss的公式：$FL(p_t) = - \alpha_t (1 - p_t)^\gamma log(p_t)$，我们可知，$\gamma$的选取影响的是模型对难以分类的样本的关注度，较大的$\gamma$值会使得模型更加关注难以分类的样本，从而减轻容易分类样本的影响，但过大的$\gamma$值可能会导致模型过于关注难以分类的样本，而影响了对容易分类样本的学习，从而使得模型在训练过程中过于集中在难以分类的样本上。所以在我们的问题中$\gamma = 2$已经过大，使模型过度关注难以分类的样本，使模型的准确度降低。
### **假设每个类别的权重不一致，我们通过取倒数确定$\alpha$**
*($\alpha$只在training中设置就行了，虽然这样会使testing中loss在计算时的$\alpha$为training中最后一次计算出来的$\alpha$，但因为在testing过程中，我们关注的是accuracy，不是loss，所以并不影响accuracy的结果)*
首先，我们先假设在这个多分类任务中，每个类别的权重不一致，这显然是更符合实际的，然后我们通过取倒数去确定$\alpha$，具体操作为：在每一个batch中，用实际的类别数目的倒数作为$\alpha$。我们再将这样训练出来的模型与之前我们假设每个类别权重相同训练出来的模型在同一个测试集上测试，得到它们的准确度，画出散点图。我们发现当$\gamma = 0.5$时，不取倒数的准确度较高，当$\gamma = 2$时，取倒数的准确度较高，总体上，$\gamma = 0.5$比$\gamma = 2$准确度更高，这一点我们在上文已经解释过了，不再重复解释，这里我们主要分析另外两个的原因。**1.对于当$\gamma = 0.5$时，$\alpha$不取倒数的准确度较高的思考：**
在这个问题的数据集中，当我们$\gamma = 0.5$时，恰好是较好的一个选取。此时，当我们再对$\alpha$取倒数，我们会降低模型对难以分类样本的关注，抵消了部分$\gamma$的影响，使整个模型的准确度降低了。
**2.对于当$\gamma = 2$时，$\alpha$取倒数的准确度较高的思考：**
我们知道$\gamma$选择的越大，会使模型越关注哪些难以分类的样本，但对于一个不平衡的数据集，我们$\alpha$的选取则是为了对一个数据量较少的类别在loss上赋予较高的权重，所以在这个问题中，我们的$\alpha$中和了部分$\gamma$选择的较大而产生的影响，使模型更加准确。
