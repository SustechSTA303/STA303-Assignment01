{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Imports | Hyperparameters | Device | Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "## Basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchmetrics\n",
    "import random\n",
    "\n",
    "## Hyperparameters \n",
    "# random seed\n",
    "SEED = 1 \n",
    "NUM_CLASS = 10\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "setup_seed(SEED)\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 50\n",
    "EVAL_INTERVAL = 1\n",
    "\n",
    "# Optimizer\n",
    "LEARNING_RATE = 1e-1\n",
    "MOMENTUM = 0.9\n",
    "STEP = 5\n",
    "GAMMA = 0.5\n",
    "\n",
    "## Device\n",
    "device = torch.device(\"cuda:5\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "## Dataset\n",
    "# cifar10 transform\n",
    "transform_cifar10_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_cifar10_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='../../data', train=True,\n",
    "                                        download=True, transform=transform_cifar10_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='../../data', train=False,\n",
    "                                       download=True, transform=transform_cifar10_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model | Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model def\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 4, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3)\n",
    "        self.fc1 = nn.Linear(8 * 6 * 6, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 8 * 6 * 6)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "## Init model\n",
    "model = ConvNet()\n",
    "model.to(device)\n",
    "\n",
    "## Init Optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### Modify here ###########################\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "###############################################################\n",
    "\n",
    "## Define the batch train\n",
    "def train_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one training batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to train.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated by the defined loss function loss_fn().\n",
    "    \"\"\"\n",
    "    \n",
    "    ####################### Modify here ###########################\n",
    "    output = model(image)\n",
    "    loss = criterion(output, target)\n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss\n",
    "\n",
    "\n",
    "def test_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one testing batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to evaluate.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated for the batch.\n",
    "    \"\"\"\n",
    "\n",
    "    ####################### Modify here ###########################\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        loss = criterion(output, target)\n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50\n",
      "Begin test......\n",
      "Test Loss: 0.0134 Acc: 0.3708 Precision: 0.4317 Recall: 0.3708 f1score_micro: 0.3708 f1score_macro: 0.3542\n",
      "Epoch: 2/50\n",
      "Begin test......\n",
      "Test Loss: 0.0133 Acc: 0.3789 Precision: 0.4226 Recall: 0.3789 f1score_micro: 0.3789 f1score_macro: 0.3546\n",
      "Epoch: 3/50\n",
      "Begin test......\n",
      "Test Loss: 0.0131 Acc: 0.3982 Precision: 0.3968 Recall: 0.3982 f1score_micro: 0.3982 f1score_macro: 0.3719\n",
      "Epoch: 4/50\n",
      "Begin test......\n",
      "Test Loss: 0.0129 Acc: 0.4036 Precision: 0.4304 Recall: 0.4036 f1score_micro: 0.4036 f1score_macro: 0.3790\n",
      "Epoch: 5/50\n",
      "Begin test......\n",
      "Test Loss: 0.0127 Acc: 0.4112 Precision: 0.4339 Recall: 0.4112 f1score_micro: 0.4112 f1score_macro: 0.3841\n",
      "Epoch: 6/50\n",
      "Begin test......\n",
      "Test Loss: 0.0115 Acc: 0.4779 Precision: 0.4763 Recall: 0.4779 f1score_micro: 0.4779 f1score_macro: 0.4596\n",
      "Epoch: 7/50\n",
      "Begin test......\n",
      "Test Loss: 0.0116 Acc: 0.4719 Precision: 0.4823 Recall: 0.4719 f1score_micro: 0.4719 f1score_macro: 0.4649\n",
      "Epoch: 8/50\n",
      "Begin test......\n",
      "Test Loss: 0.0112 Acc: 0.4880 Precision: 0.4813 Recall: 0.4880 f1score_micro: 0.4880 f1score_macro: 0.4768\n",
      "Epoch: 9/50\n",
      "Begin test......\n",
      "Test Loss: 0.0115 Acc: 0.4601 Precision: 0.4838 Recall: 0.4601 f1score_micro: 0.4601 f1score_macro: 0.4416\n",
      "Epoch: 10/50\n",
      "Begin test......\n",
      "Test Loss: 0.0112 Acc: 0.4850 Precision: 0.5015 Recall: 0.4850 f1score_micro: 0.4850 f1score_macro: 0.4775\n",
      "Epoch: 11/50\n",
      "Begin test......\n",
      "Test Loss: 0.0107 Acc: 0.5169 Precision: 0.5164 Recall: 0.5169 f1score_micro: 0.5169 f1score_macro: 0.5099\n",
      "Epoch: 12/50\n",
      "Begin test......\n",
      "Test Loss: 0.0106 Acc: 0.5172 Precision: 0.5143 Recall: 0.5172 f1score_micro: 0.5172 f1score_macro: 0.5112\n",
      "Epoch: 13/50\n",
      "Begin test......\n",
      "Test Loss: 0.0104 Acc: 0.5348 Precision: 0.5326 Recall: 0.5348 f1score_micro: 0.5348 f1score_macro: 0.5303\n",
      "Epoch: 14/50\n",
      "Begin test......\n",
      "Test Loss: 0.0105 Acc: 0.5167 Precision: 0.5259 Recall: 0.5167 f1score_micro: 0.5167 f1score_macro: 0.5081\n",
      "Epoch: 15/50\n",
      "Begin test......\n",
      "Test Loss: 0.0107 Acc: 0.5180 Precision: 0.5285 Recall: 0.5180 f1score_micro: 0.5180 f1score_macro: 0.5160\n",
      "Epoch: 16/50\n",
      "Begin test......\n",
      "Test Loss: 0.0101 Acc: 0.5436 Precision: 0.5446 Recall: 0.5436 f1score_micro: 0.5436 f1score_macro: 0.5400\n",
      "Epoch: 17/50\n",
      "Begin test......\n",
      "Test Loss: 0.0100 Acc: 0.5446 Precision: 0.5425 Recall: 0.5446 f1score_micro: 0.5446 f1score_macro: 0.5412\n",
      "Epoch: 18/50\n",
      "Begin test......\n",
      "Test Loss: 0.0101 Acc: 0.5431 Precision: 0.5460 Recall: 0.5431 f1score_micro: 0.5431 f1score_macro: 0.5381\n",
      "Epoch: 19/50\n",
      "Begin test......\n",
      "Test Loss: 0.0102 Acc: 0.5351 Precision: 0.5418 Recall: 0.5351 f1score_micro: 0.5351 f1score_macro: 0.5300\n",
      "Epoch: 20/50\n",
      "Begin test......\n",
      "Test Loss: 0.0099 Acc: 0.5537 Precision: 0.5502 Recall: 0.5537 f1score_micro: 0.5537 f1score_macro: 0.5482\n",
      "Epoch: 21/50\n",
      "Begin test......\n",
      "Test Loss: 0.0098 Acc: 0.5585 Precision: 0.5565 Recall: 0.5585 f1score_micro: 0.5585 f1score_macro: 0.5555\n",
      "Epoch: 22/50\n",
      "Begin test......\n",
      "Test Loss: 0.0097 Acc: 0.5587 Precision: 0.5541 Recall: 0.5587 f1score_micro: 0.5587 f1score_macro: 0.5549\n",
      "Epoch: 23/50\n",
      "Begin test......\n",
      "Test Loss: 0.0098 Acc: 0.5533 Precision: 0.5494 Recall: 0.5533 f1score_micro: 0.5533 f1score_macro: 0.5486\n",
      "Epoch: 24/50\n",
      "Begin test......\n",
      "Test Loss: 0.0097 Acc: 0.5607 Precision: 0.5618 Recall: 0.5607 f1score_micro: 0.5607 f1score_macro: 0.5586\n",
      "Epoch: 25/50\n",
      "Begin test......\n",
      "Test Loss: 0.0099 Acc: 0.5509 Precision: 0.5479 Recall: 0.5509 f1score_micro: 0.5509 f1score_macro: 0.5418\n",
      "Epoch: 26/50\n",
      "Begin test......\n",
      "Test Loss: 0.0097 Acc: 0.5578 Precision: 0.5566 Recall: 0.5578 f1score_micro: 0.5578 f1score_macro: 0.5551\n",
      "Epoch: 27/50\n",
      "Begin test......\n",
      "Test Loss: 0.0096 Acc: 0.5630 Precision: 0.5629 Recall: 0.5630 f1score_micro: 0.5630 f1score_macro: 0.5621\n",
      "Epoch: 28/50\n",
      "Begin test......\n",
      "Test Loss: 0.0096 Acc: 0.5655 Precision: 0.5619 Recall: 0.5655 f1score_micro: 0.5655 f1score_macro: 0.5617\n",
      "Epoch: 29/50\n",
      "Begin test......\n",
      "Test Loss: 0.0096 Acc: 0.5611 Precision: 0.5577 Recall: 0.5611 f1score_micro: 0.5611 f1score_macro: 0.5560\n",
      "Epoch: 30/50\n",
      "Begin test......\n",
      "Test Loss: 0.0095 Acc: 0.5654 Precision: 0.5610 Recall: 0.5654 f1score_micro: 0.5654 f1score_macro: 0.5603\n",
      "Epoch: 31/50\n",
      "Begin test......\n",
      "Test Loss: 0.0095 Acc: 0.5691 Precision: 0.5667 Recall: 0.5691 f1score_micro: 0.5691 f1score_macro: 0.5665\n",
      "Epoch: 32/50\n",
      "Begin test......\n",
      "Test Loss: 0.0095 Acc: 0.5692 Precision: 0.5665 Recall: 0.5692 f1score_micro: 0.5692 f1score_macro: 0.5654\n",
      "Epoch: 33/50\n",
      "Begin test......\n",
      "Test Loss: 0.0095 Acc: 0.5662 Precision: 0.5639 Recall: 0.5662 f1score_micro: 0.5662 f1score_macro: 0.5634\n",
      "Epoch: 34/50\n",
      "Begin test......\n",
      "Test Loss: 0.0095 Acc: 0.5703 Precision: 0.5662 Recall: 0.5703 f1score_micro: 0.5703 f1score_macro: 0.5650\n",
      "Epoch: 35/50\n",
      "Begin test......\n",
      "Test Loss: 0.0095 Acc: 0.5688 Precision: 0.5638 Recall: 0.5688 f1score_micro: 0.5688 f1score_macro: 0.5638\n",
      "Epoch: 36/50\n",
      "Begin test......\n",
      "Test Loss: 0.0094 Acc: 0.5724 Precision: 0.5684 Recall: 0.5724 f1score_micro: 0.5724 f1score_macro: 0.5692\n",
      "Epoch: 37/50\n",
      "Begin test......\n",
      "Test Loss: 0.0094 Acc: 0.5711 Precision: 0.5665 Recall: 0.5711 f1score_micro: 0.5711 f1score_macro: 0.5677\n",
      "Epoch: 38/50\n",
      "Begin test......\n",
      "Test Loss: 0.0094 Acc: 0.5688 Precision: 0.5637 Recall: 0.5688 f1score_micro: 0.5688 f1score_macro: 0.5633\n",
      "Epoch: 39/50\n",
      "Begin test......\n",
      "Test Loss: 0.0094 Acc: 0.5715 Precision: 0.5669 Recall: 0.5715 f1score_micro: 0.5715 f1score_macro: 0.5664\n",
      "Epoch: 40/50\n",
      "Begin test......\n",
      "Test Loss: 0.0094 Acc: 0.5699 Precision: 0.5640 Recall: 0.5699 f1score_micro: 0.5699 f1score_macro: 0.5648\n",
      "Epoch: 41/50\n",
      "Begin test......\n",
      "Test Loss: 0.0094 Acc: 0.5685 Precision: 0.5638 Recall: 0.5685 f1score_micro: 0.5685 f1score_macro: 0.5643\n",
      "Epoch: 42/50\n",
      "Begin test......\n",
      "Test Loss: 0.0094 Acc: 0.5677 Precision: 0.5627 Recall: 0.5677 f1score_micro: 0.5677 f1score_macro: 0.5633\n",
      "Epoch: 43/50\n",
      "Begin test......\n",
      "Test Loss: 0.0094 Acc: 0.5723 Precision: 0.5669 Recall: 0.5723 f1score_micro: 0.5723 f1score_macro: 0.5682\n",
      "Epoch: 44/50\n",
      "Begin test......\n",
      "Test Loss: 0.0094 Acc: 0.5712 Precision: 0.5684 Recall: 0.5712 f1score_micro: 0.5712 f1score_macro: 0.5677\n",
      "Epoch: 45/50\n",
      "Begin test......\n",
      "Test Loss: 0.0094 Acc: 0.5711 Precision: 0.5658 Recall: 0.5711 f1score_micro: 0.5711 f1score_macro: 0.5669\n",
      "Epoch: 46/50\n",
      "Begin test......\n",
      "Test Loss: 0.0094 Acc: 0.5729 Precision: 0.5685 Recall: 0.5729 f1score_micro: 0.5729 f1score_macro: 0.5693\n",
      "Epoch: 47/50\n",
      "Begin test......\n",
      "Test Loss: 0.0094 Acc: 0.5732 Precision: 0.5681 Recall: 0.5732 f1score_micro: 0.5732 f1score_macro: 0.5691\n",
      "Epoch: 48/50\n",
      "Begin test......\n",
      "Test Loss: 0.0094 Acc: 0.5728 Precision: 0.5692 Recall: 0.5728 f1score_micro: 0.5728 f1score_macro: 0.5695\n",
      "Epoch: 49/50\n",
      "Begin test......\n",
      "Test Loss: 0.0094 Acc: 0.5727 Precision: 0.5673 Recall: 0.5727 f1score_micro: 0.5727 f1score_macro: 0.5687\n",
      "Epoch: 50/50\n",
      "Begin test......\n",
      "Test Loss: 0.0094 Acc: 0.5733 Precision: 0.5686 Recall: 0.5733 f1score_micro: 0.5733 f1score_macro: 0.5696\n"
     ]
    }
   ],
   "source": [
    "test_loss_l = []\n",
    "test_acc_l = []\n",
    "test_precision_l = []\n",
    "test_recall_l = []\n",
    "test_f1score_micro_l = []\n",
    "test_f1score_macro_l = []\n",
    "\n",
    "test_acc = torchmetrics.classification.MulticlassAccuracy(num_classes=10).to(device)\n",
    "test_precision = torchmetrics.classification.MulticlassPrecision(num_classes=10, average='macro').to(device)\n",
    "test_recall = torchmetrics.classification.MulticlassRecall(num_classes=10, average='macro').to(device)\n",
    "test_f1score_micro = torchmetrics.classification.MulticlassF1Score(num_classes=10, average='micro').to(device)\n",
    "test_f1score_macro = torchmetrics.classification.MulticlassF1Score(num_classes=10, average='macro').to(device)\n",
    "\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    # torch.cuda.empty_cache()\n",
    "\n",
    "    ##########################\n",
    "    ### Training\n",
    "    ##########################\n",
    "\n",
    "    for batch_idx, (image, target) in enumerate(train_dataloader):\n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # train model\n",
    "        outputs, loss = train_batch(model, image, target)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        \n",
    "        loss_data = loss.data.item()\n",
    "        if np.isnan(loss_data):\n",
    "            raise ValueError('loss is nan while training')\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{NUM_EPOCHS}')\n",
    "\n",
    "    # change learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    ##########################\n",
    "    ### Testing\n",
    "    ##########################\n",
    "    # # eval model during training or in the last epoch\n",
    "    if (epoch + 1) % EVAL_INTERVAL == 0 or (epoch +1) == NUM_EPOCHS:\n",
    "        print('Begin test......')\n",
    "        model.eval()\n",
    "        \n",
    "        test_loss = .0        \n",
    "        test_acc.reset()\n",
    "        test_precision.reset()    \n",
    "        test_recall.reset()\n",
    "        test_f1score_micro.reset()\n",
    "        test_f1score_macro.reset()\n",
    "\n",
    "        for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # test model\n",
    "            outputs, loss = test_batch(model, image, target)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            test_acc.update(preds, target)\n",
    "            test_precision.update(preds, target)\n",
    "            test_recall.update(preds, target)\n",
    "            test_f1score_micro.update(preds, target)\n",
    "            test_f1score_macro.update(preds, target)\n",
    "\n",
    "        val_loss = test_loss / len(test_set)\n",
    "        val_acc = test_acc.compute()\n",
    "        val_precision = test_precision.compute()\n",
    "        val_recall = test_recall.compute()\n",
    "        val_f1score_micro = test_f1score_micro.compute()\n",
    "        val_f1score_macro = test_f1score_macro.compute()\n",
    "        print(f'Test Loss: {val_loss:.4f} Acc: {val_acc:.4f} Precision: {val_precision:.4f} Recall: {val_recall:.4f} f1score_micro: {val_f1score_micro:.4f} f1score_macro: {val_f1score_macro:.4f}')\n",
    "\n",
    "        test_loss_l.append(test_loss)\n",
    "        test_acc_l.append(val_acc.cpu().detach().numpy())\n",
    "        test_precision_l.append(val_precision.cpu().detach().numpy())\n",
    "        test_recall_l.append(val_recall.cpu().detach().numpy())\n",
    "        test_f1score_micro_l.append(val_f1score_micro.cpu().numpy())\n",
    "        test_f1score_macro_l.append(val_f1score_macro.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log generated\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'acc': test_acc_l, 'precision': test_precision_l, 'recall': test_recall_l, 'f1score_micro': test_f1score_micro_l, 'f1score_macro': test_f1score_macro_l})\n",
    "df.to_csv('./log/ce.csv', index=False)\n",
    "print('log generated')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
