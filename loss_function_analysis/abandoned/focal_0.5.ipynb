{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Imports | Hyperparameters | Device | Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "## Basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from focal import FocalLoss\n",
    "\n",
    "import torchmetrics\n",
    "import random\n",
    "\n",
    "## Hyperparameters \n",
    "# random seed\n",
    "SEED = 1 \n",
    "NUM_CLASS = 10\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.detestic = True\n",
    "    \n",
    "setup_seed(SEED)\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 50\n",
    "EVAL_INTERVAL=1\n",
    "SAVE_DIR = './log'\n",
    "\n",
    "# Optimizer\n",
    "LEARNING_RATE = 1e-1\n",
    "MOMENTUM = 0.9\n",
    "STEP=5\n",
    "GAMMA=0.5\n",
    "\n",
    "## Device\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "## Dataset\n",
    "# cifar10 transform\n",
    "transform_cifar10_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_cifar10_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='../../data', train=True,\n",
    "                                        download=True, transform=transform_cifar10_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='../../data', train=False,\n",
    "                                       download=True, transform=transform_cifar10_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model | Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model def\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 4, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3)\n",
    "        self.fc1 = nn.Linear(8 * 6 * 6, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 8 * 6 * 6)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "## Init model\n",
    "model = ConvNet()\n",
    "model.to(device)\n",
    "\n",
    "## Init Optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### Modify here ###########################\n",
    "# Define the loss function\n",
    "criterion = FocalLoss(gamma=0.5, reduction='mean')\n",
    "###############################################################\n",
    "\n",
    "## Define the batch train\n",
    "def train_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one training batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to train.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated by the defined loss function loss_fn().\n",
    "    \"\"\"\n",
    "    \n",
    "    ####################### Modify here ###########################\n",
    "    output = model(image)\n",
    "    loss = criterion(output, target)\n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss\n",
    "\n",
    "\n",
    "def test_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one testing batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to evaluate.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated for the batch.\n",
    "    \"\"\"\n",
    "\n",
    "    ####################### Modify here ###########################\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        loss = criterion(output, target)\n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50\n",
      "Begin test......\n",
      "Test Loss: 0.0118 Acc: 0.3877 Precision: 0.4152 Recall: 0.3877 f1score_micro: 0.3877 f1score_macro: 0.3779\n",
      "Epoch: 2/50\n",
      "Begin test......\n",
      "Test Loss: 0.0121 Acc: 0.3662 Precision: 0.3955 Recall: 0.3662 f1score_micro: 0.3662 f1score_macro: 0.3361\n",
      "Epoch: 3/50\n",
      "Begin test......\n",
      "Test Loss: 0.0113 Acc: 0.4155 Precision: 0.4169 Recall: 0.4155 f1score_micro: 0.4155 f1score_macro: 0.3978\n",
      "Epoch: 4/50\n",
      "Begin test......\n",
      "Test Loss: 0.0118 Acc: 0.3878 Precision: 0.4248 Recall: 0.3878 f1score_micro: 0.3878 f1score_macro: 0.3713\n",
      "Epoch: 5/50\n",
      "Begin test......\n",
      "Test Loss: 0.0121 Acc: 0.3857 Precision: 0.3969 Recall: 0.3857 f1score_micro: 0.3857 f1score_macro: 0.3795\n",
      "Epoch: 6/50\n",
      "Begin test......\n",
      "Test Loss: 0.0105 Acc: 0.4594 Precision: 0.4605 Recall: 0.4594 f1score_micro: 0.4594 f1score_macro: 0.4452\n",
      "Epoch: 7/50\n",
      "Begin test......\n",
      "Test Loss: 0.0109 Acc: 0.4395 Precision: 0.4648 Recall: 0.4395 f1score_micro: 0.4395 f1score_macro: 0.4406\n",
      "Epoch: 8/50\n",
      "Begin test......\n",
      "Test Loss: 0.0101 Acc: 0.4762 Precision: 0.4794 Recall: 0.4762 f1score_micro: 0.4762 f1score_macro: 0.4629\n",
      "Epoch: 9/50\n",
      "Begin test......\n",
      "Test Loss: 0.0105 Acc: 0.4559 Precision: 0.4893 Recall: 0.4559 f1score_micro: 0.4559 f1score_macro: 0.4392\n",
      "Epoch: 10/50\n",
      "Begin test......\n",
      "Test Loss: 0.0106 Acc: 0.4551 Precision: 0.4645 Recall: 0.4551 f1score_micro: 0.4551 f1score_macro: 0.4531\n",
      "Epoch: 11/50\n",
      "Begin test......\n",
      "Test Loss: 0.0099 Acc: 0.4871 Precision: 0.4954 Recall: 0.4871 f1score_micro: 0.4871 f1score_macro: 0.4812\n",
      "Epoch: 12/50\n",
      "Begin test......\n",
      "Test Loss: 0.0095 Acc: 0.5088 Precision: 0.5148 Recall: 0.5088 f1score_micro: 0.5088 f1score_macro: 0.5060\n",
      "Epoch: 13/50\n",
      "Begin test......\n",
      "Test Loss: 0.0097 Acc: 0.5082 Precision: 0.5157 Recall: 0.5082 f1score_micro: 0.5082 f1score_macro: 0.4994\n",
      "Epoch: 14/50\n",
      "Begin test......\n",
      "Test Loss: 0.0096 Acc: 0.5077 Precision: 0.5169 Recall: 0.5077 f1score_micro: 0.5077 f1score_macro: 0.4996\n",
      "Epoch: 15/50\n",
      "Begin test......\n",
      "Test Loss: 0.0094 Acc: 0.5180 Precision: 0.5231 Recall: 0.5180 f1score_micro: 0.5180 f1score_macro: 0.5166\n",
      "Epoch: 16/50\n",
      "Begin test......\n",
      "Test Loss: 0.0091 Acc: 0.5260 Precision: 0.5321 Recall: 0.5260 f1score_micro: 0.5260 f1score_macro: 0.5209\n",
      "Epoch: 17/50\n",
      "Begin test......\n",
      "Test Loss: 0.0090 Acc: 0.5412 Precision: 0.5413 Recall: 0.5412 f1score_micro: 0.5412 f1score_macro: 0.5380\n",
      "Epoch: 18/50\n",
      "Begin test......\n",
      "Test Loss: 0.0090 Acc: 0.5373 Precision: 0.5383 Recall: 0.5373 f1score_micro: 0.5373 f1score_macro: 0.5347\n",
      "Epoch: 19/50\n",
      "Begin test......\n",
      "Test Loss: 0.0091 Acc: 0.5314 Precision: 0.5368 Recall: 0.5314 f1score_micro: 0.5314 f1score_macro: 0.5280\n",
      "Epoch: 20/50\n",
      "Begin test......\n",
      "Test Loss: 0.0091 Acc: 0.5282 Precision: 0.5363 Recall: 0.5282 f1score_micro: 0.5282 f1score_macro: 0.5269\n",
      "Epoch: 21/50\n",
      "Begin test......\n",
      "Test Loss: 0.0088 Acc: 0.5504 Precision: 0.5506 Recall: 0.5504 f1score_micro: 0.5504 f1score_macro: 0.5478\n",
      "Epoch: 22/50\n",
      "Begin test......\n",
      "Test Loss: 0.0088 Acc: 0.5445 Precision: 0.5490 Recall: 0.5445 f1score_micro: 0.5445 f1score_macro: 0.5383\n",
      "Epoch: 23/50\n",
      "Begin test......\n",
      "Test Loss: 0.0088 Acc: 0.5463 Precision: 0.5460 Recall: 0.5463 f1score_micro: 0.5463 f1score_macro: 0.5412\n",
      "Epoch: 24/50\n",
      "Begin test......\n",
      "Test Loss: 0.0087 Acc: 0.5484 Precision: 0.5530 Recall: 0.5484 f1score_micro: 0.5484 f1score_macro: 0.5471\n",
      "Epoch: 25/50\n",
      "Begin test......\n",
      "Test Loss: 0.0090 Acc: 0.5413 Precision: 0.5465 Recall: 0.5413 f1score_micro: 0.5413 f1score_macro: 0.5370\n",
      "Epoch: 26/50\n",
      "Begin test......\n",
      "Test Loss: 0.0087 Acc: 0.5513 Precision: 0.5525 Recall: 0.5513 f1score_micro: 0.5513 f1score_macro: 0.5502\n",
      "Epoch: 27/50\n",
      "Begin test......\n",
      "Test Loss: 0.0085 Acc: 0.5552 Precision: 0.5555 Recall: 0.5552 f1score_micro: 0.5552 f1score_macro: 0.5522\n",
      "Epoch: 28/50\n",
      "Begin test......\n",
      "Test Loss: 0.0085 Acc: 0.5563 Precision: 0.5527 Recall: 0.5563 f1score_micro: 0.5563 f1score_macro: 0.5525\n",
      "Epoch: 29/50\n",
      "Begin test......\n",
      "Test Loss: 0.0085 Acc: 0.5535 Precision: 0.5526 Recall: 0.5535 f1score_micro: 0.5535 f1score_macro: 0.5493\n",
      "Epoch: 30/50\n",
      "Begin test......\n",
      "Test Loss: 0.0085 Acc: 0.5622 Precision: 0.5624 Recall: 0.5622 f1score_micro: 0.5622 f1score_macro: 0.5591\n",
      "Epoch: 31/50\n",
      "Begin test......\n",
      "Test Loss: 0.0085 Acc: 0.5621 Precision: 0.5609 Recall: 0.5621 f1score_micro: 0.5621 f1score_macro: 0.5591\n",
      "Epoch: 32/50\n",
      "Begin test......\n",
      "Test Loss: 0.0085 Acc: 0.5624 Precision: 0.5595 Recall: 0.5624 f1score_micro: 0.5624 f1score_macro: 0.5591\n",
      "Epoch: 33/50\n",
      "Begin test......\n",
      "Test Loss: 0.0085 Acc: 0.5612 Precision: 0.5604 Recall: 0.5612 f1score_micro: 0.5612 f1score_macro: 0.5586\n",
      "Epoch: 34/50\n",
      "Begin test......\n",
      "Test Loss: 0.0085 Acc: 0.5596 Precision: 0.5584 Recall: 0.5596 f1score_micro: 0.5596 f1score_macro: 0.5562\n",
      "Epoch: 35/50\n",
      "Begin test......\n",
      "Test Loss: 0.0085 Acc: 0.5629 Precision: 0.5579 Recall: 0.5629 f1score_micro: 0.5629 f1score_macro: 0.5584\n",
      "Epoch: 36/50\n",
      "Begin test......\n",
      "Test Loss: 0.0084 Acc: 0.5635 Precision: 0.5603 Recall: 0.5635 f1score_micro: 0.5635 f1score_macro: 0.5602\n",
      "Epoch: 37/50\n",
      "Begin test......\n",
      "Test Loss: 0.0084 Acc: 0.5625 Precision: 0.5588 Recall: 0.5625 f1score_micro: 0.5625 f1score_macro: 0.5590\n",
      "Epoch: 38/50\n",
      "Begin test......\n",
      "Test Loss: 0.0085 Acc: 0.5652 Precision: 0.5615 Recall: 0.5652 f1score_micro: 0.5652 f1score_macro: 0.5608\n",
      "Epoch: 39/50\n",
      "Begin test......\n",
      "Test Loss: 0.0084 Acc: 0.5643 Precision: 0.5599 Recall: 0.5643 f1score_micro: 0.5643 f1score_macro: 0.5595\n",
      "Epoch: 40/50\n",
      "Begin test......\n",
      "Test Loss: 0.0084 Acc: 0.5607 Precision: 0.5566 Recall: 0.5607 f1score_micro: 0.5607 f1score_macro: 0.5559\n",
      "Epoch: 41/50\n",
      "Begin test......\n",
      "Test Loss: 0.0084 Acc: 0.5635 Precision: 0.5611 Recall: 0.5635 f1score_micro: 0.5635 f1score_macro: 0.5605\n",
      "Epoch: 42/50\n",
      "Begin test......\n",
      "Test Loss: 0.0084 Acc: 0.5637 Precision: 0.5600 Recall: 0.5637 f1score_micro: 0.5637 f1score_macro: 0.5598\n",
      "Epoch: 43/50\n",
      "Begin test......\n",
      "Test Loss: 0.0084 Acc: 0.5646 Precision: 0.5604 Recall: 0.5646 f1score_micro: 0.5646 f1score_macro: 0.5609\n",
      "Epoch: 44/50\n",
      "Begin test......\n",
      "Test Loss: 0.0084 Acc: 0.5656 Precision: 0.5637 Recall: 0.5656 f1score_micro: 0.5656 f1score_macro: 0.5619\n",
      "Epoch: 45/50\n",
      "Begin test......\n",
      "Test Loss: 0.0084 Acc: 0.5643 Precision: 0.5608 Recall: 0.5643 f1score_micro: 0.5643 f1score_macro: 0.5608\n",
      "Epoch: 46/50\n",
      "Begin test......\n",
      "Test Loss: 0.0084 Acc: 0.5659 Precision: 0.5622 Recall: 0.5659 f1score_micro: 0.5659 f1score_macro: 0.5624\n",
      "Epoch: 47/50\n",
      "Begin test......\n",
      "Test Loss: 0.0084 Acc: 0.5634 Precision: 0.5597 Recall: 0.5634 f1score_micro: 0.5634 f1score_macro: 0.5598\n",
      "Epoch: 48/50\n",
      "Begin test......\n",
      "Test Loss: 0.0084 Acc: 0.5647 Precision: 0.5616 Recall: 0.5647 f1score_micro: 0.5647 f1score_macro: 0.5616\n",
      "Epoch: 49/50\n",
      "Begin test......\n",
      "Test Loss: 0.0084 Acc: 0.5642 Precision: 0.5609 Recall: 0.5642 f1score_micro: 0.5642 f1score_macro: 0.5612\n",
      "Epoch: 50/50\n",
      "Begin test......\n",
      "Test Loss: 0.0084 Acc: 0.5649 Precision: 0.5610 Recall: 0.5649 f1score_micro: 0.5649 f1score_macro: 0.5614\n"
     ]
    }
   ],
   "source": [
    "test_loss_l = []\n",
    "test_acc_l = []\n",
    "test_precision_l = []\n",
    "test_recall_l = []\n",
    "test_f1score_micro_l = []\n",
    "test_f1score_macro_l = []\n",
    "\n",
    "test_acc = torchmetrics.classification.MulticlassAccuracy(num_classes=10).to(device)\n",
    "test_precision = torchmetrics.classification.MulticlassPrecision(num_classes=10, average='macro').to(device)\n",
    "test_recall = torchmetrics.classification.MulticlassRecall(num_classes=10, average='macro').to(device)\n",
    "test_f1score_micro = torchmetrics.classification.MulticlassF1Score(num_classes=10, average='micro').to(device)\n",
    "test_f1score_macro = torchmetrics.classification.MulticlassF1Score(num_classes=10, average='macro').to(device)\n",
    "\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    # torch.cuda.empty_cache()\n",
    "\n",
    "    ##########################\n",
    "    ### Training\n",
    "    ##########################\n",
    "\n",
    "    for batch_idx, (image, target) in enumerate(train_dataloader):\n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # train model\n",
    "        outputs, loss = train_batch(model, image, target)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        \n",
    "        loss_data = loss.data.item()\n",
    "        if np.isnan(loss_data):\n",
    "            raise ValueError('loss is nan while training')\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{NUM_EPOCHS}')\n",
    "\n",
    "    # change learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    ##########################\n",
    "    ### Testing\n",
    "    ##########################\n",
    "    # # eval model during training or in the last epoch\n",
    "    if (epoch + 1) % EVAL_INTERVAL == 0 or (epoch +1) == NUM_EPOCHS:\n",
    "        print('Begin test......')\n",
    "        model.eval()\n",
    "        \n",
    "        test_loss = .0        \n",
    "        test_acc.reset()\n",
    "        test_precision.reset()    \n",
    "        test_recall.reset()\n",
    "        test_f1score_micro.reset()\n",
    "        test_f1score_macro.reset()\n",
    "\n",
    "        for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # test model\n",
    "            outputs, loss = test_batch(model, image, target)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            test_acc.update(preds, target)\n",
    "            test_precision.update(preds, target)\n",
    "            test_recall.update(preds, target)\n",
    "            test_f1score_micro.update(preds, target)\n",
    "            test_f1score_macro.update(preds, target)\n",
    "\n",
    "        val_loss = test_loss / len(test_set)\n",
    "        val_acc = test_acc.compute()\n",
    "        val_precision = test_precision.compute()\n",
    "        val_recall = test_recall.compute()\n",
    "        val_f1score_micro = test_f1score_micro.compute()\n",
    "        val_f1score_macro = test_f1score_macro.compute()\n",
    "        print(f'Test Loss: {val_loss:.4f} Acc: {val_acc:.4f} Precision: {val_precision:.4f} Recall: {val_recall:.4f} f1score_micro: {val_f1score_micro:.4f} f1score_macro: {val_f1score_macro:.4f}')\n",
    "\n",
    "        test_loss_l.append(test_loss)\n",
    "        test_acc_l.append(val_acc.cpu().detach().numpy())\n",
    "        test_precision_l.append(val_precision.cpu().detach().numpy())\n",
    "        test_recall_l.append(val_recall.cpu().detach().numpy())\n",
    "        test_f1score_micro_l.append(val_f1score_micro.cpu().numpy())\n",
    "        test_f1score_macro_l.append(val_f1score_macro.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log generated\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'acc': test_acc_l, 'precision': test_precision_l, 'recall': test_recall_l, 'f1score_micro': test_f1score_micro_l, 'f1score_macro': test_f1score_macro_l})\n",
    "df.to_csv('./log/focal_0.5.csv', index=False)\n",
    "print('log generated')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
