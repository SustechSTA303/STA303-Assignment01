{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Imports | Hyperparameters | Device | Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from focal import FocalLoss\n",
    "\n",
    "import torchmetrics\n",
    "import random\n",
    "\n",
    "# Hyperparameters\n",
    "# random seed\n",
    "SEED = 1\n",
    "NUM_CLASS = 10\n",
    "\n",
    "\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "setup_seed(SEED)\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 50\n",
    "EVAL_INTERVAL = 1\n",
    "SAVE_DIR = './log'\n",
    "\n",
    "# Optimizer\n",
    "LEARNING_RATE = 1e-1\n",
    "MOMENTUM = 0.9\n",
    "STEP = 5\n",
    "GAMMA = 0.5\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dataset\n",
    "# cifar10 transform\n",
    "transform_cifar10_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_cifar10_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='../../data', train=True,\n",
    "                                         download=True, transform=transform_cifar10_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                                               shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='../../data', train=False,\n",
    "                                        download=True, transform=transform_cifar10_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                              shuffle=False, num_workers=2)\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat',\n",
    "               'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model | Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model def\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 4, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3)\n",
    "        self.fc1 = nn.Linear(8 * 6 * 6, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 8 * 6 * 6)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "## Init model\n",
    "model = ConvNet()\n",
    "model.to(device)\n",
    "\n",
    "## Init Optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### Modify here ###########################\n",
    "# Define the loss function\n",
    "criterion = FocalLoss(gamma=2, reduction='mean')\n",
    "###############################################################\n",
    "\n",
    "## Define the batch train\n",
    "def train_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one training batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to train.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated by the defined loss function loss_fn().\n",
    "    \"\"\"\n",
    "    \n",
    "    ####################### Modify here ###########################\n",
    "    output = model(image)\n",
    "    loss = criterion(output, target)\n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss\n",
    "\n",
    "\n",
    "def test_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one testing batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to evaluate.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated for the batch.\n",
    "    \"\"\"\n",
    "\n",
    "    ####################### Modify here ###########################\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        loss = criterion(output, target)\n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50\n",
      "Begin test......\n",
      "Test Loss: 0.0092 Acc: 0.3717 Precision: 0.4012 Recall: 0.3717 f1score_micro: 0.3717 f1score_macro: 0.3581\n",
      "Epoch: 2/50\n",
      "Begin test......\n",
      "Test Loss: 0.0094 Acc: 0.3705 Precision: 0.3885 Recall: 0.3705 f1score_micro: 0.3705 f1score_macro: 0.3590\n",
      "Epoch: 3/50\n",
      "Begin test......\n",
      "Test Loss: 0.0089 Acc: 0.4003 Precision: 0.4048 Recall: 0.4003 f1score_micro: 0.4003 f1score_macro: 0.3890\n",
      "Epoch: 4/50\n",
      "Begin test......\n",
      "Test Loss: 0.0090 Acc: 0.3788 Precision: 0.4288 Recall: 0.3788 f1score_micro: 0.3788 f1score_macro: 0.3765\n",
      "Epoch: 5/50\n",
      "Begin test......\n",
      "Test Loss: 0.0087 Acc: 0.4092 Precision: 0.4013 Recall: 0.4092 f1score_micro: 0.4092 f1score_macro: 0.3911\n",
      "Epoch: 6/50\n",
      "Begin test......\n",
      "Test Loss: 0.0083 Acc: 0.4354 Precision: 0.4460 Recall: 0.4354 f1score_micro: 0.4354 f1score_macro: 0.4224\n",
      "Epoch: 7/50\n",
      "Begin test......\n",
      "Test Loss: 0.0077 Acc: 0.4476 Precision: 0.4663 Recall: 0.4476 f1score_micro: 0.4476 f1score_macro: 0.4470\n",
      "Epoch: 8/50\n",
      "Begin test......\n",
      "Test Loss: 0.0077 Acc: 0.4595 Precision: 0.4588 Recall: 0.4595 f1score_micro: 0.4595 f1score_macro: 0.4483\n",
      "Epoch: 9/50\n",
      "Begin test......\n",
      "Test Loss: 0.0077 Acc: 0.4459 Precision: 0.4843 Recall: 0.4459 f1score_micro: 0.4459 f1score_macro: 0.4214\n",
      "Epoch: 10/50\n",
      "Begin test......\n",
      "Test Loss: 0.0075 Acc: 0.4738 Precision: 0.4969 Recall: 0.4738 f1score_micro: 0.4738 f1score_macro: 0.4693\n",
      "Epoch: 11/50\n",
      "Begin test......\n",
      "Test Loss: 0.0070 Acc: 0.5039 Precision: 0.5168 Recall: 0.5039 f1score_micro: 0.5039 f1score_macro: 0.4965\n",
      "Epoch: 12/50\n",
      "Begin test......\n",
      "Test Loss: 0.0069 Acc: 0.5100 Precision: 0.5245 Recall: 0.5100 f1score_micro: 0.5100 f1score_macro: 0.5084\n",
      "Epoch: 13/50\n",
      "Begin test......\n",
      "Test Loss: 0.0067 Acc: 0.5197 Precision: 0.5235 Recall: 0.5197 f1score_micro: 0.5197 f1score_macro: 0.5142\n",
      "Epoch: 14/50\n",
      "Begin test......\n",
      "Test Loss: 0.0070 Acc: 0.5046 Precision: 0.5164 Recall: 0.5046 f1score_micro: 0.5046 f1score_macro: 0.4967\n",
      "Epoch: 15/50\n",
      "Begin test......\n",
      "Test Loss: 0.0067 Acc: 0.5241 Precision: 0.5395 Recall: 0.5241 f1score_micro: 0.5241 f1score_macro: 0.5230\n",
      "Epoch: 16/50\n",
      "Begin test......\n",
      "Test Loss: 0.0065 Acc: 0.5298 Precision: 0.5395 Recall: 0.5298 f1score_micro: 0.5298 f1score_macro: 0.5267\n",
      "Epoch: 17/50\n",
      "Begin test......\n",
      "Test Loss: 0.0063 Acc: 0.5472 Precision: 0.5501 Recall: 0.5472 f1score_micro: 0.5472 f1score_macro: 0.5470\n",
      "Epoch: 18/50\n",
      "Begin test......\n",
      "Test Loss: 0.0063 Acc: 0.5422 Precision: 0.5481 Recall: 0.5422 f1score_micro: 0.5422 f1score_macro: 0.5400\n",
      "Epoch: 19/50\n",
      "Begin test......\n",
      "Test Loss: 0.0063 Acc: 0.5455 Precision: 0.5491 Recall: 0.5455 f1score_micro: 0.5455 f1score_macro: 0.5425\n",
      "Epoch: 20/50\n",
      "Begin test......\n",
      "Test Loss: 0.0063 Acc: 0.5439 Precision: 0.5467 Recall: 0.5439 f1score_micro: 0.5439 f1score_macro: 0.5402\n",
      "Epoch: 21/50\n",
      "Begin test......\n",
      "Test Loss: 0.0061 Acc: 0.5534 Precision: 0.5569 Recall: 0.5534 f1score_micro: 0.5534 f1score_macro: 0.5520\n",
      "Epoch: 22/50\n",
      "Begin test......\n",
      "Test Loss: 0.0061 Acc: 0.5597 Precision: 0.5622 Recall: 0.5597 f1score_micro: 0.5597 f1score_macro: 0.5560\n",
      "Epoch: 23/50\n",
      "Begin test......\n",
      "Test Loss: 0.0061 Acc: 0.5604 Precision: 0.5583 Recall: 0.5604 f1score_micro: 0.5604 f1score_macro: 0.5582\n",
      "Epoch: 24/50\n",
      "Begin test......\n",
      "Test Loss: 0.0061 Acc: 0.5541 Precision: 0.5534 Recall: 0.5541 f1score_micro: 0.5541 f1score_macro: 0.5497\n",
      "Epoch: 25/50\n",
      "Begin test......\n",
      "Test Loss: 0.0062 Acc: 0.5505 Precision: 0.5513 Recall: 0.5505 f1score_micro: 0.5505 f1score_macro: 0.5463\n",
      "Epoch: 26/50\n",
      "Begin test......\n",
      "Test Loss: 0.0060 Acc: 0.5598 Precision: 0.5600 Recall: 0.5598 f1score_micro: 0.5598 f1score_macro: 0.5585\n",
      "Epoch: 27/50\n",
      "Begin test......\n",
      "Test Loss: 0.0059 Acc: 0.5650 Precision: 0.5629 Recall: 0.5650 f1score_micro: 0.5650 f1score_macro: 0.5627\n",
      "Epoch: 28/50\n",
      "Begin test......\n",
      "Test Loss: 0.0059 Acc: 0.5628 Precision: 0.5600 Recall: 0.5628 f1score_micro: 0.5628 f1score_macro: 0.5591\n",
      "Epoch: 29/50\n",
      "Begin test......\n",
      "Test Loss: 0.0059 Acc: 0.5637 Precision: 0.5635 Recall: 0.5637 f1score_micro: 0.5637 f1score_macro: 0.5611\n",
      "Epoch: 30/50\n",
      "Begin test......\n",
      "Test Loss: 0.0059 Acc: 0.5682 Precision: 0.5680 Recall: 0.5682 f1score_micro: 0.5682 f1score_macro: 0.5655\n",
      "Epoch: 31/50\n",
      "Begin test......\n",
      "Test Loss: 0.0059 Acc: 0.5638 Precision: 0.5643 Recall: 0.5638 f1score_micro: 0.5638 f1score_macro: 0.5625\n",
      "Epoch: 32/50\n",
      "Begin test......\n",
      "Test Loss: 0.0059 Acc: 0.5673 Precision: 0.5670 Recall: 0.5673 f1score_micro: 0.5673 f1score_macro: 0.5656\n",
      "Epoch: 33/50\n",
      "Begin test......\n",
      "Test Loss: 0.0058 Acc: 0.5677 Precision: 0.5674 Recall: 0.5677 f1score_micro: 0.5677 f1score_macro: 0.5660\n",
      "Epoch: 34/50\n",
      "Begin test......\n",
      "Test Loss: 0.0058 Acc: 0.5669 Precision: 0.5665 Recall: 0.5669 f1score_micro: 0.5669 f1score_macro: 0.5636\n",
      "Epoch: 35/50\n",
      "Begin test......\n",
      "Test Loss: 0.0059 Acc: 0.5732 Precision: 0.5703 Recall: 0.5732 f1score_micro: 0.5732 f1score_macro: 0.5704\n",
      "Epoch: 36/50\n",
      "Begin test......\n",
      "Test Loss: 0.0058 Acc: 0.5667 Precision: 0.5651 Recall: 0.5667 f1score_micro: 0.5667 f1score_macro: 0.5652\n",
      "Epoch: 37/50\n",
      "Begin test......\n",
      "Test Loss: 0.0058 Acc: 0.5707 Precision: 0.5683 Recall: 0.5707 f1score_micro: 0.5707 f1score_macro: 0.5683\n",
      "Epoch: 38/50\n",
      "Begin test......\n",
      "Test Loss: 0.0059 Acc: 0.5710 Precision: 0.5688 Recall: 0.5710 f1score_micro: 0.5710 f1score_macro: 0.5677\n",
      "Epoch: 39/50\n",
      "Begin test......\n",
      "Test Loss: 0.0058 Acc: 0.5725 Precision: 0.5699 Recall: 0.5725 f1score_micro: 0.5725 f1score_macro: 0.5690\n",
      "Epoch: 40/50\n",
      "Begin test......\n",
      "Test Loss: 0.0058 Acc: 0.5694 Precision: 0.5662 Recall: 0.5694 f1score_micro: 0.5694 f1score_macro: 0.5663\n",
      "Epoch: 41/50\n",
      "Begin test......\n",
      "Test Loss: 0.0058 Acc: 0.5699 Precision: 0.5672 Recall: 0.5699 f1score_micro: 0.5699 f1score_macro: 0.5676\n",
      "Epoch: 42/50\n",
      "Begin test......\n",
      "Test Loss: 0.0058 Acc: 0.5711 Precision: 0.5672 Recall: 0.5711 f1score_micro: 0.5711 f1score_macro: 0.5681\n",
      "Epoch: 43/50\n",
      "Begin test......\n",
      "Test Loss: 0.0058 Acc: 0.5711 Precision: 0.5682 Recall: 0.5711 f1score_micro: 0.5711 f1score_macro: 0.5689\n",
      "Epoch: 44/50\n",
      "Begin test......\n",
      "Test Loss: 0.0058 Acc: 0.5688 Precision: 0.5686 Recall: 0.5688 f1score_micro: 0.5688 f1score_macro: 0.5671\n",
      "Epoch: 45/50\n",
      "Begin test......\n",
      "Test Loss: 0.0058 Acc: 0.5706 Precision: 0.5680 Recall: 0.5706 f1score_micro: 0.5706 f1score_macro: 0.5678\n",
      "Epoch: 46/50\n",
      "Begin test......\n",
      "Test Loss: 0.0058 Acc: 0.5736 Precision: 0.5713 Recall: 0.5736 f1score_micro: 0.5736 f1score_macro: 0.5716\n",
      "Epoch: 47/50\n",
      "Begin test......\n",
      "Test Loss: 0.0058 Acc: 0.5726 Precision: 0.5701 Recall: 0.5726 f1score_micro: 0.5726 f1score_macro: 0.5705\n",
      "Epoch: 48/50\n",
      "Begin test......\n",
      "Test Loss: 0.0058 Acc: 0.5725 Precision: 0.5699 Recall: 0.5725 f1score_micro: 0.5725 f1score_macro: 0.5702\n",
      "Epoch: 49/50\n",
      "Begin test......\n",
      "Test Loss: 0.0058 Acc: 0.5736 Precision: 0.5711 Recall: 0.5736 f1score_micro: 0.5736 f1score_macro: 0.5718\n",
      "Epoch: 50/50\n",
      "Begin test......\n",
      "Test Loss: 0.0058 Acc: 0.5737 Precision: 0.5697 Recall: 0.5737 f1score_micro: 0.5737 f1score_macro: 0.5708\n"
     ]
    }
   ],
   "source": [
    "test_loss_l = []\n",
    "test_acc_l = []\n",
    "test_precision_l = []\n",
    "test_recall_l = []\n",
    "test_f1score_micro_l = []\n",
    "test_f1score_macro_l = []\n",
    "\n",
    "test_acc = torchmetrics.classification.MulticlassAccuracy(num_classes=10).to(device)\n",
    "test_precision = torchmetrics.classification.MulticlassPrecision(num_classes=10, average='macro').to(device)\n",
    "test_recall = torchmetrics.classification.MulticlassRecall(num_classes=10, average='macro').to(device)\n",
    "test_f1score_micro = torchmetrics.classification.MulticlassF1Score(num_classes=10, average='micro').to(device)\n",
    "test_f1score_macro = torchmetrics.classification.MulticlassF1Score(num_classes=10, average='macro').to(device)\n",
    "\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    # torch.cuda.empty_cache()\n",
    "\n",
    "    ##########################\n",
    "    ### Training\n",
    "    ##########################\n",
    "\n",
    "    for batch_idx, (image, target) in enumerate(train_dataloader):\n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # train model\n",
    "        outputs, loss = train_batch(model, image, target)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        \n",
    "        loss_data = loss.data.item()\n",
    "        if np.isnan(loss_data):\n",
    "            raise ValueError('loss is nan while training')\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{NUM_EPOCHS}')\n",
    "\n",
    "    # change learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    ##########################\n",
    "    ### Testing\n",
    "    ##########################\n",
    "    # # eval model during training or in the last epoch\n",
    "    if (epoch + 1) % EVAL_INTERVAL == 0 or (epoch +1) == NUM_EPOCHS:\n",
    "        print('Begin test......')\n",
    "        model.eval()\n",
    "        \n",
    "        test_loss = .0        \n",
    "        test_acc.reset()\n",
    "        test_precision.reset()    \n",
    "        test_recall.reset()\n",
    "        test_f1score_micro.reset()\n",
    "        test_f1score_macro.reset()\n",
    "\n",
    "        for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # test model\n",
    "            outputs, loss = test_batch(model, image, target)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            test_acc.update(preds, target)\n",
    "            test_precision.update(preds, target)\n",
    "            test_recall.update(preds, target)\n",
    "            test_f1score_micro.update(preds, target)\n",
    "            test_f1score_macro.update(preds, target)\n",
    "\n",
    "        val_loss = test_loss / len(test_set)\n",
    "        val_acc = test_acc.compute()\n",
    "        val_precision = test_precision.compute()\n",
    "        val_recall = test_recall.compute()\n",
    "        val_f1score_micro = test_f1score_micro.compute()\n",
    "        val_f1score_macro = test_f1score_macro.compute()\n",
    "        print(f'Test Loss: {val_loss:.4f} Acc: {val_acc:.4f} Precision: {val_precision:.4f} Recall: {val_recall:.4f} f1score_micro: {val_f1score_micro:.4f} f1score_macro: {val_f1score_macro:.4f}')\n",
    "\n",
    "        test_loss_l.append(test_loss)\n",
    "        test_acc_l.append(val_acc.cpu().detach().numpy())\n",
    "        test_precision_l.append(val_precision.cpu().detach().numpy())\n",
    "        test_recall_l.append(val_recall.cpu().detach().numpy())\n",
    "        test_f1score_micro_l.append(val_f1score_micro.cpu().numpy())\n",
    "        test_f1score_macro_l.append(val_f1score_macro.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log generated\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'acc': test_acc_l, 'precision': test_precision_l, 'recall': test_recall_l, 'f1score_micro': test_f1score_micro_l, 'f1score_macro': test_f1score_macro_l})\n",
    "df.to_csv('./log/focal_2.csv', index=False)\n",
    "print('log generated')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
