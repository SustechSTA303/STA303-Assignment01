{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Imports | Hyperparameters | Device | Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "## Basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchmetrics\n",
    "import random\n",
    "\n",
    "## Hyperparameters \n",
    "# random seed\n",
    "SEED = 1 \n",
    "NUM_CLASS = 10\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "setup_seed(SEED)\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 50\n",
    "EVAL_INTERVAL=1\n",
    "SAVE_DIR = './log'\n",
    "\n",
    "# Optimizer\n",
    "LEARNING_RATE = 1e-1\n",
    "MOMENTUM = 0.9\n",
    "STEP=5\n",
    "GAMMA=0.5\n",
    "\n",
    "## Device\n",
    "device = torch.device(\"cuda:6\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "## Dataset\n",
    "# cifar10 transform\n",
    "transform_cifar10_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_cifar10_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='../../data', train=True,\n",
    "                                        download=True, transform=transform_cifar10_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='../../data', train=False,\n",
    "                                       download=True, transform=transform_cifar10_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model | Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model def\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 4, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3)\n",
    "        self.fc1 = nn.Linear(8 * 6 * 6, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 8 * 6 * 6)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "## Init model\n",
    "model = ConvNet()\n",
    "model.to(device)\n",
    "\n",
    "## Init Optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### Modify here ###########################\n",
    "# Define the loss function\n",
    "criterion = nn.L1Loss()\n",
    "###############################################################\n",
    "\n",
    "## Define the batch train\n",
    "def train_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one training batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to train.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated by the defined loss function loss_fn().\n",
    "    \"\"\"\n",
    "    \n",
    "    ####################### Modify here ###########################\n",
    "    output = model(image)\n",
    "    loss = criterion(F.softmax(output, dim=1), F.one_hot(target, num_classes=10))\n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss\n",
    "\n",
    "\n",
    "def test_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one testing batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to evaluate.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated for the batch.\n",
    "    \"\"\"\n",
    "\n",
    "    ####################### Modify here ###########################\n",
    "    output = model(image)\n",
    "    loss = criterion(F.softmax(output, dim=1), F.one_hot(target, num_classes=10))\n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50\n",
      "Begin test......\n",
      "Test Loss: 0.0012 Acc: 0.2373 Precision: 0.1460 Recall: 0.2373 f1score_micro: 0.2373 f1score_macro: 0.1788\n",
      "Epoch: 2/50\n",
      "Begin test......\n",
      "Test Loss: 0.0012 Acc: 0.2603 Precision: 0.2198 Recall: 0.2603 f1score_micro: 0.2603 f1score_macro: 0.2016\n",
      "Epoch: 3/50\n",
      "Begin test......\n",
      "Test Loss: 0.0011 Acc: 0.3173 Precision: 0.2428 Recall: 0.3173 f1score_micro: 0.3173 f1score_macro: 0.2578\n",
      "Epoch: 4/50\n",
      "Begin test......\n",
      "Test Loss: 0.0011 Acc: 0.3243 Precision: 0.2606 Recall: 0.3243 f1score_micro: 0.3243 f1score_macro: 0.2819\n",
      "Epoch: 5/50\n",
      "Begin test......\n",
      "Test Loss: 0.0010 Acc: 0.3364 Precision: 0.2757 Recall: 0.3364 f1score_micro: 0.3364 f1score_macro: 0.2810\n",
      "Epoch: 6/50\n",
      "Begin test......\n",
      "Test Loss: 0.0010 Acc: 0.3484 Precision: 0.2870 Recall: 0.3484 f1score_micro: 0.3484 f1score_macro: 0.2918\n",
      "Epoch: 7/50\n",
      "Begin test......\n",
      "Test Loss: 0.0010 Acc: 0.3519 Precision: 0.2918 Recall: 0.3519 f1score_micro: 0.3519 f1score_macro: 0.3029\n",
      "Epoch: 8/50\n",
      "Begin test......\n",
      "Test Loss: 0.0010 Acc: 0.3702 Precision: 0.3072 Recall: 0.3702 f1score_micro: 0.3702 f1score_macro: 0.3188\n",
      "Epoch: 9/50\n",
      "Begin test......\n",
      "Test Loss: 0.0010 Acc: 0.3882 Precision: 0.3143 Recall: 0.3882 f1score_micro: 0.3882 f1score_macro: 0.3374\n",
      "Epoch: 10/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4104 Precision: 0.3337 Recall: 0.4104 f1score_micro: 0.4104 f1score_macro: 0.3586\n",
      "Epoch: 11/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4136 Precision: 0.3344 Recall: 0.4136 f1score_micro: 0.4136 f1score_macro: 0.3634\n",
      "Epoch: 12/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4199 Precision: 0.3499 Recall: 0.4199 f1score_micro: 0.4199 f1score_macro: 0.3642\n",
      "Epoch: 13/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4204 Precision: 0.3502 Recall: 0.4204 f1score_micro: 0.4204 f1score_macro: 0.3654\n",
      "Epoch: 14/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4275 Precision: 0.3546 Recall: 0.4275 f1score_micro: 0.4275 f1score_macro: 0.3808\n",
      "Epoch: 15/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4301 Precision: 0.3565 Recall: 0.4301 f1score_micro: 0.4301 f1score_macro: 0.3800\n",
      "Epoch: 16/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4371 Precision: 0.3557 Recall: 0.4371 f1score_micro: 0.4371 f1score_macro: 0.3825\n",
      "Epoch: 17/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4391 Precision: 0.3580 Recall: 0.4391 f1score_micro: 0.4391 f1score_macro: 0.3860\n",
      "Epoch: 18/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4457 Precision: 0.3605 Recall: 0.4457 f1score_micro: 0.4457 f1score_macro: 0.3922\n",
      "Epoch: 19/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4472 Precision: 0.3574 Recall: 0.4472 f1score_micro: 0.4472 f1score_macro: 0.3943\n",
      "Epoch: 20/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4413 Precision: 0.3583 Recall: 0.4413 f1score_micro: 0.4413 f1score_macro: 0.3856\n",
      "Epoch: 21/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4487 Precision: 0.3673 Recall: 0.4487 f1score_micro: 0.4487 f1score_macro: 0.3953\n",
      "Epoch: 22/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4497 Precision: 0.3667 Recall: 0.4497 f1score_micro: 0.4497 f1score_macro: 0.3980\n",
      "Epoch: 23/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4496 Precision: 0.3684 Recall: 0.4496 f1score_micro: 0.4496 f1score_macro: 0.3974\n",
      "Epoch: 24/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4539 Precision: 0.3666 Recall: 0.4539 f1score_micro: 0.4539 f1score_macro: 0.4003\n",
      "Epoch: 25/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4528 Precision: 0.3670 Recall: 0.4528 f1score_micro: 0.4528 f1score_macro: 0.3991\n",
      "Epoch: 26/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4545 Precision: 0.3672 Recall: 0.4545 f1score_micro: 0.4545 f1score_macro: 0.3992\n",
      "Epoch: 27/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4550 Precision: 0.3700 Recall: 0.4550 f1score_micro: 0.4550 f1score_macro: 0.3995\n",
      "Epoch: 28/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4582 Precision: 0.3706 Recall: 0.4582 f1score_micro: 0.4582 f1score_macro: 0.4023\n",
      "Epoch: 29/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4563 Precision: 0.3687 Recall: 0.4563 f1score_micro: 0.4563 f1score_macro: 0.4013\n",
      "Epoch: 30/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4585 Precision: 0.3726 Recall: 0.4585 f1score_micro: 0.4585 f1score_macro: 0.4024\n",
      "Epoch: 31/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4571 Precision: 0.3711 Recall: 0.4571 f1score_micro: 0.4571 f1score_macro: 0.4016\n",
      "Epoch: 32/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4585 Precision: 0.3726 Recall: 0.4585 f1score_micro: 0.4585 f1score_macro: 0.4040\n",
      "Epoch: 33/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4573 Precision: 0.3710 Recall: 0.4573 f1score_micro: 0.4573 f1score_macro: 0.4021\n",
      "Epoch: 34/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4582 Precision: 0.3700 Recall: 0.4582 f1score_micro: 0.4582 f1score_macro: 0.4027\n",
      "Epoch: 35/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4591 Precision: 0.3702 Recall: 0.4591 f1score_micro: 0.4591 f1score_macro: 0.4044\n",
      "Epoch: 36/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4601 Precision: 0.3728 Recall: 0.4601 f1score_micro: 0.4601 f1score_macro: 0.4047\n",
      "Epoch: 37/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4596 Precision: 0.3717 Recall: 0.4596 f1score_micro: 0.4596 f1score_macro: 0.4044\n",
      "Epoch: 38/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4596 Precision: 0.3739 Recall: 0.4596 f1score_micro: 0.4596 f1score_macro: 0.4047\n",
      "Epoch: 39/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4594 Precision: 0.3725 Recall: 0.4594 f1score_micro: 0.4594 f1score_macro: 0.4057\n",
      "Epoch: 40/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4592 Precision: 0.3710 Recall: 0.4592 f1score_micro: 0.4592 f1score_macro: 0.4044\n",
      "Epoch: 41/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4602 Precision: 0.3737 Recall: 0.4602 f1score_micro: 0.4602 f1score_macro: 0.4062\n",
      "Epoch: 42/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4601 Precision: 0.3720 Recall: 0.4601 f1score_micro: 0.4601 f1score_macro: 0.4054\n",
      "Epoch: 43/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4606 Precision: 0.3731 Recall: 0.4606 f1score_micro: 0.4606 f1score_macro: 0.4061\n",
      "Epoch: 44/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4595 Precision: 0.3727 Recall: 0.4595 f1score_micro: 0.4595 f1score_macro: 0.4051\n",
      "Epoch: 45/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4598 Precision: 0.3731 Recall: 0.4598 f1score_micro: 0.4598 f1score_macro: 0.4050\n",
      "Epoch: 46/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4601 Precision: 0.3729 Recall: 0.4601 f1score_micro: 0.4601 f1score_macro: 0.4056\n",
      "Epoch: 47/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4605 Precision: 0.3729 Recall: 0.4605 f1score_micro: 0.4605 f1score_macro: 0.4061\n",
      "Epoch: 48/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4607 Precision: 0.3729 Recall: 0.4607 f1score_micro: 0.4607 f1score_macro: 0.4060\n",
      "Epoch: 49/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4601 Precision: 0.3729 Recall: 0.4601 f1score_micro: 0.4601 f1score_macro: 0.4055\n",
      "Epoch: 50/50\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4596 Precision: 0.3726 Recall: 0.4596 f1score_micro: 0.4596 f1score_macro: 0.4052\n"
     ]
    }
   ],
   "source": [
    "test_loss_l = []\n",
    "test_acc_l = []\n",
    "test_precision_l = []\n",
    "test_recall_l = []\n",
    "test_f1score_micro_l = []\n",
    "test_f1score_macro_l = []\n",
    "\n",
    "test_acc = torchmetrics.classification.MulticlassAccuracy(num_classes=10).to(device)\n",
    "test_precision = torchmetrics.classification.MulticlassPrecision(num_classes=10, average='macro').to(device)\n",
    "test_recall = torchmetrics.classification.MulticlassRecall(num_classes=10, average='macro').to(device)\n",
    "test_f1score_micro = torchmetrics.classification.MulticlassF1Score(num_classes=10, average='micro').to(device)\n",
    "test_f1score_macro = torchmetrics.classification.MulticlassF1Score(num_classes=10, average='macro').to(device)\n",
    "\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    # torch.cuda.empty_cache()\n",
    "\n",
    "    ##########################\n",
    "    ### Training\n",
    "    ##########################\n",
    "\n",
    "    for batch_idx, (image, target) in enumerate(train_dataloader):\n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # train model\n",
    "        outputs, loss = train_batch(model, image, target)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        \n",
    "        loss_data = loss.data.item()\n",
    "        if np.isnan(loss_data):\n",
    "            raise ValueError('loss is nan while training')\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{NUM_EPOCHS}')\n",
    "\n",
    "    # change learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    ##########################\n",
    "    ### Testing\n",
    "    ##########################\n",
    "    # # eval model during training or in the last epoch\n",
    "    if (epoch + 1) % EVAL_INTERVAL == 0 or (epoch +1) == NUM_EPOCHS:\n",
    "        print('Begin test......')\n",
    "        model.eval()\n",
    "        \n",
    "        test_loss = .0        \n",
    "        test_acc.reset()\n",
    "        test_precision.reset()    \n",
    "        test_recall.reset()\n",
    "        test_f1score_micro.reset()\n",
    "        test_f1score_macro.reset()\n",
    "\n",
    "        for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # test model\n",
    "            outputs, loss = test_batch(model, image, target)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            test_acc.update(preds, target)\n",
    "            test_precision.update(preds, target)\n",
    "            test_recall.update(preds, target)\n",
    "            test_f1score_micro.update(preds, target)\n",
    "            test_f1score_macro.update(preds, target)\n",
    "\n",
    "        val_loss = test_loss / len(test_set)\n",
    "        val_acc = test_acc.compute()\n",
    "        val_precision = test_precision.compute()\n",
    "        val_recall = test_recall.compute()\n",
    "        val_f1score_micro = test_f1score_micro.compute()\n",
    "        val_f1score_macro = test_f1score_macro.compute()\n",
    "        print(f'Test Loss: {val_loss:.4f} Acc: {val_acc:.4f} Precision: {val_precision:.4f} Recall: {val_recall:.4f} f1score_micro: {val_f1score_micro:.4f} f1score_macro: {val_f1score_macro:.4f}')\n",
    "\n",
    "        test_loss_l.append(test_loss)\n",
    "        test_acc_l.append(val_acc.cpu().detach().numpy())\n",
    "        test_precision_l.append(val_precision.cpu().detach().numpy())\n",
    "        test_recall_l.append(val_recall.cpu().detach().numpy())\n",
    "        test_f1score_micro_l.append(val_f1score_micro.cpu().numpy())\n",
    "        test_f1score_macro_l.append(val_f1score_macro.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log generated\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'acc': test_acc_l, 'precision': test_precision_l, 'recall': test_recall_l, 'f1score_micro': test_f1score_micro_l, 'f1score_macro': test_f1score_macro_l})\n",
    "df.to_csv('./log/mae.csv', index=False)\n",
    "print('log generated')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
