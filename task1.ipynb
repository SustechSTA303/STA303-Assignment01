{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4438cec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "SEED = 1 \n",
    "NUM_CLASS = 10\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 30\n",
    "EVAL_INTERVAL=1\n",
    "SAVE_DIR = './log'\n",
    "LEARNING_RATE = 1e-1\n",
    "MOMENTUM = 0.9\n",
    "STEP=5\n",
    "GAMMA=0.5\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform_cifar10_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_cifar10_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='../data', train=True,\n",
    "                                        download=True, transform=transform_cifar10_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='../data', train=False,\n",
    "                                       download=True, transform=transform_cifar10_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "993dedaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40291/4218948423.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  loss = torch.tensor(loss, requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30 Train Loss: 0.0228 Acc: 0.1158\n",
      "Begin test......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40291/4218948423.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  loss = torch.tensor(loss, requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0228 Acc: 0.1165\n",
      "Epoch: 2/30 Train Loss: 0.0228 Acc: 0.1167\n",
      "Begin test......\n",
      "Test Loss: 0.0228 Acc: 0.1165\n",
      "Epoch: 3/30 Train Loss: 0.0228 Acc: 0.1165\n",
      "Begin test......\n",
      "Test Loss: 0.0228 Acc: 0.1165\n",
      "Epoch: 4/30 Train Loss: 0.0227 Acc: 0.1180\n",
      "Begin test......\n",
      "Test Loss: 0.0228 Acc: 0.1165\n",
      "Epoch: 5/30 Train Loss: 0.0227 Acc: 0.1175\n",
      "Begin test......\n",
      "Test Loss: 0.0228 Acc: 0.1165\n",
      "Epoch: 6/30 Train Loss: 0.0227 Acc: 0.1163\n",
      "Begin test......\n",
      "Test Loss: 0.0228 Acc: 0.1165\n",
      "Epoch: 7/30 Train Loss: 0.0227 Acc: 0.1166\n",
      "Begin test......\n",
      "Test Loss: 0.0228 Acc: 0.1165\n",
      "Epoch: 8/30 Train Loss: 0.0228 Acc: 0.1162\n",
      "Begin test......\n",
      "Test Loss: 0.0228 Acc: 0.1165\n",
      "Epoch: 9/30 Train Loss: 0.0228 Acc: 0.1187\n",
      "Begin test......\n",
      "Test Loss: 0.0228 Acc: 0.1165\n",
      "Epoch: 10/30 Train Loss: 0.0228 Acc: 0.1165\n",
      "Begin test......\n",
      "Test Loss: 0.0228 Acc: 0.1165\n",
      "Epoch: 11/30 Train Loss: 0.0228 Acc: 0.1166\n",
      "Begin test......\n",
      "Test Loss: 0.0228 Acc: 0.1165\n",
      "Epoch: 12/30 Train Loss: 0.0228 Acc: 0.1162\n",
      "Begin test......\n",
      "Test Loss: 0.0228 Acc: 0.1165\n",
      "Epoch: 13/30 Train Loss: 0.0227 Acc: 0.1153\n",
      "Begin test......\n",
      "Test Loss: 0.0228 Acc: 0.1165\n",
      "Epoch: 14/30 Train Loss: 0.0228 Acc: 0.1162\n",
      "Begin test......\n",
      "Test Loss: 0.0228 Acc: 0.1165\n",
      "Epoch: 15/30 Train Loss: 0.0227 Acc: 0.1189\n",
      "Begin test......\n",
      "Test Loss: 0.0228 Acc: 0.1165\n",
      "Epoch: 16/30 Train Loss: 0.0228 Acc: 0.1156\n",
      "Begin test......\n",
      "Test Loss: 0.0228 Acc: 0.1165\n",
      "Epoch: 17/30 Train Loss: 0.0227 Acc: 0.1163\n",
      "Begin test......\n",
      "Test Loss: 0.0228 Acc: 0.1165\n",
      "Epoch: 18/30 Train Loss: 0.0227 Acc: 0.1173\n",
      "Begin test......\n",
      "Test Loss: 0.0228 Acc: 0.1165\n",
      "Epoch: 19/30 Train Loss: 0.0228 Acc: 0.1163\n",
      "Begin test......\n",
      "Test Loss: 0.0228 Acc: 0.1165\n",
      "Epoch: 20/30 Train Loss: 0.0228 Acc: 0.1175\n",
      "Begin test......\n",
      "Test Loss: 0.0228 Acc: 0.1165\n",
      "Epoch: 21/30 Train Loss: 0.0228 Acc: 0.1167\n",
      "Begin test......\n",
      "Test Loss: 0.0228 Acc: 0.1165\n",
      "Epoch: 22/30 Train Loss: 0.0227 Acc: 0.1166\n",
      "Begin test......\n",
      "Test Loss: 0.0228 Acc: 0.1165\n",
      "Epoch: 23/30 Train Loss: 0.0228 Acc: 0.1168\n",
      "Begin test......\n",
      "Test Loss: 0.0228 Acc: 0.1165\n",
      "Epoch: 24/30 Train Loss: 0.0227 Acc: 0.1168\n",
      "Begin test......\n",
      "Test Loss: 0.0228 Acc: 0.1165\n",
      "Epoch: 25/30 Train Loss: 0.0227 Acc: 0.1163\n",
      "Begin test......\n",
      "Test Loss: 0.0228 Acc: 0.1165\n",
      "Epoch: 26/30 Train Loss: 0.0227 Acc: 0.1168\n",
      "Begin test......\n",
      "Test Loss: 0.0228 Acc: 0.1165\n",
      "Epoch: 27/30 Train Loss: 0.0227 Acc: 0.1174\n",
      "Begin test......\n",
      "Test Loss: 0.0228 Acc: 0.1165\n",
      "Epoch: 28/30 Train Loss: 0.0228 Acc: 0.1163\n",
      "Begin test......\n",
      "Test Loss: 0.0228 Acc: 0.1165\n",
      "Epoch: 29/30 Train Loss: 0.0227 Acc: 0.1168\n",
      "Begin test......\n",
      "Test Loss: 0.0228 Acc: 0.1165\n",
      "Epoch: 30/30 Train Loss: 0.0227 Acc: 0.1169\n",
      "Begin test......\n",
      "Test Loss: 0.0228 Acc: 0.1165\n",
      "[0.1165 0.1165 0.1165 0.1165 0.1165 0.1165 0.1165 0.1165 0.1165 0.1165\n",
      " 0.1165 0.1165 0.1165 0.1165 0.1165 0.1165 0.1165 0.1165 0.1165 0.1165\n",
      " 0.1165 0.1165 0.1165 0.1165 0.1165 0.1165 0.1165 0.1165 0.1165 0.1165]\n"
     ]
    }
   ],
   "source": [
    "# MAE(L1) loss\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 4, 3)  \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3)  \n",
    "        self.fc1 = nn.Linear(8 * 6 * 6, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 8 * 6 * 6)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "model = ConvNet()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "def train_batch(model, image, target):\n",
    "    output = model(image)\n",
    "    output = torch.max(output, dim=1)[1]\n",
    "    output = output.float()\n",
    "    target = target.float()\n",
    "    loss = criterion(output, target)\n",
    "    loss = torch.tensor(loss, requires_grad=True)\n",
    "    output = model(image)  \n",
    "    return output, loss\n",
    "\n",
    "def test_batch(model, image, target):\n",
    "    output = model(image) \n",
    "    output = torch.max(output, dim=1)[1]\n",
    "    output = output.float()\n",
    "    target = target.float()   \n",
    "    loss = criterion(output, target)\n",
    "    loss = torch.tensor(loss, requires_grad=True)\n",
    "    output = model(image)\n",
    "    return output, loss\n",
    "\n",
    "training_loss = []\n",
    "training_acc = []\n",
    "testing_loss = []\n",
    "testing_acc = []\n",
    "\n",
    "list = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    torch.cuda.empty_cache()\n",
    "    running_cls_loss = 0.0\n",
    "    running_cls_corrects = 0\n",
    "    for batch_idx, (image, target) in enumerate(train_dataloader):\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "        outputs, loss = train_batch(model, image, target)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss_data = loss.data.item()\n",
    "        if np.isnan(loss_data):\n",
    "            raise ValueError('loss is nan while training')\n",
    "        running_cls_loss += loss.item()\n",
    "        running_cls_corrects += torch.sum(preds == target.data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    epoch_loss = running_cls_loss / len(train_set)\n",
    "    epoch_acc = running_cls_corrects.double() / len(train_set)\n",
    "    print(f'Epoch: {epoch+1}/{NUM_EPOCHS} Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "    training_loss.append(epoch_loss)\n",
    "    training_acc.append(epoch_acc.cpu().detach().numpy())\n",
    "    scheduler.step()\n",
    "    if (epoch + 1) % EVAL_INTERVAL == 0 or (epoch +1) == NUM_EPOCHS:\n",
    "        print('Begin test......')\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "            outputs, loss = test_batch(model, image, target)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_loss += loss.item()\n",
    "            val_corrects += torch.sum(preds == target.data)\n",
    "        val_loss = val_loss / len(test_set)\n",
    "        val_acc = val_corrects.double() / len(test_set)\n",
    "        print(f'Test Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "        list.append(val_acc)\n",
    "        testing_loss.append(val_loss)\n",
    "        testing_acc.append(val_acc.cpu().detach().numpy())\n",
    "        if (epoch +1) == NUM_EPOCHS:  \n",
    "            state = {\n",
    "            'state_dict': model.state_dict(),\n",
    "            'acc': epoch_acc,\n",
    "            'epoch': (epoch+1),\n",
    "            }\n",
    "            if not os.path.exists(SAVE_DIR):\n",
    "                os.makedirs(SAVE_DIR)\n",
    "            torch.save(state, osp.join(SAVE_DIR, 'checkpoint_%s.pth' % (str(epoch+1))))\n",
    "\n",
    "MAE_L1_Acc = np.array([tensor.item() for tensor in list])\n",
    "print(MAE_L1_Acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6be67e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30 Train Loss: 0.0151 Acc: 0.2823\n",
      "Begin test......\n",
      "Test Loss: 0.0139 Acc: 0.3649\n",
      "Epoch: 2/30 Train Loss: 0.0139 Acc: 0.3421\n",
      "Begin test......\n",
      "Test Loss: 0.0139 Acc: 0.3691\n",
      "Epoch: 3/30 Train Loss: 0.0137 Acc: 0.3577\n",
      "Begin test......\n",
      "Test Loss: 0.0129 Acc: 0.4074\n",
      "Epoch: 4/30 Train Loss: 0.0135 Acc: 0.3726\n",
      "Begin test......\n",
      "Test Loss: 0.0129 Acc: 0.4136\n",
      "Epoch: 5/30 Train Loss: 0.0136 Acc: 0.3677\n",
      "Begin test......\n",
      "Test Loss: 0.0126 Acc: 0.4042\n",
      "Epoch: 6/30 Train Loss: 0.0125 Acc: 0.4229\n",
      "Begin test......\n",
      "Test Loss: 0.0117 Acc: 0.4625\n",
      "Epoch: 7/30 Train Loss: 0.0122 Acc: 0.4326\n",
      "Begin test......\n",
      "Test Loss: 0.0112 Acc: 0.4936\n",
      "Epoch: 8/30 Train Loss: 0.0121 Acc: 0.4418\n",
      "Begin test......\n",
      "Test Loss: 0.0116 Acc: 0.4734\n",
      "Epoch: 9/30 Train Loss: 0.0120 Acc: 0.4506\n",
      "Begin test......\n",
      "Test Loss: 0.0113 Acc: 0.4889\n",
      "Epoch: 10/30 Train Loss: 0.0120 Acc: 0.4497\n",
      "Begin test......\n",
      "Test Loss: 0.0114 Acc: 0.4902\n",
      "Epoch: 11/30 Train Loss: 0.0114 Acc: 0.4806\n",
      "Begin test......\n",
      "Test Loss: 0.0107 Acc: 0.5186\n",
      "Epoch: 12/30 Train Loss: 0.0112 Acc: 0.4868\n",
      "Begin test......\n",
      "Test Loss: 0.0109 Acc: 0.5074\n",
      "Epoch: 13/30 Train Loss: 0.0112 Acc: 0.4884\n",
      "Begin test......\n",
      "Test Loss: 0.0108 Acc: 0.5108\n",
      "Epoch: 14/30 Train Loss: 0.0112 Acc: 0.4875\n",
      "Begin test......\n",
      "Test Loss: 0.0104 Acc: 0.5299\n",
      "Epoch: 15/30 Train Loss: 0.0111 Acc: 0.4912\n",
      "Begin test......\n",
      "Test Loss: 0.0104 Acc: 0.5296\n",
      "Epoch: 16/30 Train Loss: 0.0107 Acc: 0.5085\n",
      "Begin test......\n",
      "Test Loss: 0.0100 Acc: 0.5477\n",
      "Epoch: 17/30 Train Loss: 0.0106 Acc: 0.5141\n",
      "Begin test......\n",
      "Test Loss: 0.0100 Acc: 0.5514\n",
      "Epoch: 18/30 Train Loss: 0.0106 Acc: 0.5147\n",
      "Begin test......\n",
      "Test Loss: 0.0099 Acc: 0.5509\n",
      "Epoch: 19/30 Train Loss: 0.0105 Acc: 0.5162\n",
      "Begin test......\n",
      "Test Loss: 0.0103 Acc: 0.5400\n",
      "Epoch: 20/30 Train Loss: 0.0105 Acc: 0.5238\n",
      "Begin test......\n",
      "Test Loss: 0.0098 Acc: 0.5588\n",
      "Epoch: 21/30 Train Loss: 0.0102 Acc: 0.5324\n",
      "Begin test......\n",
      "Test Loss: 0.0096 Acc: 0.5670\n",
      "Epoch: 22/30 Train Loss: 0.0102 Acc: 0.5350\n",
      "Begin test......\n",
      "Test Loss: 0.0096 Acc: 0.5637\n",
      "Epoch: 23/30 Train Loss: 0.0102 Acc: 0.5352\n",
      "Begin test......\n",
      "Test Loss: 0.0096 Acc: 0.5669\n",
      "Epoch: 24/30 Train Loss: 0.0102 Acc: 0.5360\n",
      "Begin test......\n",
      "Test Loss: 0.0095 Acc: 0.5680\n",
      "Epoch: 25/30 Train Loss: 0.0102 Acc: 0.5383\n",
      "Begin test......\n",
      "Test Loss: 0.0096 Acc: 0.5699\n",
      "Epoch: 26/30 Train Loss: 0.0100 Acc: 0.5447\n",
      "Begin test......\n",
      "Test Loss: 0.0094 Acc: 0.5696\n",
      "Epoch: 27/30 Train Loss: 0.0100 Acc: 0.5451\n",
      "Begin test......\n",
      "Test Loss: 0.0094 Acc: 0.5716\n",
      "Epoch: 28/30 Train Loss: 0.0100 Acc: 0.5450\n",
      "Begin test......\n",
      "Test Loss: 0.0094 Acc: 0.5727\n",
      "Epoch: 29/30 Train Loss: 0.0099 Acc: 0.5479\n",
      "Begin test......\n",
      "Test Loss: 0.0095 Acc: 0.5756\n",
      "Epoch: 30/30 Train Loss: 0.0100 Acc: 0.5479\n",
      "Begin test......\n",
      "Test Loss: 0.0094 Acc: 0.5759\n",
      "[0.3649 0.3691 0.4074 0.4136 0.4042 0.4625 0.4936 0.4734 0.4889 0.4902\n",
      " 0.5186 0.5074 0.5108 0.5299 0.5296 0.5477 0.5514 0.5509 0.54   0.5588\n",
      " 0.567  0.5637 0.5669 0.568  0.5699 0.5696 0.5716 0.5727 0.5756 0.5759]\n"
     ]
    }
   ],
   "source": [
    "# CE loss\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 4, 3)  \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3)  \n",
    "        self.fc1 = nn.Linear(8 * 6 * 6, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 8 * 6 * 6)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "model = ConvNet()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train_batch(model, image, target):\n",
    "    output = model(image)\n",
    "    loss = criterion(output, target) \n",
    "    return output, loss\n",
    "\n",
    "def test_batch(model, image, target):\n",
    "    output = model(image)   \n",
    "    loss = criterion(output, target)\n",
    "    return output, loss\n",
    "\n",
    "training_loss = []\n",
    "training_acc = []\n",
    "testing_loss = []\n",
    "testing_acc = []\n",
    "\n",
    "list = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    torch.cuda.empty_cache()\n",
    "    running_cls_loss = 0.0\n",
    "    running_cls_corrects = 0\n",
    "    for batch_idx, (image, target) in enumerate(train_dataloader):\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "        outputs, loss = train_batch(model, image, target)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss_data = loss.data.item()\n",
    "        if np.isnan(loss_data):\n",
    "            raise ValueError('loss is nan while training')\n",
    "        running_cls_loss += loss.item()\n",
    "        running_cls_corrects += torch.sum(preds == target.data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    epoch_loss = running_cls_loss / len(train_set)\n",
    "    epoch_acc = running_cls_corrects.double() / len(train_set)\n",
    "    print(f'Epoch: {epoch+1}/{NUM_EPOCHS} Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "    training_loss.append(epoch_loss)\n",
    "    training_acc.append(epoch_acc.cpu().detach().numpy())\n",
    "    scheduler.step()\n",
    "    if (epoch + 1) % EVAL_INTERVAL == 0 or (epoch +1) == NUM_EPOCHS:\n",
    "        print('Begin test......')\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "            outputs, loss = test_batch(model, image, target)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_loss += loss.item()\n",
    "            val_corrects += torch.sum(preds == target.data)\n",
    "        val_loss = val_loss / len(test_set)\n",
    "        val_acc = val_corrects.double() / len(test_set)\n",
    "        print(f'Test Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "        list.append(val_acc)\n",
    "        testing_loss.append(val_loss)\n",
    "        testing_acc.append(val_acc.cpu().detach().numpy())\n",
    "        if (epoch +1) == NUM_EPOCHS:  \n",
    "            state = {\n",
    "            'state_dict': model.state_dict(),\n",
    "            'acc': epoch_acc,\n",
    "            'epoch': (epoch+1),\n",
    "            }\n",
    "            if not os.path.exists(SAVE_DIR):\n",
    "                os.makedirs(SAVE_DIR)\n",
    "            torch.save(state, osp.join(SAVE_DIR, 'checkpoint_%s.pth' % (str(epoch+1))))\n",
    "\n",
    "CE_Acc = np.array([tensor.item() for tensor in list])\n",
    "print(CE_Acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71b9763a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30 Train Loss: 0.0014 Acc: 0.2751\n",
      "Begin test......\n",
      "Test Loss: 0.0012 Acc: 0.4067\n",
      "Epoch: 18/30 Train Loss: 0.0009 Acc: 0.5431\n",
      "Begin test......\n",
      "Test Loss: 0.0008 Acc: 0.5816\n",
      "Epoch: 19/30 Train Loss: 0.0009 Acc: 0.5417\n",
      "Begin test......\n",
      "Test Loss: 0.0008 Acc: 0.5834\n",
      "Epoch: 20/30 Train Loss: 0.0009 Acc: 0.5440\n",
      "Begin test......\n",
      "Test Loss: 0.0008 Acc: 0.5818\n",
      "Epoch: 21/30 Train Loss: 0.0009 Acc: 0.5495\n",
      "Begin test......\n",
      "Test Loss: 0.0008 Acc: 0.5828\n",
      "Epoch: 22/30 Train Loss: 0.0009 Acc: 0.5503\n",
      "Begin test......\n",
      "Test Loss: 0.0008 Acc: 0.5856\n",
      "Epoch: 23/30 Train Loss: 0.0009 Acc: 0.5497\n",
      "Begin test......\n",
      "Test Loss: 0.0008 Acc: 0.5853\n",
      "Epoch: 24/30 Train Loss: 0.0009 Acc: 0.5500\n",
      "Begin test......\n",
      "Test Loss: 0.0008 Acc: 0.5877\n",
      "Epoch: 25/30 Train Loss: 0.0009 Acc: 0.5517\n",
      "Begin test......\n",
      "Test Loss: 0.0008 Acc: 0.5875\n",
      "Epoch: 26/30 Train Loss: 0.0009 Acc: 0.5532\n",
      "Begin test......\n",
      "Test Loss: 0.0008 Acc: 0.5891\n",
      "Epoch: 27/30 Train Loss: 0.0009 Acc: 0.5516\n",
      "Begin test......\n",
      "Test Loss: 0.0008 Acc: 0.5901\n",
      "Epoch: 28/30 Train Loss: 0.0009 Acc: 0.5538\n",
      "Begin test......\n",
      "Test Loss: 0.0008 Acc: 0.5906\n",
      "Epoch: 29/30 Train Loss: 0.0009 Acc: 0.5560\n",
      "Begin test......\n",
      "Test Loss: 0.0008 Acc: 0.5877\n",
      "Epoch: 30/30 Train Loss: 0.0009 Acc: 0.5548\n",
      "Begin test......\n",
      "Test Loss: 0.0008 Acc: 0.5909\n",
      "[0.4067 0.4568 0.4994 0.4926 0.5174 0.5282 0.5489 0.5387 0.5361 0.5429\n",
      " 0.5654 0.5658 0.5722 0.571  0.5796 0.5772 0.5782 0.5816 0.5834 0.5818\n",
      " 0.5828 0.5856 0.5853 0.5877 0.5875 0.5891 0.5901 0.5906 0.5877 0.5909]\n"
     ]
    }
   ],
   "source": [
    "# Focal loss (gamma=0.5)\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 4, 3)  \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3)  \n",
    "        self.fc1 = nn.Linear(8 * 6 * 6, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 8 * 6 * 6)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "model = ConvNet()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, gamma, alpha = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]):\n",
    "        # 问题是10分类的，我们假设每个类别出现的次数无明显差异\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = torch.tensor(alpha)\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, output, target):\n",
    "        # 注意这里的output是128*10的二维tensor，其实也没必要特别注意啦，一直都是一样的\n",
    "        # 移到device上进行操作，避免报错\n",
    "        alpha = self.alpha.to(device)\n",
    "        alpha = alpha[target]\n",
    "        log_softmax = torch.log_softmax(output, dim=1) # 对模型裸输出做softmax再取log, shape=(bs, 3)\n",
    "        logpt = torch.gather(log_softmax, dim=1, index=target.view(-1, 1))  # 取出每个样本在类别标签位置的log_softmax值, shape=(bs, 1)\n",
    "        logpt = logpt.view(-1)  # 降维，shape=(bs)\n",
    "        ce_loss = -logpt  # 对log_softmax再取负，就是交叉熵了\n",
    "        pt = torch.exp(logpt)  #对log_softmax取exp，把log消了，就是每个样本在类别标签位置的softmax值了，shape=(bs)\n",
    "        focal_loss = alpha * (1 - pt) ** self.gamma * ce_loss  # 根据公式计算focal loss，得到每个样本的loss值，shape=(bs)\n",
    "        return torch.mean(focal_loss)\n",
    "    \n",
    "criterion = FocalLoss(0.5)\n",
    "\n",
    "def train_batch(model, image, target):\n",
    "    output = model(image)\n",
    "    loss = criterion(output, target) \n",
    "    return output, loss\n",
    "\n",
    "def test_batch(model, image, target):\n",
    "    output = model(image)   \n",
    "    loss = criterion(output, target)\n",
    "    return output, loss\n",
    "\n",
    "training_loss = []\n",
    "training_acc = []\n",
    "testing_loss = []\n",
    "testing_acc = []\n",
    "\n",
    "list = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    torch.cuda.empty_cache()\n",
    "    running_cls_loss = 0.0\n",
    "    running_cls_corrects = 0\n",
    "    for batch_idx, (image, target) in enumerate(train_dataloader):\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "        outputs, loss = train_batch(model, image, target)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss_data = loss.data.item()\n",
    "        if np.isnan(loss_data):\n",
    "            raise ValueError('loss is nan while training')\n",
    "        running_cls_loss += loss.item()\n",
    "        running_cls_corrects += torch.sum(preds == target.data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    epoch_loss = running_cls_loss / len(train_set)\n",
    "    epoch_acc = running_cls_corrects.double() / len(train_set)\n",
    "    print(f'Epoch: {epoch+1}/{NUM_EPOCHS} Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "    training_loss.append(epoch_loss)\n",
    "    training_acc.append(epoch_acc.cpu().detach().numpy())\n",
    "    scheduler.step()\n",
    "    if (epoch + 1) % EVAL_INTERVAL == 0 or (epoch +1) == NUM_EPOCHS:\n",
    "        print('Begin test......')\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "            outputs, loss = test_batch(model, image, target)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_loss += loss.item()\n",
    "            val_corrects += torch.sum(preds == target.data)\n",
    "        val_loss = val_loss / len(test_set)\n",
    "        val_acc = val_corrects.double() / len(test_set)\n",
    "        print(f'Test Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "        list.append(val_acc)\n",
    "        testing_loss.append(val_loss)\n",
    "        testing_acc.append(val_acc.cpu().detach().numpy())\n",
    "        if (epoch +1) == NUM_EPOCHS:  \n",
    "            state = {\n",
    "            'state_dict': model.state_dict(),\n",
    "            'acc': epoch_acc,\n",
    "            'epoch': (epoch+1),\n",
    "            }\n",
    "            if not os.path.exists(SAVE_DIR):\n",
    "                os.makedirs(SAVE_DIR)\n",
    "            torch.save(state, osp.join(SAVE_DIR, 'checkpoint_%s.pth' % (str(epoch+1))))\n",
    "\n",
    "Focal_gamma01 = np.array([tensor.item() for tensor in list])\n",
    "print(Focal_gamma01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab44f5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30 Train Loss: 0.0011 Acc: 0.2928\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4266\n",
      "Epoch: 2/30 Train Loss: 0.0009 Acc: 0.4050\n",
      "Begin test......\n",
      "Test Loss: 0.0008 Acc: 0.4770\n",
      "Epoch: 3/30 Train Loss: 0.0008 Acc: 0.4359\n",
      "Begin test......\n",
      "Test Loss: 0.0007 Acc: 0.4966\n",
      "Epoch: 4/30 Train Loss: 0.0008 Acc: 0.4587\n",
      "Begin test......\n",
      "Test Loss: 0.0007 Acc: 0.5032\n",
      "Epoch: 5/30 Train Loss: 0.0008 Acc: 0.4704\n",
      "Begin test......\n",
      "Test Loss: 0.0007 Acc: 0.5077\n",
      "Epoch: 6/30 Train Loss: 0.0007 Acc: 0.4955\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5462\n",
      "Epoch: 7/30 Train Loss: 0.0007 Acc: 0.5010\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5432\n",
      "Epoch: 8/30 Train Loss: 0.0007 Acc: 0.5055\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5407\n",
      "Epoch: 9/30 Train Loss: 0.0007 Acc: 0.5101\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5544\n",
      "Epoch: 10/30 Train Loss: 0.0007 Acc: 0.5115\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5537\n",
      "Epoch: 11/30 Train Loss: 0.0007 Acc: 0.5208\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5691\n",
      "Epoch: 12/30 Train Loss: 0.0007 Acc: 0.5222\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5681\n",
      "Epoch: 13/30 Train Loss: 0.0007 Acc: 0.5266\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5694\n",
      "Epoch: 14/30 Train Loss: 0.0007 Acc: 0.5289\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5660\n",
      "Epoch: 15/30 Train Loss: 0.0007 Acc: 0.5281\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5643\n",
      "Epoch: 16/30 Train Loss: 0.0007 Acc: 0.5313\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5786\n",
      "Epoch: 17/30 Train Loss: 0.0006 Acc: 0.5372\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5826\n",
      "Epoch: 18/30 Train Loss: 0.0007 Acc: 0.5356\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5718\n",
      "Epoch: 19/30 Train Loss: 0.0006 Acc: 0.5372\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5813\n",
      "Epoch: 20/30 Train Loss: 0.0006 Acc: 0.5369\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5778\n",
      "Epoch: 21/30 Train Loss: 0.0006 Acc: 0.5392\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5846\n",
      "Epoch: 22/30 Train Loss: 0.0006 Acc: 0.5409\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5828\n",
      "Epoch: 23/30 Train Loss: 0.0006 Acc: 0.5417\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5813\n",
      "Epoch: 24/30 Train Loss: 0.0006 Acc: 0.5405\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5813\n",
      "Epoch: 25/30 Train Loss: 0.0006 Acc: 0.5405\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5820\n",
      "Epoch: 26/30 Train Loss: 0.0006 Acc: 0.5438\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5819\n",
      "Epoch: 27/30 Train Loss: 0.0006 Acc: 0.5413\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5843\n",
      "Epoch: 28/30 Train Loss: 0.0006 Acc: 0.5429\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5865\n",
      "Epoch: 29/30 Train Loss: 0.0006 Acc: 0.5468\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5860\n",
      "Epoch: 30/30 Train Loss: 0.0006 Acc: 0.5451\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5875\n",
      "[0.4266 0.477  0.4966 0.5032 0.5077 0.5462 0.5432 0.5407 0.5544 0.5537\n",
      " 0.5691 0.5681 0.5694 0.566  0.5643 0.5786 0.5826 0.5718 0.5813 0.5778\n",
      " 0.5846 0.5828 0.5813 0.5813 0.582  0.5819 0.5843 0.5865 0.586  0.5875]\n",
      "Epoch: 1/30 Train Loss: 0.0011 Acc: 0.3093\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.4234\n",
      "Epoch: 2/30 Train Loss: 0.0009 Acc: 0.4119\n",
      "Begin test......\n",
      "Test Loss: 0.0007 Acc: 0.4809\n",
      "Epoch: 3/30 Train Loss: 0.0008 Acc: 0.4434\n",
      "Begin test......\n",
      "Test Loss: 0.0007 Acc: 0.4977\n",
      "Epoch: 4/30 Train Loss: 0.0008 Acc: 0.4630\n",
      "Begin test......\n",
      "Test Loss: 0.0007 Acc: 0.5114\n",
      "Epoch: 5/30 Train Loss: 0.0008 Acc: 0.4761\n",
      "Begin test......\n",
      "Test Loss: 0.0007 Acc: 0.5226\n",
      "Epoch: 6/30 Train Loss: 0.0007 Acc: 0.5018\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5501\n",
      "Epoch: 7/30 Train Loss: 0.0007 Acc: 0.5058\n",
      "Begin test......\n",
      "Test Loss: 0.0007 Acc: 0.5354\n",
      "Epoch: 8/30 Train Loss: 0.0007 Acc: 0.5126\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5568\n",
      "Epoch: 9/30 Train Loss: 0.0007 Acc: 0.5172\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5449\n",
      "Epoch: 10/30 Train Loss: 0.0007 Acc: 0.5196\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5463\n",
      "Epoch: 11/30 Train Loss: 0.0007 Acc: 0.5299\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5751\n",
      "Epoch: 12/30 Train Loss: 0.0007 Acc: 0.5338\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5727\n",
      "Epoch: 13/30 Train Loss: 0.0007 Acc: 0.5354\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5753\n",
      "Epoch: 14/30 Train Loss: 0.0007 Acc: 0.5364\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5765\n",
      "Epoch: 15/30 Train Loss: 0.0006 Acc: 0.5379\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5717\n",
      "Epoch: 16/30 Train Loss: 0.0006 Acc: 0.5441\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5874\n",
      "Epoch: 17/30 Train Loss: 0.0006 Acc: 0.5458\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5814\n",
      "Epoch: 18/30 Train Loss: 0.0006 Acc: 0.5472\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5794\n",
      "Epoch: 19/30 Train Loss: 0.0006 Acc: 0.5472\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5838\n",
      "Epoch: 20/30 Train Loss: 0.0006 Acc: 0.5487\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5847\n",
      "Epoch: 21/30 Train Loss: 0.0006 Acc: 0.5495\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5854\n",
      "Epoch: 22/30 Train Loss: 0.0006 Acc: 0.5537\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5879\n",
      "Epoch: 23/30 Train Loss: 0.0006 Acc: 0.5507\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5888\n",
      "Epoch: 24/30 Train Loss: 0.0006 Acc: 0.5515\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5883\n",
      "Epoch: 25/30 Train Loss: 0.0006 Acc: 0.5508\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5901\n",
      "Epoch: 26/30 Train Loss: 0.0006 Acc: 0.5503\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5901\n",
      "Epoch: 27/30 Train Loss: 0.0006 Acc: 0.5561\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5894\n",
      "Epoch: 28/30 Train Loss: 0.0006 Acc: 0.5568\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5888\n",
      "Epoch: 29/30 Train Loss: 0.0006 Acc: 0.5547\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5903\n",
      "Epoch: 30/30 Train Loss: 0.0006 Acc: 0.5539\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.5873\n",
      "[0.4234 0.4809 0.4977 0.5114 0.5226 0.5501 0.5354 0.5568 0.5449 0.5463\n",
      " 0.5751 0.5727 0.5753 0.5765 0.5717 0.5874 0.5814 0.5794 0.5838 0.5847\n",
      " 0.5854 0.5879 0.5888 0.5883 0.5901 0.5901 0.5894 0.5888 0.5903 0.5873]\n"
     ]
    }
   ],
   "source": [
    "# Focal loss (gamma=2)\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 4, 3)  \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3)  \n",
    "        self.fc1 = nn.Linear(8 * 6 * 6, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 8 * 6 * 6)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "model = ConvNet()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, gamma, alpha = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]):\n",
    "        # 问题是10分类的，我们假设每个类别出现的次数无明显差异\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = torch.tensor(alpha)\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, output, target):\n",
    "        # 注意这里的output是128*10的二维tensor，其实也没必要特别注意啦，一直都是一样的\n",
    "        # 移到device上进行操作，避免报错\n",
    "        alpha = self.alpha.to(device)\n",
    "        alpha = alpha[target]\n",
    "        log_softmax = torch.log_softmax(output, dim=1) # 对模型裸输出做softmax再取log, shape=(bs, 3)\n",
    "        logpt = torch.gather(log_softmax, dim=1, index=target.view(-1, 1))  # 取出每个样本在类别标签位置的log_softmax值, shape=(bs, 1)\n",
    "        logpt = logpt.view(-1)  # 降维，shape=(bs)\n",
    "        ce_loss = -logpt  # 对log_softmax再取负，就是交叉熵了\n",
    "        pt = torch.exp(logpt)  #对log_softmax取exp，把log消了，就是每个样本在类别标签位置的softmax值了，shape=(bs)\n",
    "        focal_loss = alpha * (1 - pt) ** self.gamma * ce_loss  # 根据公式计算focal loss，得到每个样本的loss值，shape=(bs)\n",
    "        return torch.mean(focal_loss)\n",
    "    \n",
    "criterion = FocalLoss(2)\n",
    "\n",
    "def train_batch(model, image, target):\n",
    "    output = model(image)\n",
    "    loss = criterion(output, target) \n",
    "    return output, loss\n",
    "\n",
    "def test_batch(model, image, target):\n",
    "    output = model(image)   \n",
    "    loss = criterion(output, target)\n",
    "    return output, loss\n",
    "\n",
    "training_loss = []\n",
    "training_acc = []\n",
    "testing_loss = []\n",
    "testing_acc = []\n",
    "\n",
    "list = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    torch.cuda.empty_cache()\n",
    "    running_cls_loss = 0.0\n",
    "    running_cls_corrects = 0\n",
    "    for batch_idx, (image, target) in enumerate(train_dataloader):\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "        outputs, loss = train_batch(model, image, target)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss_data = loss.data.item()\n",
    "        if np.isnan(loss_data):\n",
    "            raise ValueError('loss is nan while training')\n",
    "        running_cls_loss += loss.item()\n",
    "        running_cls_corrects += torch.sum(preds == target.data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    epoch_loss = running_cls_loss / len(train_set)\n",
    "    epoch_acc = running_cls_corrects.double() / len(train_set)\n",
    "    print(f'Epoch: {epoch+1}/{NUM_EPOCHS} Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "    training_loss.append(epoch_loss)\n",
    "    training_acc.append(epoch_acc.cpu().detach().numpy())\n",
    "    scheduler.step()\n",
    "    if (epoch + 1) % EVAL_INTERVAL == 0 or (epoch +1) == NUM_EPOCHS:\n",
    "        print('Begin test......')\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "            outputs, loss = test_batch(model, image, target)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_loss += loss.item()\n",
    "            val_corrects += torch.sum(preds == target.data)\n",
    "        val_loss = val_loss / len(test_set)\n",
    "        val_acc = val_corrects.double() / len(test_set)\n",
    "        print(f'Test Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "        list.append(val_acc)\n",
    "        testing_loss.append(val_loss)\n",
    "        testing_acc.append(val_acc.cpu().detach().numpy())\n",
    "        if (epoch +1) == NUM_EPOCHS:  \n",
    "            state = {\n",
    "            'state_dict': model.state_dict(),\n",
    "            'acc': epoch_acc,\n",
    "            'epoch': (epoch+1),\n",
    "            }\n",
    "            if not os.path.exists(SAVE_DIR):\n",
    "                os.makedirs(SAVE_DIR)\n",
    "            torch.save(state, osp.join(SAVE_DIR, 'checkpoint_%s.pth' % (str(epoch+1))))\n",
    "\n",
    "Focal_gamma02 = np.array([tensor.item() for tensor in list])\n",
    "print(Focal_gamma02)# Focal loss (gamma=2)\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 4, 3)  \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3)  \n",
    "        self.fc1 = nn.Linear(8 * 6 * 6, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 8 * 6 * 6)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "model = ConvNet()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, gamma, alpha = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]):\n",
    "        # 问题是10分类的，假设每个类别出现的次数无明显差异\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = torch.tensor(alpha)\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, output, target):\n",
    "        alpha = self.alpha.to(device)\n",
    "        alpha = alpha[target]\n",
    "        log_softmax = torch.log_softmax(output, dim=1) # 对模型裸输出做softmax再取log, shape=(bs, 3)\n",
    "        logpt = torch.gather(log_softmax, dim=1, index=target.view(-1, 1))  # 取出每个样本在类别标签位置的log_softmax值, shape=(bs, 1)\n",
    "        logpt = logpt.view(-1)  # 降维，shape=(bs)\n",
    "        ce_loss = -logpt  # 对log_softmax再取负，就是交叉熵了\n",
    "        pt = torch.exp(logpt)  #对log_softmax取exp，把log消了，就是每个样本在类别标签位置的softmax值了，shape=(bs)\n",
    "        focal_loss = alpha * (1 - pt) ** self.gamma * ce_loss  # 根据公式计算focal loss，得到每个样本的loss值，shape=(bs)\n",
    "        return torch.mean(focal_loss)\n",
    "    \n",
    "criterion = FocalLoss(2)\n",
    "\n",
    "def train_batch(model, image, target):\n",
    "    output = model(image)\n",
    "    loss = criterion(output, target) \n",
    "    return output, loss\n",
    "\n",
    "def test_batch(model, image, target):\n",
    "    output = model(image)   \n",
    "    loss = criterion(output, target)\n",
    "    return output, loss\n",
    "\n",
    "training_loss = []\n",
    "training_acc = []\n",
    "testing_loss = []\n",
    "testing_acc = []\n",
    "\n",
    "list = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    torch.cuda.empty_cache()\n",
    "    running_cls_loss = 0.0\n",
    "    running_cls_corrects = 0\n",
    "    for batch_idx, (image, target) in enumerate(train_dataloader):\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "        outputs, loss = train_batch(model, image, target)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss_data = loss.data.item()\n",
    "        if np.isnan(loss_data):\n",
    "            raise ValueError('loss is nan while training')\n",
    "        running_cls_loss += loss.item()\n",
    "        running_cls_corrects += torch.sum(preds == target.data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    epoch_loss = running_cls_loss / len(train_set)\n",
    "    epoch_acc = running_cls_corrects.double() / len(train_set)\n",
    "    print(f'Epoch: {epoch+1}/{NUM_EPOCHS} Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "    training_loss.append(epoch_loss)\n",
    "    training_acc.append(epoch_acc.cpu().detach().numpy())\n",
    "    scheduler.step()\n",
    "    if (epoch + 1) % EVAL_INTERVAL == 0 or (epoch +1) == NUM_EPOCHS:\n",
    "        print('Begin test......')\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "            outputs, loss = test_batch(model, image, target)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_loss += loss.item()\n",
    "            val_corrects += torch.sum(preds == target.data)\n",
    "        val_loss = val_loss / len(test_set)\n",
    "        val_acc = val_corrects.double() / len(test_set)\n",
    "        print(f'Test Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "        list.append(val_acc)\n",
    "        testing_loss.append(val_loss)\n",
    "        testing_acc.append(val_acc.cpu().detach().numpy())\n",
    "        if (epoch +1) == NUM_EPOCHS:  \n",
    "            state = {\n",
    "            'state_dict': model.state_dict(),\n",
    "            'acc': epoch_acc,\n",
    "            'epoch': (epoch+1),\n",
    "            }\n",
    "            if not os.path.exists(SAVE_DIR):\n",
    "                os.makedirs(SAVE_DIR)\n",
    "            torch.save(state, osp.join(SAVE_DIR, 'checkpoint_%s.pth' % (str(epoch+1))))\n",
    "\n",
    "Focal_gamma02 = np.array([tensor.item() for tensor in list])\n",
    "print(Focal_gamma02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d38b735e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArwAAAIjCAYAAADhisjVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAACIIElEQVR4nO3deVxUVf8H8M8wyoCyKrKPgkvugg8iDxWpSYGZaUi51KOSWZqaRqVZCm6FaQuWps9jbi2iZqg9LWSRFCku6Y80F1IeDEHApWQUU3Tm/v4YZ3RgkBm4wx0un/frdV8455575twZR7+cOed7FIIgCCAiIiIikikHqTtARERERGRLDHiJiIiISNYY8BIRERGRrDHgJSIiIiJZY8BLRERERLLGgJeIiIiIZI0BLxERERHJGgNeIiIiIpI1BrxEREREJGsMeImIyCZOnToFhUKBdevWSd0VImriGPASEVnp8OHDiI+PR7t27eDk5ISAgAA88MADeP/99232nBs2bEBqamq18jNnzmDu3LnIzc212XNXlZWVBYVCYTyaN2+O9u3bY8yYMfjf//4nynPs3r0bc+fOxcWLF0Vpj4iaNga8RERW2L17N/r06YNff/0VEyZMwLJly/D000/DwcEBS5cutdnz3ingnTdvXoMGvAbPP/88Pv74Y/znP//B4MGDsWnTJoSHh+PMmTP1bnv37t2YN28eA14iEkUzqTtARNSYvP7663B3d8f+/fvh4eFhcu7s2bPSdMoGKioq0LJlyzvWiYqKQnx8PAAgISEBd911F55//nmsX78es2bNaohuEhFZhCO8RERWyM/PR/fu3asFuwDg7e1dreyTTz5B37590aJFC3h6euK+++7Djh07jOe3b9+OwYMHw9/fHyqVCh06dMCCBQug1WqNdfr374+vvvoKf/zxh3EaQVBQELKyshAeHg5AH3Aazt0+Z3bv3r2IjY2Fu7s7WrRogX79+mHXrl0mfZw7dy4UCgWOHj2K0aNHw9PTE/fee6/Vr839998PACgoKLhjvR9++AFRUVFo2bIlPDw8MHToUBw7dsykPy+//DIAIDg42Hhfp06dsrpPREQAR3iJiKzSrl075OTk4LfffkOPHj3uWHfevHmYO3cu7r77bsyfPx+Ojo7Yu3cvfvjhBzz44IMAgHXr1sHFxQWJiYlwcXHBDz/8gKSkJGg0GixZsgQA8Nprr6G8vBxFRUV49913AQAuLi7o2rUr5s+fj6SkJDzzzDOIiooCANx9990A9IHloEGDEBYWhuTkZDg4OGDt2rW4//77kZ2djb59+5r097HHHkOnTp3wxhtvQBAEq1+b/Px8AEDr1q1rrPP9999j0KBBaN++PebOnYu///4b77//Pu655x4cPHgQQUFBiIuLw++//460tDS8++678PLyAgC0adPG6j4REQEABCIistiOHTsEpVIpKJVKITIyUpgxY4bw7bffCpWVlSb1Tpw4ITg4OAiPPvqooNVqTc7pdDrjn69cuVLtOZ599lmhRYsWwtWrV41lgwcPFtq1a1et7v79+wUAwtq1a6s9R6dOnYSYmJhqzxccHCw88MADxrLk5GQBgDBq1CiLXoOdO3cKAIQ1a9YI586dE86cOSN89dVXQlBQkKBQKIT9+/cLgiAIBQUF1foWGhoqeHt7CxcuXDCW/frrr4KDg4MwZswYY9mSJUsEAEJBQYFFfSIiuhNOaSAissIDDzyAnJwcPPLII/j111+xePFixMTEICAgAF988YWx3rZt26DT6ZCUlAQHB9N/ahUKhfHPzs7Oxj9funQJ58+fR1RUFK5cuYLjx4/XuZ+5ubk4ceIERo8ejQsXLuD8+fM4f/48KioqMHDgQPz000/Q6XQm10ycONGq53jqqafQpk0b+Pv7Y/DgwaioqMD69evRp08fs/VLSkqQm5uLcePGoVWrVsbyXr164YEHHsDXX39t/Y0SEVmAUxqIiKwUHh6O9PR0VFZW4tdff8XWrVvx7rvvIj4+Hrm5uejWrRvy8/Ph4OCAbt263bGtI0eOYPbs2fjhhx+g0WhMzpWXl9e5jydOnAAAjB07tsY65eXl8PT0ND4ODg626jmSkpIQFRUFpVIJLy8vdO3aFc2a1fzfyh9//AEA6Ny5c7VzXbt2xbfffmvRYjkiImsx4CUiqiNHR0eEh4cjPDwcd911FxISEvDZZ58hOTnZousvXryIfv36wc3NDfPnz0eHDh3g5OSEgwcPYubMmdVGYK1huHbJkiUIDQ01W8fFxcXk8e2jzZbo2bMnoqOj69Q/IqKGxICXiEgEhq/xS0pKAAAdOnSATqfD0aNHaww4s7KycOHCBaSnp+O+++4zlpvLcnD7NAhLyjt06AAAcHNzs5ugtF27dgCAvLy8aueOHz8OLy8v4+huTfdFRFQXnMNLRGSFnTt3ms1gYJh/avi6ftiwYXBwcMD8+fOrjdQarlcqlSaPAaCyshIffPBBtfZbtmxpdoqDIUCsukFDWFgYOnTogLfeeguXL1+udt25c+dqvEdb8fPzQ2hoKNavX2/S399++w07duzAQw89ZCyr6b6IiOqCI7xERFaYOnUqrly5gkcffRRdunRBZWUldu/ejU2bNiEoKAgJCQkAgI4dO+K1117DggULEBUVhbi4OKhUKuzfvx/+/v5ISUnB3XffDU9PT4wdOxbPP/88FAoFPv74Y7MBdVhYGDZt2oTExESEh4fDxcUFQ4YMQYcOHeDh4YGVK1fC1dUVLVu2REREBIKDg/Hhhx9i0KBB6N69OxISEhAQEIDi4mLs3LkTbm5u+O9//9vQLx+WLFmCQYMGITIyEuPHjzemJXN3d8fcuXNN7hfQp2QbOXIkmjdvjiFDhnB+LxHVjbRJIoiIGpdvvvlGeOqpp4QuXboILi4ugqOjo9CxY0dh6tSpQllZWbX6a9asEXr37i2oVCrB09NT6Nevn/Ddd98Zz+/atUv45z//KTg7Owv+/v7GNGcAhJ07dxrrXb58WRg9erTg4eEhADBJUbZ9+3ahW7duQrNmzaqlAfu///s/IS4uTmjdurWgUqmEdu3aCY8//riQmZlprGNIS3bu3DmLXgNDWrLPPvvsjvXMpSUTBEH4/vvvhXvuuUdwdnYW3NzchCFDhghHjx6tdv2CBQuEgIAAwcHBgSnKiKheFIJQh+ziRERERESNBOfwEhEREZGsMeAlIiIiIlljwEtEREREssaAl4iIiIhkjQEvEREREckaA14iIiIikjVuPGGGTqfDmTNn4Orqyu0tiYiIiOyQIAi4dOkS/P394eBw5zFcBrxmnDlzBmq1WupuEBEREVEtTp8+jcDAwDvWYcBrhqurKwD9C+jm5iZxb4iIiIioKo1GA7VabYzb7oQBrxmGaQxubm4MeImIiIjsmCXTT7lojYiIiIhkjQEvEREREckaA14iIiIikjUGvEREREQkawx4iYiIiEjWJA94ly9fjqCgIDg5OSEiIgL79u27Y/2LFy9i8uTJ8PPzg0qlwl133YWvv/66Xm0SERERkXxJGvBu2rQJiYmJSE5OxsGDBxESEoKYmBicPXvWbP3Kyko88MADOHXqFLZs2YK8vDysWrUKAQEBdW6TiIiIiORNIQiCINWTR0REIDw8HMuWLQOg39JXrVZj6tSpeOWVV6rVX7lyJZYsWYLjx4+jefPmorRpjkajgbu7O8rLy5mHl4iIiMgOWROvSTbCW1lZiQMHDiA6OvpWZxwcEB0djZycHLPXfPHFF4iMjMTkyZPh4+ODHj164I033oBWq61zmwBw7do1aDQak4OIiIiI5EGygPf8+fPQarXw8fExKffx8UFpaanZa/73v/9hy5Yt0Gq1+PrrrzFnzhy8/fbbWLhwYZ3bBICUlBS4u7sbD7VaXc+7IyIiIiJ7IfmiNWvodDp4e3vjP//5D8LCwjBixAi89tprWLlyZb3anTVrFsrLy43H6dOnReoxEREREUmtmVRP7OXlBaVSibKyMpPysrIy+Pr6mr3Gz88PzZs3h1KpNJZ17doVpaWlqKysrFObAKBSqaBSqepxN0RERES2pdVpkV2YjZJLJfBz9UNU2ygoHZS1X9gA7LlvgIQjvI6OjggLC0NmZqaxTKfTITMzE5GRkWavueeee3Dy5EnodDpj2e+//w4/Pz84OjrWqU0iIiJq7LQAsgCk3fyptZO2AK2uErmlqdhdOBW5panQ6irr1E76sXQELQ3CgPUDMDp9NAasH4CgpUFIP5Ze155BrPsUv2/ik3RKQ2JiIlatWoX169fj2LFjmDRpEioqKpCQkAAAGDNmDGbNmmWsP2nSJPz555+YNm0afv/9d3z11Vd44403MHnyZIvbJCIiorqw16AyHUAQgAEARt/8GXSz3Pq2BMG0Lf3jugVue4pmoKyiBUJ9X8DdbZch1PcFlFW0wJ6iGdb16lg64jfH48ylIvRrB4zsAfRrB5RcKkL85vg6BJbivWaGvhVpikzKizXFdeybjQgSe//994W2bdsKjo6OQt++fYU9e/YYz/Xr108YO3asSf3du3cLERERgkqlEtq3by+8/vrrwo0bNyxu0xLl5eUCAKG8vLzO90VE1PjcEARhpyAIG27+vHGnymT3xHw/PxcEIVAQBNx2BN4st74tnc60Lf3jurUlCApBp7u9XxB0OoUgCAor2/xc0OkgaKu0pdXhZvvW9S/n9MuCtob2tDoIOadftqidG9obQuA7gcKjGyEUXjRtq/AihLiNENTvqIUbWkvfX/FeM0PfMBeCwzwI/dZCGLlF/9NhHgTFXIWVfbOONfGapHl47RXz8BJR05MOYBqA20dpAgEsBRAnSY+oPtIhCNOgUNx6PwUhEApFXd7PdADxAKqGC4qbP7dY0WY6BGE4BAAOilulOkHfmkLxuRVtaQEEQRCKoFBUPysIgEKhBlAAoLa5pFpcue4Dp2YXTPp1e/+u3miNFs3LLGhLP42hrKIFfF20NbZXckkJX5crUDo43rGtrFNZeG/vAGx5XP+46usGAPGbgecjdqJ/UP/aegbxXjN93wasH4BHuwBLYwG1+61zp8uBaRnA1uPAzrGW9M16jSIPLxER2QtDQFNUpbz4ZrmdfCVpl8Sd7ylOe4ag0vT9FFAEQRgO695PLfS/CJkbGzOUTbewn1pcuf5MtWAXNx8LAK5cf8bCtgAgG4D5wA3AzfLTN+vV0jNdFlo0Nx/sGvrXovkFaHVZFvXs8NkP4O9qPtg1tBfgpsXhsx/U2lbppWIsjb11XdV2ACA1Vl+vduK9ZgBQcqkEj3YBtjwOBFSJNwPc9OWPdtHXkxoDXiKiJk3MgKZxEGsRkbhzR8VqzzZBZc0ESBVU6nSWBHiW1cu7YNlzWlrvSmW+aPW6tDkHtXv199PAQQG0ddfXq42YrxkA+Ll6WxSM+7l6W9SeLTHgJSJq0sQLaBoDsRYRiT8qrm9PEKqMygrWtSd2UAlYOjJXez2xg8pDZ2sP8CytV3LJoqYsrtfCsYNo9Xp5t7GoLUvqifmaAUBUW1gUjEe1tag5m2LAS0TUpIkX0JgSO7WTFlmnspB2OA1Zp7Kg1Vnf3p6iGegbsAS+LqbX+rpo0TdgiRVBr9ij4vr2BEGo9lWzQqFfUWRpe2IHlVqdZSNzltQTO6g8fq4NTpffmsdalU4ACsv19WqjdOhvUVtKh/4W9a2n93M4c0l5x/aKNUr09H6u1rYcHAIsek5L6on5mgGA0uGsqPVsiQEvEVEjJUYQCPiJXA8Q+6t+MXJ8anWVaOv+DoCav3pVu71j4fQGsUfFxZtXKXZQmV0IiwKk7MLa2xI7qPR1DcC0jFvXVm0LAKZn6OvVJqptf8z/qfUd21r4U2tEtbWsb0oHRxSWJ96xvdOaxFoXrN3sHYBA1JRiQF+uvlnvzsR8zfRs8e+HbTDgJSJqhMRL9K7/z/TWivuqFLD0P9ObPYOYX/WLlX9UzEVEYo+KizmvUuygsuTSWYsCpJJLtY/giR1URrWNwv4zgXhsM1CsMT1XpAEe2wz8ckaNqLa1/91VOigxqON/7thWbMf/WLVz2D8DF2Nf8csovWx6TcklJfYVv4x/Bi62sCUlgKVQKBQQBNO/wIKggEKhAJAKS7IqiPma3WwR4v77YTuSbS1MRER1YwgChSpfqRsSvW95fAviulqa2kn/n6l+/qgCCsWtNvWPAUv/M639q34F9F/ND7WoPa1Oi2kZ0zCsi2A25dH0DAHTM6ZjaOehtQYiYi4i0uq8obRguMjSeofOnkOorzj1otr2x8SvWuPfD1+ATjCfwmrhT62xYnD/2p8QgJ+rH7Ye16e9qvoeFGn0we7W48DzEbWP4N0KKocj1UxbL2QAT/SyPKhUOiixNHYp4jfHY3uegHvbAn6u+tHrnwsBnaDAlsdTLW5P/5n5HPeufR7BHsXGtk5dDMQ7MUut+Ezd8s/AxdDqFiK39ANcqcxHC8cO6On9HALcLBnZNekdgC1QKExTByoUgdB/Pi3rm9iv2e3/fug/37d/9g1/+VJh2b8ftsU8vGYwDy8R2Y4W+q+mS6D/mi8K1vxnoNVpEbQ0qNquRgYKKBDoFoiCaQVWjUbtKZqBtu7vwN/11rSIYo0SpzWJVoxEZUE/faE2OwH0r701EfOP5pamItT3hVqfM7f0XYT6Tq+lX5no4BmNADfzi3V0gj6A+99f36N/0MBan3Pj4U9xT9sna21vd+EnGNnziVrbSz+Wjk8PVQ8qC8sNQeXnFgdvhr9vxZpiKBQCom4LkLIL9b8UWfv3Lf1YOl74VrygMv1YOqZlTDP5TKjd1EiNTa1Te1qdFtmF2Si5VAI/Vz9EtY2y6rNkW/X798NA7NfMfN5nNRSKVNgyj7c18RoDXjMY8BJJQZx/yMUnZr/qv7mDIdF7baxJ9G4YMa4a0Nwa8bF0xDgN+jm7tdkAYFSttcQMBMXcCCDtcBo+Ozq61kD8sW4bMKpn7fcp7sYCemIGlYa/HwBMvlVQ3BzBs+4bBT2xg0r7DlLtU+V1LT74Khv5ZSXo4OOH5wZHwbF53V6z9HTghRe0CA7Ohp9fCUpK/FBQEIV331Uizob71lgTr3FKAxHZAXvd5UvMftW0W5Vhbqtlu1VZmsDd0nqGaQMCBAgC8OMfpucVgMXTBsT+qt+Qf7QmhpRHf1qQf9SwiMjXZUmNX/Wf1iRa9FWzmF/zA/p5lf/aGojHNhfV+FW/dfMq9V/PD+08VJQgMK5rHLY8vqXaiGCgW2CdRwSVDkpRd94Suz25S08Hpk1Toqiov7Hs7UBg6VJYHaCmpwPx8YAgKFFYeKs9hUJfvmWL9W3aAkd4zeAIL1FDEnPbUgMxRmUNeVFNU0XdmtdqTb/023nWvLJfAX0gXft2nmKP8IrZnthf9et0n8LB4UkL6n0CB4fav+oHxJm6Yauv+eM3x8NBUdO8SutHUcXGUVTpabVAdjZQUgL4+QFRUYDSyrfgVoBqWm74d86aAFWrBYKCgKIa/mlTKIDAQKCgwPp+WoJbCxNRI2GLXb7E2a1KrLyoeuKlsYpqG4VAt0AooICDAiaZCxwU+q+Z1W6WjwaKOWIs5op+QNz8owb/DFwMn5ZXkFv6LnYXTkFu6bvwdblixTzlWwt/AH1w++MfwMbf9KPjhlX0qbHWLPy5NYrq5xpo0p6/q9ougl3g1ijqqJ6j0D+oP4NdC2m1QFYWkJam/6mtY0rq9HR9cDlgADB6tP5nUJC+3Jq+TJtWPdgFbpVNn255H7Ozaw52DW2ePq2vJzVOaSAiCVkTCPa3oD1xpg1YlxfVkn6Jl8bKEGyZW5RkyFzwRC/Lgy0/V8u+dreknthf9d/KP2r+vRAEQKGwPuWR0sGx1oVptbHF1/xiTkNoasQY+bQF/dQB06AwsA5TB2oalS0utm7agDUBav/+tbdXYuE/bZbWsyUGvEQkITHzmYqXEkunK4aDBd9/WVpP7OTscV2BR7tUv9MAN2DL46gxUDfHMGJcrCmuluYMuJX1wZIRY0Nb244XY3ue+a/61Ra2pWfIPxp/M7itT8o08dkiQOVcVOuJFVQaiBU8ixWk1jYqq1DoR2WHDq29n2IHqH4W/tNmaT1b4pQGIpKQmIGgeNMGxN5vXqu726JtRrW6uy1pDcA0KBTmdwzTJ6GfDkunW9z+9byiSvJ4w2NLv563xVf9t/KPmk5b0Ocfrcv8bnHxa/66EfNr/vj46qOWhqDSmq/7De3Vd9oAIO7UATGnDYgdoEZF6X+5uNO3YWq1vp7UGPASkYTE3KVHvNFisfebzy7cjSlfa43XVm0LAKZ+o0V24W5LWoO429re+no+wM00qAx0C7R6/qiYbd3WKoBT0Ofv3XDzZwGkDnZtQaxA0BbsaS6qoT9izkcVM3gWM0gVc1RW7ABVqdSPpBuurdoWAKSm2sf0EghUTXl5uQBAKC8vl7orRE3A54IgKASdTiEI+vVggiDg5mPFzfOW2Glyfc3HztpbKtgpPLoRglanP26/3lD26EYIOwtqb0sQBGHDoQ0C5uqvKbxo2t4fF/XlmAthw6ENlrRm4X1a0papG9obws6CncKGQxuEnQU7hRvaG1a3YYu2morPPxeEwEBB0IdD+iMwUF8uNbH69vnngqBQmLYD6MsUCuva27mzejvmjp07a2/rxo3q91e1f2q1vp4lNmywrG8bLPiYinmfgnDrPaj6PtTlPbi9zaqvn1pt+7+71sRrTEtmBtOSETUscXb50qf+qn2BU+2pvwxpp/r6V8+Latitav8ZtcVpp25P/eWgQLW5rYZRXstSiWVBzN3MyD6ImSrKwNZzUa3tm9gprNLS9CPEtdmwARhVy/4fWVn6keba7Nxp2WIuMdszvG7FxeZHs+uS+svcvGe1Wj8aW9ecuVIsHOROa/XEgJeo4Yi3y5c+cO4bsASA+Y0F9hW/bHEALWZe1Nvztt5pYZhlAbQhp28xzC/QszynL9kHW+QyFWshl5h9s+egUszgGRA/SDX80gGYtmcPvxBJiXl4iahRuH2XL50Ak0VOWmPe1unQ6mqfhKfVafHYZ2mI3wwUa0zPFWmAxzYDj3+20aK2AHHzooq5MMyQucBwtSnD41Qw2G08xM5l2hTmogLizkcVezGX2HNb4+L0QW1AlZTTgYF138lMqdT/IjBqlP5nYwt2rcW0ZEQkmezCbJMcplUJEHBacxrZhdm1ftVvaKtIA2zPq2nagGVtGdjv9qz6zAXmtz1OhRwXc8mZmIGgmCmsxO6brYLK+Hj9fZkb+bQ0qDQEz7WNyFqTbcAQpJobaa/L1IG4OP371thHZaXCgJeIJCPuLl+36hhGi+vznAZi5kUVN29rHPQ5heu7hTLVhxhfC4sZCIq9sYCYfbPnoFLM4Llq/8QMUg2jsmQ9BrxEJBmxd/kS8zltRdyNBZTgwjTpiDVPVsxA0FbTBsTom70HlWKPyBowSLUPnMNLZNe00K/KT7v5046ScorAsDNX1XmtBgoooHZTW7XLlxhtEdVGzHmyYs73bIpzUQ39FGM+alwccOqUfqHbhg36nwUFde8X2Q9maTCDWRrIPqTD/BzNpZDTHE1DNgQAJhkMDIGrNQvExGyLqCa2yKoAiJMqyhYprMTqW9V+ci4q1RfTktUTA16SXjqAeFRPO2UYYpF+S1UxpR9Lr7aYS+2mrsNiLnHbIjJH7PRatxMjELRFCiux+kYkJga89cSAl6RlyLNa08oTeeZZ1eq0Ii3mErctoqrEztlqC7bYWIDI3lgTr3HRGpHdyUbNwS6gH/U9fbNe/4boUIMQczGXuAvDqC7kPBoo9jxZW2AKKyJTDHiJ7I6labOsS69F1FDEyl5wO3sKoG2RXssWmB2A6BZmaSASOROCVqdF1qkspB1OQ9apLIt39rrF0mEhadNrEZkjZvaC29sMCtLPmx09Wv8zKKhubYlB7MwFRGR7dhHwLl++HEFBQXByckJERAT27dtXY91169ZBoVCYHE5OTiZ1xo0bV61ObGysrW+DGqV06OfLDgAw+ubPoJvldWjtWDqClgZhwPoBGJ0+GgPWD0DQ0iCkH7OmvSjo5+jWsF8mFADUN+sRiUer1S/ISkvT/9Ra+btabbt8Afpdvqxp1xYBtBhslV6LiGxD8oB306ZNSExMRHJyMg4ePIiQkBDExMTg7NmzNV7j5uaGkpIS4/HHH9W3VIqNjTWpk5aWZsvboEbJkAmh6nzZ4pvl1v1PakiJVXWr3GJNMeI3x1sR9CqhTz0GVA96DY9TIacFayQ9MUZRrdnlyxK2CKDFxJytRI2H5AHvO++8gwkTJiAhIQHdunXDypUr0aJFC6xZs6bGaxQKBXx9fY2Hj49PtToqlcqkjqenpy1vgxodLfQ5bs0lKTGUTYel0xu0Oi2mZUwzyf16qzV92fSM6VZMb4iDPvVYleEjBMJ+UpLJe1OMpkSsUVSxd/kSO4C2BbE2PCAi25I04K2srMSBAwcQHR1tLHNwcEB0dDRycnJqvO7y5cto164d1Go1hg4diiNHjlSrk5WVBW9vb3Tu3BmTJk3ChQsXamzv2rVr0Gg0JgfJnTWZECxorTC72siuaWsCTmtOI7vQmv+Z4wCcArATwIabPwtQv2BXrCBV3KkgJB0xR1HFzl4gdgBNRE2XpAHv+fPnodVqq43Q+vj4oLS01Ow1nTt3xpo1a7B9+3Z88skn0Ol0uPvuu1F02zBAbGwsPvroI2RmZuLNN9/Ejz/+iEGDBkFbw7/YKSkpcHd3Nx5qtVq8myQ7JW4mhJJL4ta7RQl96rFRN3/WZ/hIrCBVPxVEEEwDfEGo21QQkpaYo6iG7AVVF3IZKBT6XLCWZi9oDOm/iKhxkHxKg7UiIyMxZswYhIaGol+/fkhPT0ebNm3w73//21hn5MiReOSRR9CzZ08MGzYMX375Jfbv34+srCyzbc6aNQvl5eXG4/Tp0w10NyQdcTMh+LmKW098Ys1X1k8FEQTBzOp0Afp9bKaD0xsaDzFHUcXOXiB2AE1ETZekAa+XlxeUSiXKyspMysvKyuDr62tRG82bN0fv3r1x8uTJGuu0b98eXl5eNdZRqVRwc3MzOUjuxM2EENU2CoFugVDU0J4CCqjd1IhqK8X/zGLOV9ZPBblTAGLNVBCSntijqGJmL2D6LyISi6QBr6OjI8LCwpCZmWks0+l0yMzMRGRkpEVtaLVaHD58GH53+Ne4qKgIFy5cuGMdamrEzYSgdFBiaezSm1ebtmd4nBqbKtH2tuLNV9bpii16RkvrkfRsMYoqZvYCW6T/qm/6NSJqfCSf0pCYmIhVq1Zh/fr1OHbsGCZNmoSKigokJCQAAMaMGYNZs2YZ68+fPx87duzA//73Pxw8eBBPPvkk/vjjDzz99NMA9AvaXn75ZezZswenTp1CZmYmhg4dio4dOyImJkaSeyR7JW4mhLiucdjy+BYEuJm2F+gWiC2Pb0FcV+v/Z67/JhaAmPOVD509Z1FLltYj6dlqFFXM7AViBtD2tokFETUMybcWHjFiBM6dO4ekpCSUlpYiNDQUGRkZxoVshYWFcHC4FZf/9ddfmDBhAkpLS+Hp6YmwsDDs3r0b3bp1AwAolUocOnQI69evx8WLF+Hv748HH3wQCxYsgEqlkuQeyZ7FARgK/ehmCfRzdqNQ18VhcV3jMLTzUGQXZqPkUgn8XP0Q1TaqTiO76cfSMS1jmkn2h0C3QCyNXWpl8CzefOXj59qgtTMQ4AY4mBkR1AlAkUZfL9SyWUlkBwyjqOa2A05NtY+8smJsk2tIv1Y1I4Uh/Ro3jCCSL4UgmEtG07RpNBq4u7ujvLyc83lJEoZNLKrm9TVMj7BuxFgLfTaGYpifx6uAflS7ALUF+lmnsvDe3gHY8rj+8e1Br+5m0/GbgecjdqJ/UH8L+0f2QqvVZ2MoKdHP2Y2Kks/8WK1WP5JbU0YKhUIf4BcUyOeeieTOmnhN8ikNRPJTv1y34m9ioZ+vLAiCMSg10Am4mVkhFZaMake1jcL+M4F4bDNQXCVddZEGeGwz8MsZqRbnUX3JeROFxrCJBRHZDgNeIlHVP9etLTaxSD+mH3k1F6TGb9aft4Rhcd7W4woELwX6rwNGfa7/2X4psPW4QsLFeUQ14yYWRE2b5HN4ieTDkOu26sisIdetZQvhxN7EwjBiXKQBtuUBUW0BP1eg5BKQXQgIggL7z0zH0M5DLQpUDYvzpmVMw49/3ArM1W5qpMam1mlxHpGtcRMLoqaNAS+RKGrLdauAPtftUNQ2dUDsTSxuHzHWCcCPf1Tvn2HE2NJ5t2IuziNqCIb0a8XF5rdRNszh5SYWRPLEgJdIFNbkuu1/x5YMm1gUa4rNzuNVQIFAt0CL58naattjpYOSC9PqQMyFYXJeZCY2Q/q1+Hh9cHt70MtNLIjkj3N4qcmzt1y3Ym9iYf/bHjcdYuaAZT5Z69liEwsiahyYlswMpiVrOsTLdZsF/QK12uxEbSO8d+pbXebJanVaBC0NqnXEuGBaAack2FBNOWANo4vWBFxittUUcWScSB6sidcY8JrBgLdpsNdctyat6rSibWIRvzkeAEzut273StYSMwcs88kSEekxDy9RLWyV61av6hZkhsepsHYHN8M82VE9R6F/UP86j8DaYttjspyYOWCZT5aIyHpctEZNkjW5bi1fmBUHfeqxaTBdwBYIfbArbVDJzArSETMHLPPJEhFZjwEvNVJa6DMelADwAxAFa0ZPbZW5QB/UDq1X32yJmRWkIWYOWOaTJSKyHgNeaoTSYX4UdSksHUW1beYCJSxdmEZNg5g5YJlPlojIepzDS42MYTezqtMRDLuZWZaTyZDrtmraLwMFFFC7qS3OdUt0J4YcsMCtTAoG1uaAFbMtIqKmggEvNSK17WYG6Hczq32hmdi5bqn+tFogKwtIS9P/1NYlHbIdEzMHLPPJEhFZh2nJzGBaMnuVBXvNdUv1k54OTJtmmn0gMFA/kim34I07rRERiYN5eOuJAa+9SgMw2oJ6GwCMsrhVsXLdUt1wEwUiIqoLa+I1LlqjRsTSBWTWLTRj5gLpaLX6kV1zv3YLgj7onT4dGDqUI5dERFR3nMNLjYZWdzfOXFJCV8N3EjoBKNYoodXd3bAdozrjJgpERNQQGPBSo5FduBtTvtavZKoa9BoeT/1Gi+zC3Q3cM6orbqJAREQNgQEvNSAt9AvP0m7+tG4ZfsmlEmw9DsRvBoo1pueKNPryrcfrslkESYWbKBARUUPgHF5qIOJtFrH1OLA9D4hqC/i5AiWXgOzCW6O8ddssgqTQGDZRYCYEIqLGjyO81ADE3yxCJwA//gFs/E3/Uydws4jGyN43UUhPB4KCgAEDgNGj9T+DgvTlRETUeDDgJRvjZhF0Z7bYREGMTSwM6dKqLqorLtaXM+glImo8mIfXDObhFVMWuFkEWUKsqQNibGKh1epHcmvKIGGYalFQwOkNRERS4cYT9cSAV0zcLIIajlibWGRl6acv1GbnTqB/f2t7SUREYuDGE2RHuFkENQwxN7FgujQiInnhHF6ysSjoszEoajivAKC+WY+o7sTcxILp0oiI5IUBL9mYEvrUY0D1oNfwOPVmPaK6E3NU1pAurWrmCAOFAlCrpU2XRkRElmPASw0gDsAWAFWW4SPwZjkXmlH9iTkqa+/p0oiIyDpctGYGF63pib8wTAsgG0AJ9HN2o8CRXRKLIbNCbZtYWJNZwVzGB7VaH+zWJV0aERGJx5p4zS5GeJcvX46goCA4OTkhIiIC+/btq7HuunXroFAoTA4nJyeTOoIgICkpCX5+fnB2dkZ0dDROnDhh69uQlfRj6Wj/XjvMzRqAL34fjblZA9D+vXZIP1af5KNK6FOPjbr5k8EuiccWo7JxccCpU/psDBs26H8WFDDYJSJqbCTP0rBp0yYkJiZi5cqViIiIQGpqKmJiYpCXlwdvb2+z17i5uSEvL8/4WFHlf7fFixfjvffew/r16xEcHIw5c+YgJiYGR48erRYcU3Xpx9Lx6aHh+DkBULvfKj9dXozpGcMBfM58t2SXDJtYmMvDW9dRWaWSqceIiBo7yac0REREIDw8HMuWLQMA6HQ6qNVqTJ06Fa+88kq1+uvWrcP06dNx8eJFs+0JggB/f3+8+OKLeOmllwAA5eXl8PHxwbp16zBy5Mha+9SUpzRodVpM/MoH/374AgDA4bbfJXQ3/6ZM/LI1VgwuY95bsltibWJBRET2q9FMaaisrMSBAwcQHR1tLHNwcEB0dDRycnJqvO7y5cto164d1Go1hg4diiNHjhjPFRQUoLS01KRNd3d3RERE1NjmtWvXoNFoTI6mKrswC0n3VQ92b388+74LyC7MatiOEVnBMCo7apT+J4NdIqKmTdKA9/z589BqtfDx8TEp9/HxQWlpqdlrOnfujDVr1mD79u345JNPoNPpcPfdd6Po5veXhuusaTMlJQXu7u7GQ61W1/fWGi2tLgtq9+rBroGDAmjrrq9H5mm1+p260tL0P7VaqXtERETUtNnFojVrREZGYsyYMQgNDUW/fv2Qnp6ONm3a4N///ned25w1axbKy8uNx+nTp0XscePi5ypuvdtpdVpkncpC2uE0ZJ3KglYnv0gwPV2fKWDAAGD0aP3PoCB9OREREUlD0kVrXl5eUCqVKCsrMykvKyuDr6+vRW00b94cvXv3xsmTJwHAeF1ZWRn8bku4WVZWhtDQULNtqFQqqFSqOtyB/HRu3R/AQgvrWS79WDqmZUxDkebWSqJAt0AsjV0qmwVw6elAfHz1lFjFxfryLVu4up+IiEgKko7wOjo6IiwsDJmZmcYynU6HzMxMREZGWtSGVqvF4cOHjcFtcHAwfH19TdrUaDTYu3evxW02ZUqH/rhyvbVxgVpVOgG4cr01lA79LW4z/Vg64jfHmwS7AFCsKUb85vh6pjqzD1qtPjOAuSWghrLp0+U1vYFTN4iIqLGQfEpDYmIiVq1ahfXr1+PYsWOYNGkSKioqkJCQAAAYM2YMZs2aZaw/f/587NixA//73/9w8OBBPPnkk/jjjz/w9NNPA9CnKJs+fToWLlyIL774AocPH8aYMWPg7++PYcOGSXGLjYwSLZr/BwqgWtCrE/SbAbdo/h9YmkNXq9NiWsY0CKgeCRrKpmdMb/TTG7KzTdNgVSUIwOnT+npSEitI5dQNIiJqTCTPwztixAicO3cOSUlJKC0tRWhoKDIyMoyLzgoLC+HgcCsu/+uvvzBhwgSUlpbC09MTYWFh2L17N7p162asM2PGDFRUVOCZZ57BxYsXce+99yIjI4M5eC0WB4Xic0CYBuBWFKdAIBSKpbBmK+DswuxqI7u3EyDgtOY0sguz0T+of927LLGSEnHr2YK5XcMCA/WbNVgz1YJTN4iIqLGRPA+vPWrKeXhN1X8r4LTDaRidPrrWehviNmBUz1F16KN9yMrSj3LWZudOaTYxqClINezZYmmQati+t6bR7Lps30tERFQXjSYPL9m7+m8F7OfqV3slK+rZq6gofaBXdUtbA4UCUKv19RqamPOLG8vUDSIiotsx4CWbimobhUC3QChgPhJUQAG1mxpRbSWIBEWkVOqnBgDVg17D49RUaUY9xQxSG8PUDSIioqoY8JJNKR2UWBqrjwSrBr2Gx6mxqbLYpjguTj81ICDAtDwwUNp5rWIGqX4WDsRbWo+IiKghMOCVHS2ALABpN39Kn/0grmsctjy+BQFuppFgoFsgtjy+RTZ5eAF9UHvqlH6u7oYN+p8FBdIu4hIzSLXnqRtEREQ14aI1MxrvorV0AKaZFYBAANZlVrAVrU6L7MJslFwqgZ+rH6LaRsliZNfeGRaaFRebn8dr7UIzwwI4wLQ9axfAERER1QcXrTVJ6QDiYRrsAkDxzXLpE6QqHZToH9Qfo3qOQv+g/gx2G4jY84vtdeoGERFRTTjCa0bjG+HVAghC9WDXQAH9SG8B6pJpgeTBXB5etVof7NYlSNVq9QvdSkr00yGiopiKjIiIGo418RoDXjMaX8CbBcCCJLDYCX16MWqqGKQSEZFcWBOvSb7TGonB0hxQzBXV1CmV0mx8QUREJCUGvLJgaQ4o5opqbDgiS0REVH9ctCYLUdDP0a0hVxQUANQ361FjkZ6uz64wYAAwerT+Z1CQvpyIiIgsx4BXFpTQpx4Dqge9hsep4IK1xsOQ+qvqDmnFxfpyBr1ERESWY8ArG3EAtgCokisKgTfLmSuqsdBq9dkUzC0nNZRNn66vR0RERLVjwCsrcQBOQZ+NYcPNnwVgsNu4ZGdXH9m9nSAAp0/r6xEREVHtuGhNdpRg6rHGrcTCZBqW1iMiImrqOMJLZGf8LEymYWk9IiKipo4BL5GdiYrSb9NbdRtgA4VCv0NaFJNuEBERWYQBL5GdUSqBpTeTblQNeg2PU1OZj5eIiMhSDHipydNqgawsIC1N/9Mesh/ExQFbtgABVZJuBAbqy+O4DpGIiMhiXLRGTVp6uj4F2O1ZEQID9SOsUgeVcXHA0KHcaY2IiKi+FIJgLttn06bRaODu7o7y8nK4ublJ3R2yEcPmDlU/AYZpAxxJJSIisl/WxGuc0kBNEjd3ICIiajoY8FKTxM0diIiImg7O4ZUZrU6L7MJslFwqgZ+rH6LaRkHpwEmfVXFzByIioqaDAa+MpB9Lx7SMaSjS3Bq6DHQLxNLYpYjrysmot+PmDkRERE0HpzTIRPqxdMRvjjcJdgGgWFOM+M3xSD+WLlHP7BM3dyAiImo6GPDKgFanxbSMaRBQfQWWoWx6xnRodVyBZcDNHYiIiJoOBrwykF2YXW1k93YCBJzWnEZ2IVdg3Y6bOxARETUNnMMrAyWXLFtZZWm9poSbOxAREckfA14Z8HO1bGWVpfWaGqUS6N9f6l4QERGRrdjFlIbly5cjKCgITk5OiIiIwL59+yy6buPGjVAoFBg2bJhJ+bhx46BQKEyO2NhYG/TcPkS1jUKgWyAUML8CSwEF1G5qRLXlCiwiIiJqeiQPeDdt2oTExEQkJyfj4MGDCAkJQUxMDM6ePXvH606dOoWXXnoJUTUso4+NjUVJSYnxSEtLs0X37YLSQYmlsfoVWFWDXsPj1NhU5uMlIiKiJknygPedd97BhAkTkJCQgG7dumHlypVo0aIF1qxZU+M1Wq0WTzzxBObNm4f27dubraNSqeDr62s8PD09a2zv2rVr0Gg0JkdjE9c1Dlse34IAN9MVWIFugdjy+Bbm4SUiIqImS9KAt7KyEgcOHEB0dLSxzMHBAdHR0cjJyanxuvnz58Pb2xvjx4+vsU5WVha8vb3RuXNnTJo0CRcuXKixbkpKCtzd3Y2HWq2u2w1JLK5rHE5NO4WdY3diQ9wG7By7EwXTChjsEhERUZMm6aK18+fPQ6vVwsfHx6Tcx8cHx48fN3vNzz//jNWrVyM3N7fGdmNjYxEXF4fg4GDk5+fj1VdfxaBBg5CTkwOlmeX3s2bNQmJiovGxRqNptEGv0kGJ/kH9pe4GERERkd1oVFkaLl26hH/9619YtWoVvLy8aqw3cuRI45979uyJXr16oUOHDsjKysLAgQOr1VepVFCpVDbpMxERERFJS9KA18vLC0qlEmVlZSblZWVl8PX1rVY/Pz8fp06dwpAhQ4xlOp0OANCsWTPk5eWhQ4cO1a5r3749vLy8cPLkSbMBLxERERHJl6RzeB0dHREWFobMzExjmU6nQ2ZmJiIjI6vV79KlCw4fPozc3Fzj8cgjj2DAgAHIzc2tcRpCUVERLly4AD8/5qElIiIiamokn9KQmJiIsWPHok+fPujbty9SU1NRUVGBhIQEAMCYMWMQEBCAlJQUODk5oUePHibXe3h4AICx/PLly5g3bx6GDx8OX19f5OfnY8aMGejYsSNiYmIa9N6IiIiISHqSB7wjRozAuXPnkJSUhNLSUoSGhiIjI8O4kK2wsBAODpYPRCuVShw6dAjr16/HxYsX4e/vjwcffBALFizgPF0iIiKiJkghCIIgdSfsjUajgbu7O8rLy+Hm5iZ1d4iIiIioCmviNck3niAiIiIisiUGvEREREQkawx4iYiIiEjWGPASERERkawx4CUiIiIiWWPAS0RERESyxoCXiIiIiGSNAS8RERERyRoDXiIiIiKSNcm3FiYtgGwAJQD8AEQBUEraIyIiIiI5YcArqXQA0wAU3VYWCGApgDhJekREREQkN5zSIJl0APEwDXYBoPhmeXqD94iIiIhIjhjwSkIL/ciuYOacoWz6zXpEREREVB8MeCWRjeoju7cTAJy+WY+IiIiI6oMBryRKRK5HRERERDVhwCsJP5HrEREREVFNGPBKIgr6bAyKGs4rAKhv1iMiIiKi+mBaMkkooU89Fg99cHv74jVDEJwKueXj1WqB7GygpATw8wOiogClvG6RiIiI7BBHeCUTB2ALgIAq5YE3y+WVhzc9HQgKAgYMAEaP1v8MCtKXExEREdmSQhAEc7mxmjSNRgN3d3eUl5fDzc3Nxs8m/53W0tOB+Hig6t80xc3B7C1bgDh5xfdERERkY9bEawx4zWjYgFfetFr9SG5RDVnYFAogMBAoKOD0BiIiIrKcNfEapzSQTWVn1xzsAvpR39On9fWIiIiIbIGL1qhGYiwyK7EwlbCl9YiIiIisxYBXYlqdFtmF2Si5VAI/Vz9EtY2C0kH67/bT04Fp00xHZwMDgaVLrZtv62dhKmFL6xERERFZi3N4zWioObzpx9IxLWMaijS3ospAt0AsjV2KuK7SreISc5GZYQ5vcXH19gxtcg4vERERWYtzeBuB9GPpiN8cbxLsAkCxphjxm+ORfkyafF1arX5k11xwaiibPl1fzxJKpX5UGLgVMBsYHqemWh/sarVAVhaQlqb/aWl/iIiIqOlhwCsBrU6LaRnTIKB6VGkom54xHVpdw0dxtlhkFhenHxUOqJJyODCwbinJmNOXiIiIrMGAVwLZhdnVRnZvJ0DAac1pZBc2fOoCWy0yi4sDTp0Cdu4ENmzQ/ywoqFuwGx9fPSgvLtaXM+glIiKiqrhoTQIllyyLFi2tJyZbLjJTKoH+/a2/zqC26RYKhX66xdChnA9MREREt9jFCO/y5csRFBQEJycnREREYN++fRZdt3HjRigUCgwbNsykXBAEJCUlwc/PD87OzoiOjsaJEyds0PO68XO1LFq0tJ6YoqL0Uw2qzrc1UCgAtVpfr6Expy8RERHVheQB76ZNm5CYmIjk5GQcPHgQISEhiImJwdmzZ+943alTp/DSSy8hykzktXjxYrz33ntYuXIl9u7di5YtWyImJgZXr1611W1YJaptFALdAqGA+ahSAQXUbmpEtW34qNJWi8zEwJy+REREVBeSB7zvvPMOJkyYgISEBHTr1g0rV65EixYtsGbNmhqv0Wq1eOKJJzBv3jy0b9/e5JwgCEhNTcXs2bMxdOhQ9OrVCx999BHOnDmDbdu22fhuLKN0UGJprD6qrBr0Gh6nxqZKlo9X7EVmYmFOXyIiIqoLSQPeyspKHDhwANHR0cYyBwcHREdHIycnp8br5s+fD29vb4wfP77auYKCApSWlpq06e7ujoiIiBrbvHbtGjQajclha3Fd47Dl8S0IcDONKgPdArHl8S2S5uEFxFtkJiZ7nm5BRERE9kvSRWvnz5+HVquFj4+PSbmPjw+OHz9u9pqff/4Zq1evRm5urtnzpaWlxjaqtmk4V1VKSgrmzZtnZe/rL65rHIZ2HmqXO60B9V9kJjbDdIv4eH1we/viNamnWxAREZH9knxKgzUuXbqEf/3rX1i1ahW8vLxEa3fWrFkoLy83HqdPnxat7dooHZToH9Qfo3qOQv+g/nYT7Nore51uQURERPZL0hFeLy8vKJVKlJWVmZSXlZXB19e3Wv38/HycOnUKQ4YMMZbpdDoAQLNmzZCXl2e8rqysDH63TeYsKytDaGio2X6oVCqoVKr63g41kLg4feqx7Gz9AjU/P/00Bo7sEhERkTmSjvA6OjoiLCwMmZmZxjKdTofMzExERkZWq9+lSxccPnwYubm5xuORRx7BgAEDkJubC7VajeDgYPj6+pq0qdFosHfvXrNtUuNkmG4xapT+J4NdIiIiqonkG08kJiZi7Nix6NOnD/r27YvU1FRUVFQgISEBADBmzBgEBAQgJSUFTk5O6NGjh8n1Hh4eAGBSPn36dCxcuBCdOnVCcHAw5syZA39//2r5eomIiIhI/iQPeEeMGIFz584hKSkJpaWlCA0NRUZGhnHRWWFhIRwcrBuInjFjBioqKvDMM8/g4sWLuPfee5GRkQEnJydb3AIRERER2TGFIJjbqLVp02g0cHd3R3l5Odzc3KTuDhERERFVYU281qiyNBARERERWYsBLxERERHJGgNeIiIiIpI1yRetERERUXVarRbXr1+XuhtEkmnevDmUIuUdZcBLRERkRwRBQGlpKS5evCh1V4gk5+HhAV9fXygUinq1w4CXiIjIjhiCXW9vb7Ro0aLe/9ETNUaCIODKlSs4e/YsAJjsnlsXDHiJiIjshFarNQa7rVu3lro7RJJydnYGAJw9exbe3t71mt7ARWtERER2wjBnt0WLFhL3hMg+GD4L9Z3PzoCXiIjIznAaA5GeWJ8FBrxEREREJGsMeImIiIhI1hjwEhEREZGsMeAlIiKSI60WyMoC0tL0P7Vamz7duHHjoFAoMHHixGrnJk+eDIVCgXHjxpmU5+TkQKlUYvDgwdWuOXXqFBQKhdljz549tfZn3bp18PDwqPH8Tz/9hCFDhsDf3x8KhQLbtm2rtU1z0tLSoFQqMXny5DpdTw2DAS8REZHcpKcDQUHAgAHA6NH6n0FB+nIbUqvV2LhxI/7++29j2dWrV7Fhwwa0bdu2Wv3Vq1dj6tSp+Omnn3DmzBmzbX7//fcoKSkxOcLCwurd14qKCoSEhGD58uX1amf16tWYMWMG0tLScPXq1Xr3i2yDAa/MNPAv9EREZG/S04H4eKCoyLS8uFhfbsOg9x//+AfUajXSb3uO9PR0tG3bFr179zape/nyZWzatAmTJk3C4MGDsW7dOrNttm7dGr6+viZH8+bN693XQYMGYeHChXj00Ufr3EZBQQF2796NV155BXfddZfJfRusWbMG3bt3h0qlgp+fH6ZMmWI8d/HiRTz77LPw8fGBk5MTevTogS+//LLO/aGaMeCVEYl+oSciInuh1QLTpgGCUP2coWz6dJuOhjz11FNYu3at8fGaNWuQkJBQrd7mzZvRpUsXdO7cGU8++STWrFkDwVy/7djatWsxePBguLu748knn8Tq1atNzq9YsQKTJ0/GM888g8OHD+OLL75Ax44dAQA6nQ6DBg3Crl278Mknn+Do0aNYtGhRvTZXoJpxpzWZMPxCX/XfCsMv9Fu2AHFx0vSNiIgaSHZ29ZHd2wkCcPq0vl7//jbpwpNPPolZs2bhjz/+AADs2rULGzduRFZWlkm91atX48knnwQAxMbGory8HD/++CP6V+nX3XffDQcH0/G5y5cv26Tv1tDpdFi3bh3ef/99AMDIkSPx4osvoqCgAMHBwQCAhQsX4sUXX8S0adOM14WHhwPQT9XYt28fjh07hrvuugsA0L59+wa+i6aDAa/EtFr9vzslJYCfHxAVBVj7y11tv9ArFPpf6IcOtb5tIiJqREpKxK1XB23atDFOURAEAYMHD4aXl5dJnby8POzbtw9bt24FADRr1gwjRozA6tWrqwW8mzZtQteuXW3W37r67rvvUFFRgYceeggA4OXlhQceeABr1qzBggULcPbsWZw5cwYDBw40e31ubi4CAwONwS7ZFgNeCaWn6wPV238ZDwwEli61bjTWDn6hJyIie+DnJ269OnrqqaeMc1XNLQpbvXo1bty4AX9/f2OZIAhQqVRYtmwZ3N3djeVqtdo4DcCerF69Gn/++SecnZ2NZTqdDocOHcK8efNMys2p7TyJi3N4JSLmmgI7+IWeiIjsQVSUfuSkpu1YFQpArdbXs6HY2FhUVlbi+vXriImJMTl348YNfPTRR3j77beRm5trPH799Vf4+/sjLS3Npn0Tw4ULF7B9+3Zs3LjR5B7+7//+D3/99Rd27NgBV1dXBAUFITMz02wbvXr1QlFREX7//fcG7n3TxBFeCYg9BcFOfqEnIiKpKZX6rwnj4/X/mdz+H40hCE5Ntfn8NqVSiWPHjhn/fLsvv/wSf/31F8aPH28ykgsAw4cPx+rVq01y+V64cAGlpaUm9Tw8PODk5FRrP7RaLXJzc03KVCoVunbtisuXL+PkyZPG8oKCAuTm5qJVq1ZmU6jd7uOPP0br1q3x+OOPQ1Hll4uHHnoIq1evRmxsLObOnYuJEyfC29sbgwYNwqVLl7Br1y5MnToV/fr1w3333Yfhw4fjnXfeQceOHXH8+HEoFArExsbWem9kHY7wSsCaKQiWsJNf6ImIyB7ExelXKgcEmJYHBjboCmY3Nze4ublVK1+9ejWio6OrBbuAPuD95ZdfcOjQIWNZdHQ0/Pz8TA5LN4m4fPkyevfubXIMGTIEAPDLL78YywAgMTERvXv3RlJSUq3trlmzBo8++mi1YNdwD1988QXOnz+PsWPHIjU1FR988AG6d++Ohx9+GCdOnDDW/fzzzxEeHo5Ro0ahW7dumDFjBrTMJ2oTCqGx5QBpABqNBu7u7igvLzf7Ya2vtDR92rDabNgAjBplWZuGKRKA+V/omaWBiMj+Xb161bjK35IRzDsSY1U0kcTu9JmwJl6zeoR3586d1l5CVdhiCoKd/EJPRET2QqnUr1QeNUr/k8EuNWFWB7yxsbHo0KEDFi5ciNOnT9uiT7JnqykIcXHAqVPAzp360eGdO4GCAga7REQkP927d4eLi4vZ49NPP61X29nZ2TW27eLiItIdUEOyetFacXExPv74Y6xfvx7z5s3D/fffj/Hjx2PYsGFwdHS0RR9lx5ZrCgy/0BMREcnZ119/jevXr5s95+PjU6+2+/TpU22xGzVu9ZrDe/DgQaxdu9aYQmT06NEYP348QkJCROugFGw9h9fAXB5etVof7HJUloio6RF1Di+RDEg2h/d2//jHPzBr1ixMmTIFly9fxpo1axAWFoaoqCgcOXKkPk03CZyCQERERGR7dQp4r1+/ji1btuChhx5Cu3bt8O2332LZsmUoKyvDyZMn0a5dOzz22GNi91WWuKaAiIiIyLasnsM7depUpKWlQRAE/Otf/8LixYvRo0cP4/mWLVvirbfeMtkukIiIiIhIKlaP8B49ehTvv/8+zpw5g9TUVJNg18DLy8uq9GXLly9HUFAQnJycEBERgX379tVYNz09HX369IGHhwdatmyJ0NBQfPzxxyZ1xo0bB4VCYXJw1xIiIiKipsnqEd6a9oQ2abRZM/Tr18+i9jZt2oTExESsXLkSERERSE1NRUxMDPLy8uDt7V2tfqtWrfDaa6+hS5cucHR0xJdffomEhAR4e3ub7NcdGxuLtWvXGh+rVCqL+kNERERE8mL1CG9KSgrWrFlTrXzNmjV48803re7AO++8gwkTJiAhIQHdunXDypUr0aJFC7PPAQD9+/fHo48+iq5du6JDhw6YNm0aevXqhZ9//tmknkqlgq+vr/Hw9PS0um9ERERE1PhZHfD++9//RpcuXaqVd+/eHStXrrSqrcrKShw4cADR0dG3OuTggOjoaOTk5NR6vSAIyMzMRF5eHu677z6Tc1lZWfD29kbnzp0xadIkXLhwocZ2rl27Bo1GY3IQERE1ZlotkJWl384+K0v/uCGUlpZi6tSpaN++PVQqFdRqNYYMGWL8hjgoKKjatEOFQoFFixZZ9TwxMTFQKpXYv3+/LW6DZMbqKQ2lpaXwM7PnbZs2bVBSUmJVW+fPn4dWq62WINrHxwfHjx+v8bry8nIEBATg2rVrUCqV+OCDD/DAAw8Yz8fGxiIuLg7BwcHIz8/Hq6++ikGDBiEnJwdKM2kQUlJSMG/ePKv6TkREZK/M5XkPDNRvemTL1JenTp3CPffcAw8PDyxZsgQ9e/bE9evX8e2332Ly5MnG/9vnz5+PCRMmmFzr6upq8fMUFhZi9+7dmDJlCtasWYPw8HBR74Pkx+oRXrVajV27dlUr37VrV4NlZnB1dUVubi7279+P119/HYmJicjKyjKeHzlyJB555BH07NkTw4YNw5dffon9+/eb1LndrFmzUF5ebjy4ZTIRETVW6en6nTxvD3YBoLhYX56ebrvnfu6556BQKLBv3z4MHz4cd911F7p3747ExETs2bPHWM/V1dVk2qGvry9atmxp8fOsXbsWDz/8MCZNmoS0tDT8/fffJucvXryIZ599Fj4+PnByckKPHj3w5ZdfGs/v2rUL/fv3R4sWLeDp6YmYmBj89ddf9X8ByG5ZPcI7YcIETJ8+HdevX8f9998PQL+QbcaMGXjxxRetasvLywtKpRJlZWUm5WVlZfD19a3xOgcHB3Ts2BEAEBoaimPHjiElJQX9a9hTt3379vDy8sLJkycxcODAaudVKhUXtRERUaOn1epHds3toSoI+u3rp08Hhg4VP+/7n3/+iYyMDLz++utmg1cPDw9RnkcQBKxduxbLly9Hly5d0LFjR2zZsgX/+te/AAA6nQ6DBg3CpUuX8Mknn6BDhw44evSo8Rve3NxcDBw4EE899RSWLl2KZs2aYefOndA21JwPkoTVAe/LL7+MCxcu4LnnnkNlZSUAwMnJCTNnzsSsWbOsasvR0RFhYWHIzMzEsGHDAOj/omZmZmLKlCkWt6PT6XDt2rUazxcVFeHChQtmp2IQERHJRXZ29ZHd2wkCcPq0vl4NY0R1dvLkSQiCYHadT1UzZ87E7NmzTcq++eYbREVF1Xrt999/jytXrhgzMz355JNYvXq1MeD9/vvvsW/fPhw7dgx33XUXAP3Al8HixYvRp08ffPDBB8ay7t27136D1KhZHfAqFAq8+eabmDNnDo4dOwZnZ2d06tSpziOkiYmJGDt2LPr06YO+ffsiNTUVFRUVSEhIAACMGTMGAQEBSElJAaCfb9unTx906NAB165dw9dff42PP/4YK1asAABcvnwZ8+bNw/Dhw+Hr64v8/HzMmDEDHTt2NElbRkREJDeWLqWxcsmNRQRzw8o1ePnllzFu3DiTsoCAAIuuXbNmDUaMGIFmzfQhzKhRo/Dyyy8jPz8fHTp0QG5uLgIDA43BblW5ubncDbYJsjrgNXBxcRFlkviIESNw7tw5JCUlobS0FKGhocjIyDAuZCssLISDw62pxhUVFXjuuedQVFQEZ2dndOnSBZ988glGjBgBAFAqlTh06BDWr1+Pixcvwt/fHw8++CAWLFjAaQtERCRrln6RaYsvPDt16gSFQnHHRecGXl5exqmJ1vjzzz+xdetWXL9+3TjQBQBarRZr1qzB66+/Dmdn5zu2Udt5kieFYM2vZDf98ssv2Lx5MwoLC43TGgzSbTkbvoFoNBq4u7ujvLwcbm5uUneHiIiaiKtXr6KgoADBwcFwcnKy+nqtFggK0i9QM/e/u0Khz9ZQUCD+HF4AGDRoEA4fPoy8vLxq83gvXrwIDw8PBAUFYfr06Zg+fbrV7b///vtYunQptm3bZlK+Y8cOvP322ygsLMTPP/+M+++/32RKw+0SEhJw4sSJavn7yT7d6TNhTbxmdZaGjRs34u6778axY8eMv2UdOXIEP/zwA9zd3a1tjoiIiESiVOpTjwH64PZ2hsepqbYJdgFg+fLl0Gq16Nu3Lz7//HOcOHECx44dw3vvvYfIyEhjvUuXLqG0tNTksCQH/urVqxEfH48ePXqYHOPHj8f58+eRkZGBfv364b777sPw4cPx3XffoaCgAN988w0yMjIA6DMz7d+/H8899xwOHTqE48ePY8WKFTh//rxtXhSyC1YHvG+88Qbeffdd/Pe//4WjoyOWLl2K48eP4/HHH0fbtm1t0UciIiKyUFwcsGULUHVKbGCgvtyWeXjbt2+PgwcPYsCAAXjxxRfRo0cPPPDAA8jMzDSZgpCUlAQ/Pz+TY8aMGXds+8CBA/j1118xfPjwaufc3d0xcOBArF69GgDw+eefIzw8HKNGjUK3bt0wY8YMYxaGu+66Czt27MCvv/6Kvn37IjIyEtu3bzfOCSZ5snpKQ8uWLXHkyBEEBQWhdevWyMrKQs+ePXHs2DHcf//9Vm8+YY84pYGIiKRQ3ykNt9Nq9dkYSkr0c3ajomw3sktkK2JNabD61xlPT09cunQJgH5F5W+//YaePXvi4sWLuHLlirXNERERkQ0oleKnHiNqrKye0nDffffhu+++AwA89thjmDZtGiZMmIBRo0aZ3dSBiIiIyBITJ06Ei4uL2WPixIlSd48aMaunNPz555+4evUq/P39odPpsHjxYuzevRudOnXC7Nmz4enpaau+NhhOaSAiIimIOaWhMTp79myNi9fc3Nzg7e3dwD0iqUkypeHGjRv48ssvjRs4ODg44JVXXrGy60RERETVeXt7M6glm7BqSkOzZs0wceJEXL161Vb9ISIiIiISldVzePv27Yvc3FwbdIWIiIiISHxWZ2l47rnnkJiYiNOnTyMsLKzaTiq9evUSrXNERERERPVldcA7cuRIAMDzzz9vLFMoFBAEAQqFwpjYmYiIiIjIHlgd8BYUFNiiH0RERERENmH1HN527drd8SAiIiJqSHPnzkVoaKjU3ZCFvLw8+Pr6GjcZs5WVK1diyJAhNn2O21kd8H700Ud3PIiIiKjpGTduHBQKRbXj5MmTUnetScjKysI//vEPqFQqdOzYEevWrTM5/9NPP2HIkCHw9/eHQqHAtm3bzLYza9YsTJ06Fa6ursayQ4cOISoqCk5OTlCr1Vi8eHGt/TH3d2Hjxo3G80899RQOHjyI7OzsOt2vtaye0jBt2jSTx9evX8eVK1fg6OiIFi1aYMyYMaJ1joiIiOpGq9MiuzAbJZdK4Ofqh6i2UVA6KG36nLGxsVi7dq1JWZs2bWz6nKSfbjp48GBMnDgRn376KTIzM/H000/Dz8/PuHdCRUUFQkJC8NRTTyEuLs5sO4WFhfjyyy/x/vvvG8s0Gg0efPBBREdHY+XKlTh8+DCeeuopeHh44Jlnnrljv9auXYvY2FjjYw8PD+OfHR0dMXr0aLz33nuIioqqx91bxuoR3r/++svkuHz5MvLy8nDvvfciLS3NFn0kIiIiK6QfS0fQ0iAMWD8Ao9NHY8D6AQhaGoT0Y+k2fV6VSgVfX1+TQ6lU4scff0Tfvn2hUqng5+eHV155BTdu3DBeZ9i5tWPHjlCpVGjbti1ef/114/mZM2firrvuQosWLdC+fXvMmTMH169fr1Mfb9y4geeffx4eHh5o3bo1Zs6cibFjx2LYsGHGOhkZGbj33nuNdR5++GHk5+cbz586dQoKhQKbN29GVFQUnJ2dER4ejt9//x379+9Hnz594OLigkGDBuHcuXPG68aNG4dhw4bhjTfegI+PDzw8PDB//nzcuHEDL7/8Mlq1aoXAwMBqvzTUdv8rV65EcHAw3n77bXTt2hVTpkxBfHw83n33XWOdQYMGYeHChXj00UdrfG02b96MkJAQBAQEGMs+/fRTVFZWYs2aNejevTtGjhyJ559/Hu+8806tr7WHh4fJ34WqO6UNGTIEX3zxBf7+++9a26ovqwNeczp16oRFixZVG/0lIiKihpV+LB3xm+NRpCkyKS/WFCN+c7zNg96qiouL8dBDDyE8PBy//vorVqxYgdWrV2PhwoXGOrNmzcKiRYswZ84cHD16FBs2bICPj4/xvKurK9atW4ejR49i6dKlWLVqlUkwZ40333wTn376KdauXYtdu3ZBo9FU+3q/oqICiYmJ+OWXX5CZmQkHBwc8+uij0Ol0JvWSk5Mxe/ZsHDx4EM2aNcPo0aMxY8YMLF26FNnZ2Th58iSSkpJMrvnhhx9w5swZ/PTTT3jnnXeQnJyMhx9+GJ6enti7dy8mTpyIZ599FkVFt96/2u4/JycH0dHRJs8TExODnJwcq16b7Oxs9OnTx6QsJycH9913HxwdHU3azsvLw19//XXH9iZPngwvLy/07dsXa9asgSAIJuf79OmDGzduYO/evVb1s04Ekfzf//2f4OrqKlZzkiovLxcACOXl5VJ3hYiImpC///5bOHr0qPD333/X6fob2htC4DuBAubC7KGYqxDU76iFG9obIvdcEMaOHSsolUqhZcuWxiM+Pl549dVXhc6dOws6nc5Yd/ny5YKLi4ug1WoFjUYjqFQqYdWqVRY/15IlS4SwsDDj4+TkZCEkJMSia318fIQlS5YYH9+4cUNo27atMHTo0BqvOXfunABAOHz4sCAIglBQUCAAED788ENjnbS0NAGAkJmZaSxLSUkROnfubHw8duxYoV27doJWqzWWde7cWYiKijLpT8uWLYW0tLQa+1P1/jt16iS88cYbJnW++uorAYBw5cqVatcDELZu3VqtPCQkRJg/f75J2QMPPCA888wzJmVHjhwRAAhHjx6tsY/z588Xfv75Z+HgwYPCokWLBJVKJSxdurRaPU9PT2HdunU1tnOnz4Q18ZrVc3i/+OKLqgEzSkpKsGzZMtxzzz31DsCJiIiobrILs6uN7N5OgIDTmtPILsxG/6D+oj//gAEDsGLFCuPjli1bYvLkyYiMjIRCoTCW33PPPbh8+TKKiopQWlqKa9euYeDAgTW2u2nTJrz33nvIz8/H5cuXcePGDbi5uVndv/LycpSVlaFv377GMqVSibCwMJPR2xMnTiApKQl79+7F+fPnjecKCwvRo0cPY73bN9syjEj37NnTpOzs2bMmfejevTscHBxM6tzeplKpROvWrU2uE+v+a/P3339Xm3ZQV3PmzDH+uXfv3qioqMCSJUtM9nEAAGdnZ1y5ckWU57wTqwPe2+e4APpVeG3atMH999+Pt99+W6x+ERERkZVKLpWIWs9aLVu2RMeOHa26xtnZ+Y7nc3Jy8MQTT2DevHmIiYmBu7s7Nm7caNOYY8iQIWjXrh1WrVoFf39/6HQ69OjRA5WVlSb1mjdvbvyzIaCvWlZ1GsTt5w11zJUZrrPk/n19fVFWVmbSRllZGdzc3Gp9fW/n5eVVbZpCTW0bzlkqIiICCxYswLVr16BSqYzlf/75Z4MsbLQ64K36xhEREZF98HP1E7WeGLp27YrPP//cuCMrAOzatQuurq4IDAyEt7c3nJ2djZkFqtq9ezfatWuH1157zVj2xx9/1Kkv7u7u8PHxwf79+3HfffcBALRaLQ4ePGjM43vhwgXk5eVh1apVxuwBP//8c52eTwyW3H9kZCS+/vprk7LvvvsOkZGRVj1X7969cfTo0Wptv/baa7h+/boxMP/uu+/QuXNneHp6Wtx2bm4uPD09TYLd/Px8XL16Fb1797aqn3UhyqI1IiIikl5U2ygEugVCAYXZ8woooHZTI6qt7dNAGTz33HM4ffo0pk6diuPHj2P79u1ITk5GYmIiHBwc4OTkhJkzZ2LGjBn46KOPkJ+fjz179mD16tUA9AvjCwsLsXHjRuTn5+O9997D1q1b69yfqVOnIiUlBdu3b0deXh6mTZuGv/76yxiMe3p6onXr1vjPf/6DkydP4ocffkBiYqIor0VdWHL/EydOxP/+9z/MmDEDx48fxwcffIDNmzfjhRdeMNa5fPkycnNzkZubC0Cfyiw3NxeFhYXGOoaFblqt1lg2evRoODo6Yvz48Thy5Ag2bdqEpUuXmrwmW7duRZcuXYyP//vf/+LDDz/Eb7/9hpMnT2LFihV44403MHXqVJN+Z2dno3379ujQoYMor9WdWB3wDh8+HG+++Wa18sWLF+Oxxx4TpVNERERkPaWDEktjlwJAtaDX8Dg1NtXm+XhvFxAQgK+//hr79u1DSEgIJk6ciPHjx2P27NnGOnPmzMGLL76IpKQkdO3aFSNGjDDOYX3kkUfwwgsvYMqUKQgNDcXu3btN5odaa+bMmRg1ahTGjBmDyMhIuLi4ICYmxjh31cHBARs3bsSBAwfQo0cPvPDCC1iyZEn9XoR6sOT+g4OD8dVXX+G7775DSEgI3n77bXz44YfGHLwA8Msvv6B3797G0dTExET07t3bJIvEoEGD0KxZM3z//ffGMnd3d+zYsQMFBQUICwszvk+35+AtLy9HXl6e8XHz5s2xfPlyREZGIjQ0FP/+97+NGSlul5aWhgkTJojzQtVCIQhVckTUok2bNvjhhx9MJmUDwOHDhxEdHV1tnkdjpNFo4O7ujvLycptMCiciIjLn6tWrKCgoQHBwcL0WD6UfS8e0jGkmC9jUbmqkxqYirqv5TQeaKp1Oh65du+Lxxx/HggULpO6O5JYvX44vvvgC3377rU2f58iRI7j//vvx+++/w93dvcZ6d/pMWBOvWT2H9/Llyya52AyaN28OjUZjbXNEREQksriucRjaeWiD77TWGPzxxx/YsWMH+vXrh2vXrmHZsmUoKCjA6NGjpe6aXXj22Wdx8eJFXLp0yWR7YbGVlJTgo48+umOwKyarA96ePXti06ZN1RIpb9y4Ed26dROtY0RERFR3SgelTVKP2TsXF5caz33zzTcICgrCunXr8NJLL0EQBPTo0QPff/89unbt2oC9tF/NmjUzWSBnK1U3yrA1qwPeOXPmIC4uDvn5+bj//vsBAJmZmdiwYQO2bNkiegeJiIiILGVYlGVOQEAAnJ2dsWvXrobrENkFqwPeIUOGYNu2bXjjjTewZcsWODs7IyQkBD/88ANatWpliz4SERERWcTaPMDUNFgd8ALA4MGDMXjwYAD6CcNpaWl46aWXcODAAZNUFkREREREUqtzHt6ffvoJY8eOhb+/P95++23cf//92LNnj5h9IyIiIiKqN6sC3tLSUixatAidOnXCY489Bjc3N1y7dg3btm3DokWLEB4eXqdOLF++HEFBQXByckJERAT27dtXY9309HT06dMHHh4eaNmyJUJDQ/Hxxx+b1BEEAUlJSfDz84OzszOio6Nx4sSJOvWNiIiIiBo3iwPeIUOGoHPnzjh06BBSU1Nx5swZvP/++/XuwKZNm5CYmIjk5GQcPHgQISEhiImJMSacrqpVq1Z47bXXkJOTg0OHDiEhIQEJCQkm+eIWL16M9957DytXrsTevXvRsmVLxMTE4OrVq/XuLxERERE1LhZvPNGsWTM8//zzmDRpEjp16mQsb968OX799dc6pySLiIhAeHg4li1bBkCfAFqtVmPq1Kl45ZVXLGrjH//4BwYPHowFCxZAEAT4+/vjxRdfxEsvvQRAvwOIj48P1q1bh5EjR9baHjeeICIiKYi18QSRXIi18YTFI7w///wzLl26hLCwMERERGDZsmU4f/583Xp/U2VlJQ4cOGCSi83BwQHR0dHIycmp9XpBEJCZmYm8vDzcd999APR7Q5eWlpq06e7ujoiIiBrbvHbtGjQajclBREREjcPcuXMRGhoqdTdkITMzE127drUqCcHIkSPx9ttv27BX9WdxwPvPf/4Tq1atQklJCZ599lls3LgR/v7+0Ol0+O6773Dp0iWrn/z8+fPQarXw8fExKffx8UFpaWmN15WXl8PFxQWOjo4YPHgw3n//fTzwwAMAYLzOmjZTUlLg7u5uPNRqtdX3QkRE1JSNGzcOCoWi2nHy5Empu9YkZGVl4R//+AdUKhU6duyIdevWmZxPSUlBeHg4XF1d4e3tjWHDhiEvL69aOzNmzMDs2bOhVOp35UtPT8cDDzyANm3awM3NDZGRkdW2HZ49ezZef/11lJeX2+z+6svqLA0tW7bEU089hZ9//hmHDx/Giy++iEWLFsHb2xuPPPKILfpYjaurK3Jzc7F//368/vrrSExMRFZWVp3bmzVrFsrLy43H6dOnxessERGRJLQAsgCk3fxp+7ShsbGxKCkpMTmCg4Nt/rxNXUFBAQYPHowBAwYgNzcX06dPx9NPP20SmP7444+YPHky9uzZg++++w7Xr1/Hgw8+iIqKCmOdn3/+Gfn5+Rg+fLix7KeffsIDDzyAr7/+GgcOHMCAAQMwZMgQ/N///Z+xTo8ePdChQwd88sknDXPDdVDntGQA0LlzZyxevBhFRUVIS0uz+novLy8olUqUlZWZlJeVlcHX17fG6xwcHNCxY0eEhobixRdfRHx8PFJSUgDAeJ01bapUKri5uZkcREREjVc6gCAAAwCMvvkz6Ga57ahUKvj6+pocSqUSP/74I/r27QuVSgU/Pz+88soruHHjhvE6nU6HxYsXo2PHjlCpVGjbti1ef/114/mZM2firrvuQosWLdC+fXvMmTMH169fr1Mfb9y4geeffx4eHh5o3bo1Zs6cibFjx2LYsGHGOhkZGbj33nuNdR5++GHk5+cbz586dQoKhQKbN29GVFQUnJ2dER4ejt9//x379+9Hnz594OLigkGDBuHcuXPG68aNG4dhw4bhjTfegI+PDzw8PDB//nzcuHEDL7/8Mlq1aoXAwECsXbvWpM+13f/KlSsRHByMt99+G127dsWUKVMQHx+Pd9991+Sexo0bh+7duyMkJATr1q1DYWEhDhw4YKyzceNGPPDAAyZzZVNTUzFjxgyEh4ejU6dOeOONN9CpUyf897//NenjkCFDsHHjxjq9Jw2hXgGvgVKpxLBhw/DFF19YdZ2joyPCwsKQmZlpLNPpdMjMzERkZKTF7eh0Oly7dg0AEBwcDF9fX5M2NRoN9u7da1WbREREjVM6gHgARVXKi2+W2zboraq4uBgPPfQQwsPD8euvv2LFihVYvXo1Fi5caKwza9YsLFq0CHPmzMHRo0exYcMGk6mJrq6uWLduHY4ePYqlS5di1apVJsGcNd588018+umnWLt2LXbt2gWNRoNt27aZ1KmoqEBiYiJ++eUXZGZmwsHBAY8++ih0Op1JveTkZMyePRsHDx5Es2bNMHr0aMyYMQNLly5FdnY2Tp48iaSkJJNrfvjhB5w5cwY//fQT3nnnHSQnJ+Phhx+Gp6cn9u7di4kTJ+LZZ59FUdGt96+2+8/JyTFZuwQAMTExd1wPZZh+cPsuudnZ2ejTp88dXz+dTodLly5V2123b9++2LdvnzEeszuCxDZu3CioVCph3bp1wtGjR4VnnnlG8PDwEEpLSwVBEIR//etfwiuvvGKs/8Ybbwg7duwQ8vPzhaNHjwpvvfWW0KxZM2HVqlXGOosWLRI8PDyE7du3C4cOHRKGDh0qBAcHC3///bdFfSovLxcACOXl5eLeLBER0R38/fffwtGjRy3+/6q6G4IgBAqCgBoOhSAI6pv1xDV27FhBqVQKLVu2NB7x8fHCq6++KnTu3FnQ6XTGusuXLxdcXFwErVYraDQaQaVSmfw/XpslS5YIYWFhxsfJyclCSEiIRdf6+PgIS5YsMT6+ceOG0LZtW2Ho0KE1XnPu3DkBgHD48GFBEAShoKBAACB8+OGHxjppaWkCACEzM9NYlpKSInTu3Nn4eOzYsUK7du0ErVZrLOvcubMQFRVl0p+WLVsKaWlpNfan6v136tRJeOONN0zqfPXVVwIA4cqVK9Wu12q1wuDBg4V77rnHpNzd3V346KOPanxeQRCEN998U/D09BTKyspMyn/99VcBgHDq1Kk7Xm+tO30mrInX6rS1sJhGjBiBc+fOISkpCaWlpQgNDUVGRobxN7vCwkI4ONwaiK6oqMBzzz2HoqIiODs7o0uXLvjkk08wYsQIY50ZM2agoqICzzzzDC5evIh7770XGRkZTPFCREQyl43qI7u3EwCcvlmvv+jPPmDAAKxYscL4uGXLlpg8eTIiIyOhUCiM5ffccw8uX76MoqIilJaW4tq1axg4cGCN7W7atAnvvfce8vPzcfnyZdy4caNO0w/Ly8tRVlaGvn37GsuUSiXCwsJMRm9PnDiBpKQk7N27F+fPnzeeKywsRI8ePYz1evXqZfyzIW7p2bOnSVnVfQW6d+9uEtf4+PiYtKlUKtG6dWuT68S6f4PJkyfjt99+w88//2xS/vfff98xVtqwYQPmzZuH7du3w9vb2+Scs7MzAODKlSt17pctSR7wAsCUKVMwZcoUs+eqLkZbuHChydcg5igUCsyfPx/z588Xq4tERESNQInI9azTsmVLdOzY0aprDIFSTXJycvDEE09g3rx5iImJgbu7OzZu3GjTNFhDhgxBu3btsGrVKmNGqh49eqCystKkXvPmzY1/NgT0VcuqToO4/byhjrkyw3WW3L+vr6/ZtUtubm7VXt8pU6bgyy+/xE8//YTAwECTc15eXvjrr7/MviYbN27E008/jc8++6za9AkA+PPPPwEAbdq0MXu91ESZw0tERET2wE/kevXXtWtX5OTkQLhtn6tdu3bB1dUVgYGB6NSpE5ydnU3W3txu9+7daNeuHV577TX06dMHnTp1wh9//FGnvri7u8PHxwf79+83lmm1Whw8eND4+MKFC8jLy8Ps2bMxcOBAdO3atcYgsCFYcv+RkZHVXr/vvvvOZO2SIAiYMmUKtm7dih9++MFs9ozevXvj6NGj1crT0tKQkJCAtLQ0DB482Gw/f/vtNwQGBsLLy6sut2lzdjHCS0RERGKIAhAI/QI1cxupKm6ej2qwHj333HNITU3F1KlTMWXKFOTl5SE5ORmJiYlwcHCAk5MTZs6ciRkzZsDR0RH33HMPzp07hyNHjmD8+PHo1KkTCgsLsXHjRoSHh+Orr77C1q1b69yfqVOnIiUlBR07dkSXLl3w/vvv46+//jKO0Hp6eqJ169b4z3/+Az8/PxQWFlq886stWHL/EydOxLJlyzBjxgw89dRT+OGHH7B582Z89dVXxjqTJ0/Ghg0bsH37dri6uhr3JnB3dzeOAsfExGD9+vUmbW/YsAFjx47F0qVLERERYbzO2dkZ7u7uxnrZ2dl48MEHbfIaiIEjvERERLKhBLD05p8VVc4ZHqferNcwAgIC8PXXX2Pfvn0ICQnBxIkTMX78eMyePdtYZ86cOXjxxReRlJSErl27YsSIEcY5rI888gheeOEFTJkyBaGhodi9ezfmzJlT5/7MnDkTo0aNwpgxYxAZGQkXFxfExMQY5646ODhg48aNOHDgAHr06IEXXngBS5Ysqd+LUA+W3H9wcDC++uorfPfddwgJCcHbb7+NDz/8EDExMcY6K1asQHl5Ofr37w8/Pz/jsWnTJmOdJ554AkeOHDHZkOI///kPbty4gcmTJ5tcN23aNGOdq1evYtu2bZgwYYINX4n6UQi3f8dAAKzbm5mIiEgsV69eRUFBAYKDg+u50DodwDSYLmBTQx/sxtWjXfnR6XTo2rUrHn/8cSxYsEDq7kju5Zdfhkajwb///W+Lr1mxYgW2bt2KHTt2iN6fO30mrInXOKWBiIhIduIADIU+G0MJ9HN2o9CQI7v26o8//sCOHTvQr18/XLt2DcuWLUNBQQFGjx4tddfswmuvvYYPPvgAOp3OJJvEnTRv3hzvv/++jXtWPwx4iYiIZEkJW6Qes3cuLi41nvvmm28QFBSEdevW4aWXXoIgCOjRowe+//57dO3atQF7ab88PDzw6quvWnXN008/baPeiIcBLxEREclGbm5ujecCAgLg7OyMXbt2NVyHyC4w4CUiIiLZsDYPMDUNzNJARERkZ7ienEhPrM8CA14iIiI7Ydhxy163ZyVqaIbPQtXd6KzFKQ1ERER2QqlUwsPDw5iDtkWLFsYNEYiaEkEQcOXKFZw9exYeHh5QKuuXYYQBLxERkR3x9fUFAGPQS9SUeXh4GD8T9cGAl4iIyI4oFAr4+fnB29sb169fl7o7RJJp3rx5vUd2DRjwEhER2SGlUinaf/ZETR0XrRERERGRrDHgJSIiIiJZY8BLRERERLLGgJeIiIiIZI0BLxERERHJGgNeIiIiIpI1BrxEREREJGsMeImIiIhI1hjwEhEREZGsMeAlIiIiIlljwEtEREREssaAl4iIiIhkjQEvEREREckaA14iIiIikjUGvEREREQkawx4iYiIiEjW7CLgXb58OYKCguDk5ISIiAjs27evxrqrVq1CVFQUPD094enpiejo6Gr1x40bB4VCYXLExsba+jaIiIiIyA5JHvBu2rQJiYmJSE5OxsGDBxESEoKYmBicPXvWbP2srCyMGjUKO3fuRE5ODtRqNR588EEUFxeb1IuNjUVJSYnxSEtLa4jbISIiIiI7oxAEQZCyAxEREQgPD8eyZcsAADqdDmq1GlOnTsUrr7xS6/VarRaenp5YtmwZxowZA0A/wnvx4kVs27atTn3SaDRwd3dHeXk53Nzc6tQGEREREdmONfGapCO8lZWVOHDgAKKjo41lDg4OiI6ORk5OjkVtXLlyBdevX0erVq1MyrOysuDt7Y3OnTtj0qRJuHDhQo1tXLt2DRqNxuQgIiIiInmQNOA9f/48tFotfHx8TMp9fHxQWlpqURszZ86Ev7+/SdAcGxuLjz76CJmZmXjzzTfx448/YtCgQdBqtWbbSElJgbu7u/FQq9V1vykiIiIisivNpO5AfSxatAgbN25EVlYWnJycjOUjR440/rlnz57o1asXOnTogKysLAwcOLBaO7NmzUJiYqLxsUajYdBLREREJBOSjvB6eXlBqVSirKzMpLysrAy+vr53vPatt97CokWLsGPHDvTq1euOddu3bw8vLy+cPHnS7HmVSgU3NzeTg4iIiIjkQdKA19HREWFhYcjMzDSW6XQ6ZGZmIjIyssbrFi9ejAULFiAjIwN9+vSp9XmKiopw4cIF+Pn5idJvIiIiImo8JE9LlpiYiFWrVmH9+vU4duwYJk2ahIqKCiQkJAAAxowZg1mzZhnrv/nmm5gzZw7WrFmDoKAglJaWorS0FJcvXwYAXL58GS+//DL27NmDU6dOITMzE0OHDkXHjh0RExMjyT0SERERkXQkn8M7YsQInDt3DklJSSgtLUVoaCgyMjKMC9kKCwvh4HArLl+xYgUqKysRHx9v0k5ycjLmzp0LpVKJQ4cOYf369bh48SL8/f3x4IMPYsGCBVCpVA16b0REREQkPcnz8Noj5uElIiIism+NJg8vEREREZGtMeAlIiIiIlljwEtEREREssaAl4iIiIhkjQEvEREREckaA14iIiIikjUGvEREREQkawx4iYiIiEjWGPASERERkawx4CUiIiIiWWPAS0RERESyxoCXiIiIiGSNAS8RERERyRoDXiIiIiKSNQa8RERERCRrDHiJiIiISNYY8BIRERGRrDHgJSIiIiJZY8BLRERERLLGgJeIiIiIZI0BLxERERHJGgNeIiIiIpI1BrxEREREJGsMeImIiIhI1hjwEhEREZGsMeAlIiIiIlljwEtEREREssaAl4iIiIhkjQEvEREREckaA14iIiIikjW7CHiXL1+OoKAgODk5ISIiAvv27aux7qpVqxAVFQVPT094enoiOjq6Wn1BEJCUlAQ/Pz84OzsjOjoaJ06csPVtEBEREZEdkjzg3bRpExITE5GcnIyDBw8iJCQEMTExOHv2rNn6WVlZGDVqFHbu3ImcnByo1Wo8+OCDKC4uNtZZvHgx3nvvPaxcuRJ79+5Fy5YtERMTg6tXrzbUbRERERGRnVAIgiBI2YGIiAiEh4dj2bJlAACdTge1Wo2pU6filVdeqfV6rVYLT09PLFu2DGPGjIEgCPD398eLL76Il156CQBQXl4OHx8frFu3DiNHjqy1TY1GA3d3d5SXl8PNza1+N0hEREREorMmXpN0hLeyshIHDhxAdHS0sczBwQHR0dHIycmxqI0rV67g+vXraNWqFQCgoKAApaWlJm26u7sjIiKixjavXbsGjUZjchARERGRPEga8J4/fx5arRY+Pj4m5T4+PigtLbWojZkzZ8Lf398Y4Bqus6bNlJQUuLu7Gw+1Wm3trRARERGRnZJ8Dm99LFq0CBs3bsTWrVvh5ORU53ZmzZqF8vJy43H69GkRe0lEREREUmom5ZN7eXlBqVSirKzMpLysrAy+vr53vPatt97CokWL8P3336NXr17GcsN1ZWVl8PPzM2kzNDTUbFsqlQoqlaqOd0FERERE9kzSEV5HR0eEhYUhMzPTWKbT6ZCZmYnIyMgar1u8eDEWLFiAjIwM9OnTx+RccHAwfH19TdrUaDTYu3fvHdskIiIiInmSdIQXABITEzF27Fj06dMHffv2RWpqKioqKpCQkAAAGDNmDAICApCSkgIAePPNN5GUlIQNGzYgKCjIOC/XxcUFLi4uUCgUmD59OhYuXIhOnTohODgYc+bMgb+/P4YNGybVbRIRERGRRCQPeEeMGIFz584hKSkJpaWlCA0NRUZGhnHRWWFhIRwcbg1Er1ixApWVlYiPjzdpJzk5GXPnzgUAzJgxAxUVFXjmmWdw8eJF3HvvvcjIyKjXPF8iIiIiapwkz8Nrj5iHl4iIiMi+NZo8vEREREREtsaAl4iIiIhkjQEvEREREckaA14iIiIikjUGvEREREQkawx4iYiIiEjWGPASERERkawx4CUiIiIiWWPAS0RERESyxoCXiIiIiGSNAS8RERERyRoDXiIiIiKSNQa8RERERCRrDHiJiIiISNYY8BIRERGRrDHgJSIiIiJZY8BLRERERLLGgJeIiIiIZI0BLxERERHJGgNeIiIiIpI1BrxEREREJGsMeImIiIhI1hjwEhEREZGsMeAlIiIiIlljwEtEREREssaAl4iIiIhkjQEvEREREckaA14iIiIikjUGvEREREQkawx4iYiIiEjWJA94ly9fjqCgIDg5OSEiIgL79u2rse6RI0cwfPhwBAUFQaFQIDU1tVqduXPnQqFQmBxdunSx4R0QERERkT2TNODdtGkTEhMTkZycjIMHDyIkJAQxMTE4e/as2fpXrlxB+/btsWjRIvj6+tbYbvfu3VFSUmI8fv75Z1vdAhERERHZOUkD3nfeeQcTJkxAQkICunXrhpUrV6JFixZYs2aN2frh4eFYsmQJRo4cCZVKVWO7zZo1g6+vr/Hw8vKy1S0QERERkZ2TLOCtrKzEgQMHEB0dfaszDg6Ijo5GTk5Ovdo+ceIE/P390b59ezzxxBMoLCy8Y/1r165Bo9GYHEREREQkD5IFvOfPn4dWq4WPj49JuY+PD0pLS+vcbkREBNatW4eMjAysWLECBQUFiIqKwqVLl2q8JiUlBe7u7sZDrVbX+fmJiIiIyL5IvmhNbIMGDcJjjz2GXr16ISYmBl9//TUuXryIzZs313jNrFmzUF5ebjxOnz7dgD0mIiIiIltqJtUTe3l5QalUoqyszKS8rKzsjgvSrOXh4YG77roLJ0+erLGOSqW645xgIiIiImq8JBvhdXR0RFhYGDIzM41lOp0OmZmZiIyMFO15Ll++jPz8fPj5+YnWJhERERE1HpKN8AJAYmIixo4diz59+qBv375ITU1FRUUFEhISAABjxoxBQEAAUlJSAOgXuh09etT45+LiYuTm5sLFxQUdO3YEALz00ksYMmQI2rVrhzNnziA5ORlKpRKjRo2S5iaJiIiISFKSBrwjRozAuXPnkJSUhNLSUoSGhiIjI8O4kK2wsBAODrcGoc+cOYPevXsbH7/11lt466230K9fP2RlZQEAioqKMGrUKFy4cAFt2rTBvffeiz179qBNmzYNem9EREREZB8UgiAIUnfC3mg0Gri7u6O8vBxubm5Sd4eIiIiIqrAmXpNdlgYiIiIiotsx4CUiIiIiWWPAS0RERESyxoCXiIiIiGSNAS8RERERyRoDXiIiIiKSNQa8RERERCRrDHiJiIiISNYY8BIRERGRrDHgJSIiIiJZY8BLRERERLLGgJeIiIiIZI0BLxERERHJGgNeIiIiIpI1BrxEREREJGvNpO5Ak6fVAtnZQEkJ4OcHREUBSqV9tNdU+tZU7pN9k74t9k1+fWsq98m+ya9v9nyftiBQNeXl5QIAoby83LZP9PnnghAYKAjArSMwUF8udXtNpW9N5T7ZN+nbYt/k17emcp/sm/z6Zs/3aQVr4jUGvGY0SMD7+eeCoFCY/uUA9GUKhfV/ScRsr6n0rancJ/smfVvsm/z61lTuk32TX9/s+T6txIC3nmwe8N64Uf03oap/SdRqfb2Gbq+p9K2p3Cf7Jn1b7Jv8+tZU7pN9k1/f7Pk+64ABbz3ZPODdubPmvxy3Hzt3Nnx7TaVvTeU+2Tfp22Lf5Ne3pnKf7Jv8+mbP91kH1sRrzNIghZIS+63XVPrWVO5T7HpNpW9N5T7FrtdU+tZU7lPseuxb3erZa1u2qGdDDHil4Odnv/WaSt+ayn2KXa+p9K2p3KfY9ZpK35rKfYpdj32rWz17bcsW9WzJJmPMjVyDzeE1N8kbqPscGjHaayp9ayr3yb5J3xb7Jr++NZX7ZN/k1zd7vs864BzeemrQLA1V/5LUd5WkGO01lb41lftk36Rvi32TX9+ayn2yb/Lrmz3fp5UY8NaTpHl41Wpx8+DVtb2m0remcp/sm/RtsW/y61tTuU/2TX59s+f7tII18ZpCEARByikV9kij0cDd3R3l5eVwc3Oz7ZPZ804nTaVvTeU+2Tfp22Lf5Ne3pnKf7Jv8+mbP92kha+I1BrxmNGjAS0RERERWsyZeY5YGIiIiIpI1BrxEREREJGsMeImIiIhI1iQPeJcvX46goCA4OTkhIiIC+/btq7HukSNHMHz4cAQFBUGhUCA1NbXebRIRERGRvEka8G7atAmJiYlITk7GwYMHERISgpiYGJw9e9Zs/StXrqB9+/ZYtGgRfH19RWmTiIiIiORN0iwNERERCA8Px7JlywAAOp0OarUaU6dOxSuvvHLHa4OCgjB9+nRMnz5dtDYNmKWBiIiIyL41iiwNlZWVOHDgAKKjo291xsEB0dHRyMnJadA2r127Bo1GY3IQERERkTxIFvCeP38eWq0WPj4+JuU+Pj4oLS1t0DZTUlLg7u5uPNRqdZ2en4iIiIjsj+SL1uzBrFmzUF5ebjxOnz4tdZeIiIiISCTNpHpiLy8vKJVKlJWVmZSXlZXVuCDNVm2qVCqoVKo6PScRERER2TfJRngdHR0RFhaGzMxMY5lOp0NmZiYiIyPtpk0iIiIiatwkG+EFgMTERIwdOxZ9+vRB3759kZqaioqKCiQkJAAAxowZg4CAAKSkpADQL0o7evSo8c/FxcXIzc2Fi4sLOnbsaFGbRERERNS0SBrwjhgxAufOnUNSUhJKS0sRGhqKjIwM46KzwsJCODjcGoQ+c+YMevfubXz81ltv4a233kK/fv2QlZVlUZtERERE1LRImofXXjEPLxEREZF9axR5eImIiIiIGgIDXiIiIiKSNQa8RERERCRrDHiJiIiISNYY8BIRERGRrDHgJSIiIiJZY8BLRERERLLGgJeIiIiIZI0BLxERERHJGgNeIiIiIpI1BrxEREREJGsMeImIiIhI1hjwEhEREZGsMeAlIiIiIlljwEtEREREssaAl4iIiIhkjQEvEREREckaA14iIiIikjUGvEREREQkawx4iYiIiEjWGPASERERkawx4CUiIiIiWWPAS0RERESyxoCXiIiIiGSNAS8RERERyRoDXiIiIiKSNQa8RERERCRrDHiJiIiISNYY8BIRERGRrDHgJSIiIiJZs4uAd/ny5QgKCoKTkxMiIiKwb9++O9b/7LPP0KVLFzg5OaFnz574+uuvTc6PGzcOCoXC5IiNjbXlLRARERGRnZI84N20aRMSExORnJyMgwcPIiQkBDExMTh79qzZ+rt378aoUaMwfvx4/N///R+GDRuGYcOG4bfffjOpFxsbi5KSEuORlpbWELdDRERERHZGIQiCIGUHIiIiEB4ejmXLlgEAdDod1Go1pk6dildeeaVa/REjRqCiogJffvmlseyf//wnQkNDsXLlSgD6Ed6LFy9i27ZtdeqTRqOBu7s7ysvL4ebmVqc2iIiIiMh2rInXmjVQn8yqrKzEgQMHMGvWLGOZg4MDoqOjkZOTY/aanJwcJCYmmpTFxMRUC26zsrLg7e0NT09P3H///Vi4cCFat25tts1r167h2rVrxsfl5eUA9C8kEREREdkfQ5xmyditpAHv+fPnodVq4ePjY1Lu4+OD48ePm72mtLTUbP3S0lLj49jYWMTFxSE4OBj5+fl49dVXMWjQIOTk5ECpVFZrMyUlBfPmzatWrlar63JbRERERNRALl26BHd39zvWkTTgtZWRI0ca/9yzZ0/06tULHTp0QFZWFgYOHFit/qxZs0xGjXU6Hf7880+0bt0aCoXC7HNoNBqo1WqcPn2a0x4kwvdAenwPpMf3QHp8D+wD3wfpNfR7IAgCLl26BH9//1rrShrwenl5QalUoqyszKS8rKwMvr6+Zq/x9fW1qj4AtG/fHl5eXjh58qTZgFelUkGlUpmUeXh4WHQPbm5u/GBJjO+B9PgeSI/vgfT4HtgHvg/Sa8j3oLaRXQNJszQ4OjoiLCwMmZmZxjKdTofMzExERkaavSYyMtKkPgB89913NdYHgKKiIly4cAF+fn7idJyIiIiIGg3J05IlJiZi1apVWL9+PY4dO4ZJkyahoqICCQkJAIAxY8aYLGqbNm0aMjIy8Pbbb+P48eOYO3cufvnlF0yZMgUAcPnyZbz88svYs2cPTp06hczMTAwdOhQdO3ZETEyMJPdIRERERNKRfA7viBEjcO7cOSQlJaG0tBShoaHIyMgwLkwrLCyEg8OtuPzuu+/Ghg0bMHv2bLz66qvo1KkTtm3bhh49egAAlEolDh06hPXr1+PixYvw9/fHgw8+iAULFlSbtlAfKpUKycnJorZJ1uF7ID2+B9LjeyA9vgf2ge+D9Oz5PZA8Dy8RERERkS1JPqWBiIiIiMiWGPASERERkawx4CUiIiIiWWPAS0RERESyxoC3DpYvX46goCA4OTkhIiIC+/btk7pLTcrcuXOhUChMji5dukjdLVn76aefMGTIEPj7+0OhUGDbtm0m5wVBQFJSEvz8/ODs7Izo6GicOHFCms7KVG3vwbhx46p9LmJjY6XprEylpKQgPDwcrq6u8Pb2xrBhw5CXl2dS5+rVq5g8eTJat24NFxcXDB8+vNpmSVR3lrwH/fv3r/ZZmDhxokQ9lp8VK1agV69exs0lIiMj8c033xjP2+tngAGvlTZt2oTExEQkJyfj4MGDCAkJQUxMDM6ePSt115qU7t27o6SkxHj8/PPPUndJ1ioqKhASEoLly5ebPb948WK89957WLlyJfbu3YuWLVsiJiYGV69ebeCeyldt7wEAxMbGmnwu0tLSGrCH8vfjjz9i8uTJ2LNnD7777jtcv34dDz74ICoqKox1XnjhBfz3v//FZ599hh9//BFnzpxBXFychL2WF0veAwCYMGGCyWdh8eLFEvVYfgIDA7Fo0SIcOHAAv/zyC+6//34MHToUR44cAWDHnwGBrNK3b19h8uTJxsdarVbw9/cXUlJSJOxV05KcnCyEhIRI3Y0mC4CwdetW42OdTif4+voKS5YsMZZdvHhRUKlUQlpamgQ9lL+q74EgCMLYsWOFoUOHStKfpurs2bMCAOHHH38UBEH/97558+bCZ599Zqxz7NgxAYCQk5MjVTdlrep7IAiC0K9fP2HatGnSdaoJ8vT0FD788EO7/gxwhNcKlZWVOHDgAKKjo41lDg4OiI6ORk5OjoQ9a3pOnDgBf39/tG/fHk888QQKCwul7lKTVVBQgNLSUpPPhbu7OyIiIvi5aGBZWVnw9vZG586dMWnSJFy4cEHqLslaeXk5AKBVq1YAgAMHDuD69esmn4UuXbqgbdu2/CzYSNX3wODTTz+Fl5cXevTogVmzZuHKlStSdE/2tFotNm7ciIqKCkRGRtr1Z0DyndYak/Pnz0Or1Rp3gTPw8fHB8ePHJepV0xMREYF169ahc+fOKCkpwbx58xAVFYXffvsNrq6uUnevySktLQUAs58LwzmyvdjYWMTFxSE4OBj5+fl49dVXMWjQIOTk5ECpVErdPdnR6XSYPn067rnnHuNOn6WlpXB0dISHh4dJXX4WbMPcewAAo0ePRrt27eDv749Dhw5h5syZyMvLQ3p6uoS9lZfDhw8jMjISV69ehYuLC7Zu3Ypu3bohNzfXbj8DDHip0Rk0aJDxz7169UJERATatWuHzZs3Y/z48RL2jEg6I0eONP65Z8+e6NWrFzp06ICsrCwMHDhQwp7J0+TJk/Hbb79x/YCEanoPnnnmGeOfe/bsCT8/PwwcOBD5+fno0KFDQ3dTljp37ozc3FyUl5djy5YtGDt2LH788Uepu3VHnNJgBS8vLyiVymqrDcvKyuDr6ytRr8jDwwN33XUXTp48KXVXmiTD331+LuxL+/bt4eXlxc+FDUyZMgVffvkldu7cicDAQGO5r68vKisrcfHiRZP6/CyIr6b3wJyIiAgA4GdBRI6OjujYsSPCwsKQkpKCkJAQLF261K4/Awx4reDo6IiwsDBkZmYay3Q6HTIzMxEZGSlhz5q2y5cvIz8/H35+flJ3pUkKDg6Gr6+vyedCo9Fg7969/FxIqKioCBcuXODnQkSCIGDKlCnYunUrfvjhBwQHB5ucDwsLQ/PmzU0+C3l5eSgsLORnQSS1vQfm5ObmAgA/Czak0+lw7do1u/4McEqDlRITEzF27Fj06dMHffv2RWpqKioqKpCQkCB115qMl156CUOGDEG7du1w5swZJCcnQ6lUYtSoUVJ3TbYuX75sMjpSUFCA3NxctGrVCm3btsX06dOxcOFCdOrUCcHBwZgzZw78/f0xbNgw6TotM3d6D1q1aoV58+Zh+PDh8PX1RX5+PmbMmIGOHTsiJiZGwl7Ly+TJk7FhwwZs374drq6uxjmJ7u7ucHZ2hru7O8aPH4/ExES0atUKbm5umDp1KiIjI/HPf/5T4t7LQ23vQX5+PjZs2ICHHnoIrVu3xqFDh/DCCy/gvvvuQ69evSTuvTzMmjULgwYNQtu2bXHp0iVs2LABWVlZ+Pbbb+37MyBpjohG6v333xfatm0rODo6Cn379hX27NkjdZealBEjRgh+fn6Co6OjEBAQIIwYMUI4efKk1N2StZ07dwoAqh1jx44VBEGfmmzOnDmCj4+PoFKphIEDBwp5eXnSdlpm7vQeXLlyRXjwwQeFNm3aCM2bNxfatWsnTJgwQSgtLZW627Ji7vUHIKxdu9ZY5++//xaee+45wdPTU2jRooXw6KOPCiUlJdJ1WmZqew8KCwuF++67T2jVqpWgUqmEjh07Ci+//LJQXl4ubcdl5KmnnhLatWsnODo6Cm3atBEGDhwo7Nixw3jeXj8DCkEQhIYMsImIiIiIGhLn8BIRERGRrDHgJSIiIiJZY8BLRERERLLGgJeIiIiIZI0BLxERERHJGgNeIiIiIpI1BrxEREREJGsMeImIiIhI1hjwEhFRjRQKBbZt2yZ1N4iI6oUBLxGRnRo3bhwUCkW1IzY2VuquERE1Ks2k7gAREdUsNjYWa9euNSlTqVQS9YaIqHHiCC8RkR1TqVTw9fU1OTw9PQHopxusWLECgwYNgrOzM9q3b48tW7aYXH/48GHcf//9cHZ2RuvWrfHMM8/g8uXLJnXWrFmD7t27Q6VSwc/PD1OmTDE5f/78eTz66KNo0aIFOnXqhC+++MK2N01EJDIGvEREjdicOXMwfPhw/Prrr3jiiScwcuRIHDt2DABQUVGBmJgYeHp6Yv/+/fjss8/w/fffmwS0K1aswOTJk/HMM8/g8OHD+OKLL9CxY0eT55g3bx4ef/xxHDp0CA899BCeeOIJ/Pnnnw16n0RE9aEQBEGQuhNERFTduHHj8Mknn8DJycmk/NVXX8Wrr74KhUKBiRMnYsWKFcZz//znP/GPf/wDH3zwAVatWoWZM2fi9OnTaNmyJQDg66+/xpAhQ3DmzBn4+PggICAACQkJWLhwodk+KBQKzJ49GwsWLACgD6JdXFzwzTffcC4xETUanMNLRGTHBgwYYBLQAkCrVq2Mf46MjDQ5FxkZidzcXADAsWPHEBISYgx2AeCee+6BTqdDXl4eFAoFzpw5g4EDB96xD7169TL+uWXLlnBzc8PZs2frektERA2OAS8RkR1r2bJltSkGYnF2draoXvPmzU0eKxQK6HQ6W3SJiMgmOIeXiKgR27NnT7XHXbt2BQB07doVv/76KyoqKoznd+3aBQcHB3Tu3Bmurq4ICgpCZmZmg/aZiKihcYSXiMiOXbt2DaWlpSZlzZo1g5eXFwDgs88+Q58+fXDvvffi008/xb59+7B69WoAwBNPPIHk5GSMHTsWc+fOxblz5zB16lT861//go+PDwBg7ty5mDhxIry9vTFo0CBcunQJu3btwtSpUxv2RomIbIgBLxGRHcvIyICfn59JWefOnXH8+HEA+gwKGzduxHPPPQc/Pz+kpaWhW7duAIAWLVrg22+/xbRp0xAeHo4WLVpg+PDheOedd4xtjR07FlevXsW7776Ll156CV5eXoiPj2+4GyQiagDM0kBE1EgpFAps3boVw4YNk7orRER2jXN4iYiIiEjWGPASERERkaxxDi8RUSPFGWlERJbhCC8RERERyRoDXiIiIiKSNQa8RERERCRrDHiJiIiISNYY8BIRERGRrDHgJSIiIiJZY8BLRERERLLGgJeIiIiIZO3/ATnFFBZUmxJNAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "x = torch.arange(1, 31)\n",
    "\n",
    "plt.scatter(x, MAE_L1_Acc, color='red', label='MAE_L1_Acc')\n",
    "plt.scatter(x, CE_Acc, color='blue', label='CE_Acc')\n",
    "plt.scatter(x, Focal_gamma01, color='green', label='Focal_gamma01(0.5)')\n",
    "plt.scatter(x, Focal_gamma02, color='yellow', label='Focal_gamma02(2)')\n",
    "\n",
    "plt.title(\"Scatter Plot\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Acuracy\")\n",
    "\n",
    "plt.yticks(np.arange(0.05, 0.65, 0.05))\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef602507",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
